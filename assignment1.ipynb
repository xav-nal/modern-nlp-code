{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j05XaIOUvcf"
   },
   "source": [
    "#  Assignment 1 - Language model foundations üí¨\n",
    "\n",
    "Welcome to the **1st assignment** for the **CS-552: Modern NLP course**!\n",
    "\n",
    "> - üòÄ Name: **Xavier Nal**\n",
    "> - ‚úâÔ∏è Email: **xavier.nal@epfl.ch**\n",
    "> - ü™™ SCIPER: **288275**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0bVT0KPUvck"
   },
   "source": [
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid orange;background-color:#fff5d6;border-radius: 20px;\">\n",
    "\n",
    "## How to implement this assignment\n",
    "\n",
    "Please read carefully the following points. All the information on how to read, implement and submit your assignment is explained in detail below.\n",
    "\n",
    "1. For this assignment, you will need to implement and fill in the missing code snippets for both the **Jupyter Notebook** `assignment1.ipynb` and the **`utils.py`** python file. In the `utils.py` file, you will add all the Dataset and Model classes you will implement according to the skeleton present in the file. In the notebook, you will add the data preprocessing pipeline for all the datasets, the training and testing pipelines of all implemented models and the report (See diagram below). \n",
    "    \n",
    "![assignment_1_arch.png](docs/assignment_1_arch.png)\n",
    "\n",
    "2. To implement your coding part, you can import the external libraries we provide in the `requirements.txt` file, however, you should not use any other package non included in these requirements. \n",
    "\n",
    "3. At the end of the notebook, you will need to fill in a **report** template, providing the results of your implementation. We provide you with the template for the report, therefore you need to fill in the missing Markdown cells with the requested information. \n",
    "\n",
    "4. Along with the `assignment1.ipynb` and the `utils.py` files, you need to additionally upload models' pickle files under the `models/` dir, regarding the following models:\n",
    "    - the three LSTM-variant models (PART 2)  \n",
    "    - the trained-from-scratch Transformer model (PART 2) \n",
    "    - the fine-tuned Encoder-Decoder model (PART 3) \n",
    "    - the fine-tuned pre-trained Transformer model (PART 3)\n",
    "    \n",
    "You will provide test results on all of the model variants according to the report template.\n",
    "    \n",
    "5. Finally, you will need to log your training pipelines using Tensorboard. Please follow the instructions in the `README.md` of the [tensorboard/](tensorboard/README.md) directory.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA3bGKeGUvcl"
   },
   "source": [
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid green;background-color:#e4fae4;border-radius: 20px;\">\n",
    "\n",
    "## Assignment Description\n",
    "\n",
    "- In the first two parts of this assignment, you need to train and evaluate two different language models; an **LSTM-based model** and a **Transformer-based model**. You will first explore the distribution of the input data and perform data cleaning and pre-processing. Then you will build two language model training and testing pipelines implementing an LSTM and a Transformer language model. You will play around with different hyperparameters.\n",
    "- In the third part, you will build models on the downstream task of **Sentence Paraphrasing**. More specifically, you will fine-tune a sequence-2-sequence (**Encoder-Decoder**) architecture with attention and you will also fine-tune a **Transformer** model for this task.\n",
    "- Finally, you will fill out a report with the model results for the different parts. \n",
    "\n",
    "More specifically:\n",
    "\n",
    "- **[PART 1: Get to know your data](#1)**\n",
    "    - [1.1 Data Pre-processing](#11)\n",
    "    - [1.2 PyTorch Dataset creation](#12)\n",
    "- **[PART 2: Training Language Models](#2)**\n",
    "    - [2.1 LSTM-variants](#21)\n",
    "    - [2.2 Transformer-variants](#22)\n",
    "- **[PART 3: Fine-tune on the Text Paraphrasing task](#3)**\n",
    "    - [3.1 Train an Encoder-Decoder model on Text Paraphrasing](#31)\n",
    "    - [3.2 Run Transformer on Text Paraphrasing](#32)\n",
    "- **[PART 4: Write your report](#4)**\n",
    "    \n",
    "### Deliverables\n",
    "\n",
    "- ‚úÖ This Jupyter notebook\n",
    "- ‚úÖ `utils.py` file\n",
    "- ‚úÖ 3 pickle files with the three LSTM-variant language models (Part 2)\n",
    "- ‚úÖ Pickle file with the trained-from-scratch Transformer language model (Part 2)\n",
    "- ‚úÖ Pickle file with the Encoder-Decoder model (Part 3)\n",
    "- ‚úÖ Pickle file with the fine-tuned pre-trained Transformer model (Part 3)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBdny5anryRz"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: **Add your SCIPER number below as a `str`!**\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3412,
     "status": "ok",
     "timestamp": 1679775537435,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "StlQjC0igYT5",
    "outputId": "b263119a-409e-4d89-9fc1-78f7b060e3dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1679775537435,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "4vXxVwVOhDRI"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir 'drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2571,
     "status": "ok",
     "timestamp": 1679775539997,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "8UEgVxw_sIrn",
    "outputId": "44282392-be42-49d4-98e9-e00d28f0852e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name: cuda\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device name:', device)\n",
    "\n",
    "SCIPER = \"288275\"\n",
    "\n",
    "try:\n",
    "    assert re.match(\"\\d{6}\", SCIPER)[0] == SCIPER, \"Invalid SCIPER given. please enter your correct 6-digit SCIPER number above!\"\n",
    "except:\n",
    "    print(\"Invalid SCIPER given. please enter your correct 6-digit SCIPER number above!\")\n",
    "\n",
    "student_seed = int(SCIPER[-4:])\n",
    "\n",
    "\n",
    "\"\"\"Set seed for reproducibility.\"\"\"\n",
    "random.seed(student_seed)\n",
    "np.random.seed(student_seed)\n",
    "torch.manual_seed(student_seed)\n",
    "torch.cuda.manual_seed_all(student_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eosLecQYgYT7"
   },
   "source": [
    "### Packgage installation & importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1679775539998,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "eiPc1rRNiS__"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # limiting to one GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679775539999,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "uexGOS0GiS__",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install apache_beam\n",
    "#!pip install torchmetrics\n",
    "#!pip install gensim==4.1.2\n",
    "#!pip install transformers\n",
    "#!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2920,
     "status": "ok",
     "timestamp": 1679775542912,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "NFD5zPpWgYT8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb_writer = SummaryWriter(log_dir='tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1679775542912,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "nrVoV0AGgYT8",
    "outputId": "d62d1e73-2566-4d07-f616-d015c985addf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.2\n"
     ]
    }
   ],
   "source": [
    "import tensorboard\n",
    "print(tensorboard.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1679775542913,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "a_24Wd9PgYT8",
    "outputId": "15dea2cf-8172-4dd9-f378-fb150c423044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.16 (main, Dec  7 2022, 01:11:51) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26288,
     "status": "ok",
     "timestamp": 1679775569188,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "pSns1pqRhqly",
    "outputId": "6830c14d-5592-4039-b7c7-d2c64c7c7b55",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install torchmetrics\n",
    "# !pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1679775571261,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "q0bmJE-0iTAA"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import torch\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, AutoConfig, AutoModelWithLMHead, AutoTokenizer, DataCollatorForLanguageModeling, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m06WLo6qUvcm"
   },
   "source": [
    "---\n",
    "\n",
    "<a name=\"1\"></a>\n",
    "# PART 1: Get to know your data üîé\n",
    "\n",
    "For the first two parts of this assignment, we will build our language models using the `wikitext-103` dataset.\n",
    "\n",
    "> The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified \n",
    "Good and Featured articles on Wikipedia. \n",
    "\n",
    "Bellow is an example from the dataset: \n",
    "<br>_(This example was too long and was cropped)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdwMZ-OUiTAB"
   },
   "source": [
    "\n",
    "\n",
    "<div style=\"padding:8px 0 8px 15px;background-color:#F3F3F3;border-radius:20px;\">\n",
    "<code>{\n",
    "\"text\": \"\\\" The Sinclair Scientific Programmable was introduced in 1975 , with the same case as the Sinclair Oxford . It was larger than t...\"\n",
    "}\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRxt_WZBiTAB"
   },
   "source": [
    "üßê You can find more about this dataset [here](https://huggingface.co/datasets/wikitext)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOD9aSZIiTAC"
   },
   "source": [
    "<a name=\"11\"></a>\n",
    "## 1.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7A0sYxb8klR"
   },
   "source": [
    "In this part, while you get to better understand the dataset sturcuture, you will also do several steps to clean the dataset before passing them to neural models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "d9f84ccd34824ba1a3c26e8e8f39e124",
      "a7bf2383162c427f93f7db57a8682f05",
      "b29b1168dca94462ae55636774096aa9",
      "ff03838c865a4d2ea5ecb535421d2769",
      "a68646357761487f80be410354f638aa",
      "807fa2d1d12f4d4bb9de1e9ff6a88f85",
      "36581e29d6444968b551d831df14be43",
      "3b6738de1bb4438d918b820e0b62a8cf",
      "06cf13ee150c496bbd31da7d6569360c",
      "ec7e8bda72634bc5bc6040217103ea9d",
      "bf122a0867834256ba6f9b017555ad4e",
      "d7be444614614cdebefd632eab00274e",
      "78e3ad377b414579ac2c6da8cf7dba90",
      "025f242e19564a05bf9b553678bad44c",
      "28b10dd4609a498ab08ad3cfeca2be8a",
      "9018602694384bb9b47e21db15c085fa",
      "e1808aa90409413a8073dd37e9a94de2",
      "a42d00425a824e2b8b3d3ad0ab4efdb3",
      "67a4f961064e432580e6b455708604dc",
      "5efc29c94753456a8ff1bd42c53a52ca",
      "0c876787b40f4573bec3a52fde8be8de",
      "f297e5ff171240d885126866d4dc373c",
      "2fd028ca78464d46b313736ca6c26a4c",
      "9570391d6cfe4f7382dc888a32c826a0",
      "f87816bee388448eb40b4b2212293636",
      "8acfef37376641ed92dc344587c128ad",
      "9a86c946a63449efa04938836b37d711",
      "171604fac3c74d3fbcdaa01f23cb45d9",
      "8839b54691a44686b71bba32e9e1cf75",
      "1ac291c00dfd4ec492f30ae43a44ff8c",
      "79e309e661bf44dc93be16b5712e8491",
      "f32b937e9f404e879feeeba76c6d53cd",
      "5ef7d65286614bbbaced24ee49816531",
      "e7fb00ef48dc4a1f9c44bb78052265df",
      "9b3531590e7f411987d75576eb8af05c",
      "35d752525c9349f790fed9c47a7c09f5",
      "d963008f79e94d1386897fcae8e9a696",
      "cb86bf0487f2493f981198ab8e7a6987",
      "98ac5d3ecb9542799910f5e1853bcc61",
      "c8b675c5337a43bba40826d012ed30b3",
      "2eaac12254044bcf8c3200a4677709d3",
      "7f40482551384b978b4fe2a829f506fc",
      "5d49f44429cd4fcc9084ea07b1d3bf70",
      "2d62ec78e3a34e57884c97305ffdec2a",
      "2eb31da671c549f4a90122ea1c8e583e",
      "71a29f6d0871401ca4db0d71eab7cc37",
      "de36110ca4af4a6e809bb8ddf04038d0",
      "144a862f034548ea86d3ebf4f2854ab6",
      "770fc153b46243c4b4c42940a05bf4c8",
      "a5fc9575b72549c0b5ffa370efca03a2",
      "09201791427b4c84b15256669ad148fc",
      "83654b33cc2946d787b6d4bd782abd81",
      "2af9b39de1b0470e9023721f6dbfd97d",
      "9b150a3bef194727a3ebc2699817d79b",
      "cf920b95527949a6ad3de089f12c5f9b",
      "39e1c7fcf7a7431a9e9c195a859d7968",
      "c05a9dc5cc4141baa0ddd4dcb03c4b15",
      "443ea0050e2f4828a5a74fee720d6bb3",
      "465c0385cd8a475c98826353a70e5e5f",
      "7d0f88ae81cc4cd3aee435e5aaebd873",
      "73e21b2a2c7f41f3a43e685fa4d11661",
      "dba1c7baf21c45a2931788783b84745d",
      "c43ffb6fe16045318ab4666c1cfc93eb",
      "ac4514fb3e574d4f874d174896401952",
      "9d54870203074c71a305ce304ee0945c",
      "7ec015b596e14d5a94f4d9a4f8a0af79",
      "07c75c51ca214472b10a87b8d7ad2948",
      "aa2ae5e20c554addab4c3d467f62655a",
      "32685da210ad44dc9943b45fa935bf51",
      "a315d162401746d4b76fab00aa97b654",
      "a8ea751547ba42a6ab8464316904bc3b",
      "de817ad07eca41cb998f81e6df7a808e",
      "da1f6761c0da40b3a98fc1214f10a61c",
      "0d77624d8ab541709df0c2a95d617c98",
      "aaaeecbd3f854fe784e399fc0690babc",
      "44f52a5791fa487f9e4757de3c485e84",
      "0bb7ef7760b84b67af5bcb72c294a40e"
     ]
    },
    "executionInfo": {
     "elapsed": 69042,
     "status": "ok",
     "timestamp": 1679775640299,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "ADe8a4xOUvcm",
    "outputId": "ae08fe77-1d18-446e-9b1c-375cf8619d30"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f84ccd34824ba1a3c26e8e8f39e124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7be444614614cdebefd632eab00274e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/6.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd028ca78464d46b313736ca6c26a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikitext/wikitext-103-v1 to /root/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fb00ef48dc4a1f9c44bb78052265df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/190M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb31da671c549f4a90122ea1c8e583e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e1c7fcf7a7431a9e9c195a859d7968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c75c51ca214472b10a87b8d7ad2948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikitext downloaded and prepared to /root/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.\n",
      "Size of the dataset is 1801350\n"
     ]
    }
   ],
   "source": [
    "# Loads the dataset\n",
    "wikitext_dataset = load_dataset(\"wikitext\", 'wikitext-103-v1', split=\"train\")\n",
    "\n",
    "print(f\"Size of the dataset is {len(wikitext_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfMJBW7OAnj-"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: **Filter out all empty sentences**.\n",
    "\n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe.\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "referenced_widgets": [
      "36f3a0a2c5924ce8bce8945b56dc31df",
      "e5178c6b9715475b967e7fef7a4b2453",
      "9e7bbfed279d4965ac919d1df9c8e421",
      "a369666f68744bba925a590c8ef8dd3e",
      "b209c6c467084a45833e58c72a3aa1a0",
      "a3900f2f2d0b4bbb98385d0716cb152d",
      "87721358a94442e488281df8ce9cc14a",
      "1c9d774078b74375a0e89fecd991eed6",
      "ecad496b93e242edb40cced29c6db8bf",
      "22ee8d4fdf9e4b82a9b7f671e942755c",
      "01ba31f819094461b5b9673535c48a55"
     ]
    },
    "executionInfo": {
     "elapsed": 10659,
     "status": "ok",
     "timestamp": 1679775650927,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "fXz9W7tZiTAD",
    "outputId": "e289327a-6483-4e5c-8010-580b8704c496"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f3a0a2c5924ce8bce8945b56dc31df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset is 1165029\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.filter(lambda example: len(example[\"text\"].split())>=1)\n",
    "\n",
    "\n",
    "print(f\"Size of the dataset is {len(wikitext_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdr5LIY5Dym3"
   },
   "source": [
    "Long sequences in the language model training can significantly slow down the training progress, both for RNN-based and transformer-based models.\n",
    "\n",
    "One of the tricks that is mentioned in [BERT's paper](https://arxiv.org/abs/1810.04805) is to perform pretraining with shorter sequences in the beginning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sIemLH6iTAF"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Following the same line of reasoning, **keep only samples that have at most 128 tokens**.\n",
    "    \n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "referenced_widgets": [
      "afa9834bbbc74f5283418c0ce59fc009",
      "53f9c5eb29974620880ab132cf160c46",
      "49a348ba2027403585844a28edf3e571",
      "5acaa02e1f0e4b01b25f4c9703207fdc",
      "18987a269dfc4a4fb8bdd57b6aa0c5ed",
      "3e9c47e91062408cac3f4eb3cdc0b8b3",
      "b78632f5893341d88e9c468ab66bca91",
      "64ae5659a2284405b58d29256078de2d",
      "15a14e16ac044e2abaf91aaa45d10570",
      "631e539166704bb6b69854731f6099c8",
      "5e9c1496dda043f6ac74dca1009d036f"
     ]
    },
    "executionInfo": {
     "elapsed": 20270,
     "status": "ok",
     "timestamp": 1679775671182,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "E9_xgDXJiTAG",
    "outputId": "e006528b-bb7d-470e-dc2f-e62b749b7af0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa9834bbbc74f5283418c0ce59fc009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1165029 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset is 826663\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.filter(lambda example: len(example['text'].split()) <= 128)\n",
    "\n",
    "print(f\"Size of the dataset is {len(wikitext_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9LcAg0EJzrz"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Let's make the dataset samples **lower case** to decrease the vocabulary size.\n",
    "\n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "26637a3cecff475480064279ef7e36c1",
      "93fbda9a67cb4fd49c3512854325dea0",
      "f7f88bc4a0a741af87dc0d60bf071477",
      "29da6946d5f54607b13b8e161640a3de",
      "dae125af277b4375986e41e0bed34ede",
      "5c39a6e6a35e45f68165eebeca871e5f",
      "226ec8ae56f340a8a33de465e611a69e",
      "b87060d8716445d2bb1915f8c6baffd2",
      "fbb31eb0d1c2426ca6e30f68391298e9",
      "6cb6f7a17e444e2b8b1d62d04279a91f",
      "c0891a63b30e47f9b93aef3ef19c22dd"
     ]
    },
    "executionInfo": {
     "elapsed": 62642,
     "status": "ok",
     "timestamp": 1679775733810,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Q8-Y-7JQiTAH",
    "outputId": "814d913f-da97-421a-9255-058ccc23131d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26637a3cecff475480064279ef7e36c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/826663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.map(lambda example: {'text': example['text'].lower()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1679775733811,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "PrmxbA_JgYT_",
    "outputId": "df85fef7-8869-4b49-9f66-7907a284d47e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aria ( alto ) : kein arzt ist <unk> dir zu <unk> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Get a random example index\n",
    "random_index = random.randint(0, len(wikitext_dataset)-1)\n",
    "\n",
    "# Print the random example text\n",
    "print(wikitext_dataset[random_index]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1679775733811,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "dNH7cVjMgYUA",
    "outputId": "2baefd23-ea06-4b97-fac5-455775652f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = valkyria chronicles iii = \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at the first samples\n",
    "\n",
    "print(wikitext_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1679775733811,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "fdnt6WKegYUA",
    "outputId": "cb20b786-df1c-440c-f6ff-adac504ae9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64061\n",
      " the red hartebeest is listed as least concern . it is the most widespread , with increasing numbers after its reintroduction into protected and private areas . however , it has been extinct in lesotho since the twentieth century . its population is estimated to be over 130 @,@ 000 ( as of 2008 ) , mostly in southern africa . in namibia , the largest population occurs in the etosha national park . a reintroduced population is flourishing in the <unk> nature reserve ( swaziland ) , outside its range . however , numbers have seen a sharp fall in southwestern botswana . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at a random sample \n",
    "import random\n",
    "random_number = random.randint(0, 100000)\n",
    "print(random_number)\n",
    "print(wikitext_dataset[random_number]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUjCH6Z-NALB"
   },
   "source": [
    "If you take a look at the first few samples of the dataset, you will notice that they belong to [this](https://en.wikipedia.org/wiki/Valkyria_Chronicles_II) Wikipedia article.\n",
    "\n",
    "We notice that **the title of  sections/articles are also included** in the dataset (for instance the title itself, or the `gameplay` section in this article). These samples are not very useful for language modeling, due to not having a sentence structure.\n",
    "Given the pattern of these samples, we need to **filter them out** from the dataset.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTuUlhFuiTAI"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Filter out the samples with `= = <section> = = \\n` patterns.\n",
    "    \n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "referenced_widgets": [
      "0af258e7f83b423382f53beca0ff7f63",
      "086ca127059e4c68888f86480f27cb0f",
      "1d00cf3cc9fa4489ae0ca0f179f229ea",
      "fee951e3317c4fe7bdc6a49c71414486",
      "54e7b4b3da4d4a3aaf4aa974c6688194",
      "85c6c1b69ceb493ca68f31a897016b54",
      "213257cf28d74bccb7e242750febcd72",
      "5f0963a36b2a408abb8b7d64230ec827",
      "59af41e4807b4f8d81045f9351a2a095",
      "e150516900614b2ab6197bcf1cb2bf9d",
      "510c23a6481746e69e530c5a7a37851c"
     ]
    },
    "executionInfo": {
     "elapsed": 2850,
     "status": "ok",
     "timestamp": 1679775736628,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "4snXCQBZiTAJ",
    "outputId": "89b7ba35-f712-459f-baee-3ad8512e8bef"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af258e7f83b423382f53beca0ff7f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/826663 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset is 551037\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.filter(lambda example: not re.search(r'= = .* = =', example['text']))\n",
    "\n",
    "print(f\"Size of the dataset is {len(wikitext_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16AHClg64IE6"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Normalize accented letters** (e.g., `cl√©ment` becomes `clement`) from text using `gensim.utils.deaccent` to further decrease vocabulary size.\n",
    "    \n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "33200a33a7c044abb69fbae569464073",
      "5bf499efa43a489bb40ce97811b15a63",
      "af1d7cc540d4474087481c5b419f1998",
      "b19027e8ea574d7ab773e280d25a2c3a",
      "5f374cd198f64204a3daeeffae300a92",
      "76be472206e44e4293cd9f66bc131733",
      "308442a8a1c44a8583cbb62125962068",
      "c1924555bfb04c5d834c93b3e89ff35b",
      "d8cbdc1c4470477fac7d57e9841edb32",
      "fcbd371a0c00498f995c5b41d5c1a161",
      "1a45aeeb3906466c9c3004dc5f528fa3"
     ]
    },
    "executionInfo": {
     "elapsed": 78199,
     "status": "ok",
     "timestamp": 1679775814821,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "1_IHLtBriTAK",
    "outputId": "df4ba437-c8a3-4c0d-c2d0-88e387f0e8e9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33200a33a7c044abb69fbae569464073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/551037 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.map(lambda example: {'text': gensim.utils.deaccent(example['text'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiD093zf5ie_"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Remove all samples having **non-english characters**. \n",
    "   \n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe along with the provided function `isEnglish()`. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "referenced_widgets": [
      "b4c563f6674d4b0496ae03dfdfae29ae",
      "9d60b69a42254880b663c2d92eeb488e",
      "971574a5243045febe0dac53d7782159",
      "269e33af121a4b6c924dfd4d3aa1d898",
      "3fd61e57948c489ba28f36cd98f5e44c",
      "6df94057dba24663b23c9527cff45a34",
      "b54098cbda6c44c08f56667edf64a582",
      "e071d3e7d9ac4386b56d9e74fc151bea",
      "f181e720a2b548c8b1ce0f4ea2b1580d",
      "eb64cfa2be5e42adb40540f8667dd117",
      "efd909b842ea4ee6b3a6e2844f7f406e"
     ]
    },
    "executionInfo": {
     "elapsed": 1373,
     "status": "ok",
     "timestamp": 1679775816180,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Xf0eznSxiTAL",
    "outputId": "e7625f21-5c67-4fb7-b353-da2d80b20ec8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c563f6674d4b0496ae03dfdfae29ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/551037 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset is 461250\n"
     ]
    }
   ],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.filter(lambda example: isEnglish(example['text']))\n",
    "\n",
    "\n",
    "print(f\"Size of the dataset is {len(wikitext_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dboQyQoD9jVx"
   },
   "source": [
    "### Looking at the vocabulary\n",
    "\n",
    "Before we move into additional preprocessing (similarly with the dataset used in exercises for week 2), we will take a look at the vocabulary size of the dataset until this point. We will assume that tokens can be simply splitted by `\" \"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU6bUxgGiTAM"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Compute the frequency of all tokens in the dataset.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34357,
     "status": "ok",
     "timestamp": 1679775850534,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "1M0zpagYiTAM",
    "outputId": "f04bbce5-67db-493c-81f8-b62a99443f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size of the dataset is 189555\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_token_frequency(dataset):\n",
    "  # YOUR CODE HERE\n",
    "    all_tokens = \" \".join([i[\"text\"] for i in dataset]).split()\n",
    "    vocab_frequency = Counter(all_tokens)\n",
    "\n",
    "    return vocab_frequency\n",
    "\n",
    "vocab_frequency = compute_token_frequency(wikitext_dataset)\n",
    "print(f\"\\nVocabulary size of the dataset is {len(vocab_frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1XjEaDvWJtB"
   },
   "source": [
    "As discussed in the lectures, real text datasets have a relatively high fraction of rare tokens. For that reason, let's visualize the histogram of token frequencies to better see this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dU97c1miTAN"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Plot a **histogram** with the frequencies of the words of the vocabulary. \n",
    "   \n",
    "üíª API hint: You can use the `matplotlib.hist` function. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1679775850535,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "rBKUzDEDiTAN"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "frequencies = list(vocab_frequency.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1679775851079,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "i6tZrc6KgYUC",
    "outputId": "0fb54c27-171a-4faf-f2d4-7c5c21b26be2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(frequencies, bins=80)\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('number')\n",
    "plt.title('Word Frequency Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-vDgr_5HyrE"
   },
   "source": [
    "As you saw in the cells above, the dataset vocabulary is quite huge. Let's consider every token that occurs less than (or equal to) 5 times as a rare token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jf5G9QFyiTAN"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Put these rare tokens in the **`rare_tokens` variable** and replace every rare token in the dataset with the `<unk>` token.\n",
    "    \n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 33481,
     "status": "ok",
     "timestamp": 1679775884558,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "_ZmvzguNgYUD"
   },
   "outputs": [],
   "source": [
    "rare_threshold = 5\n",
    "rare_tokens = set()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "vocab_frequency = compute_token_frequency(wikitext_dataset)\n",
    "for token,frequency in vocab_frequency.items():\n",
    "    if frequency <= rare_threshold:\n",
    "        rare_tokens.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54,
     "referenced_widgets": [
      "da839139d26f4f5f85fbc52b09ba0ae4",
      "7b5ba65a7bc14774a920e01c6a800e96",
      "cc59c287c3454140bd328409d98efc63",
      "b0750a0ba06f4fd4b8fb8eb1f76e2961",
      "a924aadadc694854b51f8afc9b658378",
      "94326579ed4c41c8be462f9eb5def04b",
      "29f8282ce02c44efb836baf310eeb88d",
      "b7d43c9c45704760934a7f4b5f5c569f",
      "e9e4261d7084455c88a7688dffe9e3a2",
      "76acca8861394988a064605cce1d842a",
      "dac642df43b84c328d3125a2d6072661"
     ]
    },
    "executionInfo": {
     "elapsed": 42746,
     "status": "ok",
     "timestamp": 1679775927293,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "wRWJFfThiTAO",
    "outputId": "c77a5ca7-f47b-47ae-a3d4-4ba76b6a6e7d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da839139d26f4f5f85fbc52b09ba0ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/461250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With threshold of 5, we have 105529 rare tokens.\n",
      " The vocabulary size is now 84026\n"
     ]
    }
   ],
   "source": [
    "def replace_rare_tokens(text):\n",
    "    \n",
    "    tokens = text['text'].split()\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in rare_tokens:\n",
    "            tokens[i] = '<unk>'\n",
    "            \n",
    "    return{'text': ' '.join(tokens)}\n",
    "\n",
    "wikitext_dataset = wikitext_dataset.map(replace_rare_tokens)\n",
    "\n",
    "\n",
    "print(f\"With threshold of {rare_threshold}, we have {len(rare_tokens)} rare tokens.\\n\",\n",
    "      f\"The vocabulary size is now {len(vocab_frequency) - len(rare_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fu2W9EMiWrP"
   },
   "source": [
    "The dataset still includes many short samples which are not very useful for the language modeling task. We will filter out very short samples from the dataset. _(Note: Assume tokens can be achieved by simple `\" \"` splitting.)_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruh0XqGKiTAO"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    " üéØ Goal: Filter out every sample that has **less than (or equal to) 5 tokens**.\n",
    "    \n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "referenced_widgets": [
      "6bb7b0998f684ca1880bd3c29f160c3b",
      "c0ce9505c0924043a8bef24fc74330e0",
      "74e3fb2bd354439f88613e0005337f24",
      "2c1a87385c4c4aa28551e0deb21852d7",
      "41f83a1a34f54058a8f15c64dca44254",
      "561847ce5f5144caa303db28f1cf2906",
      "06892332c4a84e36896a78114647a91c",
      "7914efe566764982bf5e7e730b6f41f7",
      "f5436e2862a04ff3bf2485f02f3e0ef2",
      "ab5818844fd74e309381fe7244ff27a2",
      "f97a7c1f127b4748a028fb1b4341cb2a"
     ]
    },
    "executionInfo": {
     "elapsed": 2913,
     "status": "ok",
     "timestamp": 1679775930182,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "2QMmBOwjiTAO",
    "outputId": "6b5e717c-a931-4bf0-b3d8-fb22beed289a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb7b0998f684ca1880bd3c29f160c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/461250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset is 415138\n"
     ]
    }
   ],
   "source": [
    "short_seq_threshold = 5\n",
    "\n",
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.filter(lambda example: len(example['text'].split()) > 5)\n",
    "\n",
    "print(f\"Size of the dataset is {len(wikitext_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9wvH77WiTAP"
   },
   "source": [
    "After replacing rare tokens with <unk>, we could have sentences like `<unk> <unk> <unk> <unk>` which are again not very useful for language modeling. We will **filter out samples that more than 5% of its tokens are `<unk>`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoC2HrwKlalG"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Filter out samples that more than 5% of its tokens are `<unk>`**\n",
    "    \n",
    "üíª API hint: Use `datasets.Dataset` utilities to manipulate the dataframe.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "referenced_widgets": [
      "679cecd59fb54ace8e72d95344bc3490",
      "dc06c0eeba5a4cd6bdbdeea2b3ada254",
      "4ad7b16fdfd5483cae339aa49fddff0b",
      "2eb3b4764ba84657a55834e01814b630",
      "b2dfe8e49084416082a3a4d10360d447",
      "d2a6aa142fb040b49bc587f359d28ec9",
      "4bf1f5718b0e462eabd49678333f34e2",
      "36868ebb18b140389df9a0ad5565a2a5",
      "fe04aabeb8f344c48825f32206332b47",
      "4783ccb33d88473fb349c804b212d255",
      "d0e1cc77d4b045fca1eee7cbc1e9ed00"
     ]
    },
    "executionInfo": {
     "elapsed": 7281,
     "status": "ok",
     "timestamp": 1679775937454,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "xdiXr9p0iTAP",
    "outputId": "1c903426-60c2-486b-831e-b4dcdc59e789"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679cecd59fb54ace8e72d95344bc3490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/415138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset is 376835\n"
     ]
    }
   ],
   "source": [
    "unknown_token_threshold = 0.05  # every sample that more than 5% of its tokens are <unk> should be removed\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "wikitext_dataset = wikitext_dataset.filter(lambda example: sum([1 for token in example['text'].split() if token == \"<unk>\"]) \n",
    "                                           / len( example['text'].split()) <= unknown_token_threshold)\n",
    "\n",
    "print(f\"Size of the dataset is {len(wikitext_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGtIxEa07-8K"
   },
   "source": [
    "Let's recalculate the vocabulary for the resulting dataset, to see the vocabulary of the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27241,
     "status": "ok",
     "timestamp": 1679775964669,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "q3-WohMHlXIo",
    "outputId": "8c3f4dcb-6f31-4453-9012-5d232b139845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vocabulary size of the dataset is 83880\n"
     ]
    }
   ],
   "source": [
    "vocab_frequency = compute_token_frequency(wikitext_dataset)\n",
    "\n",
    "print(f\"\\nvocabulary size of the dataset is {len(vocab_frequency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "b973ae1f891b422b81fb945cdeda3337",
      "0ca7a531653e409485df5872820d612b",
      "d3a8b092d677406c98101ef81941f608",
      "d74a7f92c7924dcd998f499efc2c1dd2",
      "6144aa3e44a2437cbc45bb3c1c75f273",
      "1b44e8ed0163498584a679bb3caa7e82",
      "2981ac58ca60496c9cf71acb28c20b99",
      "c494739760624207bcbe68869bc2ec18",
      "000cf54d7a994e76b3c8ed6e5a7fa8ea",
      "59e61f302b6b4d068f1aa2bbe961ac97",
      "89982609fcee4f78a3f682e84bfde852",
      "af6dbb2893ac472d8213175b68a55c23",
      "841206ab98c044cba8bd439428b83c4c",
      "6af28750e5a24a748cf955506848a3c6",
      "274c571165ad49b8b951c98637de3b8c",
      "cdc95de5485d4a3b86f09944443cb667",
      "7cc0781f7c534819adae03e75d068b2f",
      "cd550588ac0d4e57b17cb3933c45206f",
      "a7d53085374c4e0298fa60595eec89aa",
      "4dd935a314e34a8889261bc587d8f73f",
      "99590e9aa62b43c1af8bdfcf4100f50c",
      "f14d8ff493af428d931d743619c05bd2"
     ]
    },
    "executionInfo": {
     "elapsed": 3840,
     "status": "ok",
     "timestamp": 1679775968494,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "qIdCK15ogYUE",
    "outputId": "b3cd7800-99a4-4638-ec11-1b8abfd001e6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b973ae1f891b422b81fb945cdeda3337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/376835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6dbb2893ac472d8213175b68a55c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/376835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the dataset filtered for later use\n",
    "wikitext_dataset.save_to_disk(\"wikitext_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1679775968495,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "j6S1E5-WgYUE"
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "wikitext_dataset = load_from_disk(\"wikitext_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679775968495,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "ATGk3BhdgYUF",
    "outputId": "d22e2904-e49b-4f75-cd2d-7c592351456a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 376835\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07Q5by1kiTAQ"
   },
   "source": [
    "---\n",
    "\n",
    "<a name=\"12\"></a>\n",
    "## 1.2 PyTorch Dataset  creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXgKUIGbSdAu"
   },
   "source": [
    "After the pre-processing of the dataset, we will now create a `torch.Dataset` class for the wiki-text dataset. \n",
    "We need to do so, in order to transform the dataset to the right format for the language modeling task. \n",
    "The following steps should be implemented:\n",
    "\n",
    "- Add `<start>` and `<stop>` tokens at the beginning and end of a sentence respectively.\n",
    "- Add padding tokens ( `<pad>` ) at the end of the sentences.\n",
    "- Create a fallback to <unk> token if an unseen word is encoded.\n",
    "- Define dictionaries that map tokens to their respective index in the embedding matrix and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtKKcjq4iTAR"
   },
   "source": [
    "### Create the RNN Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYcATZ2XiTAR"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Go to the `utils.py` file, and fill in the `RNNDataset` class with your implemenation.**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679775968496,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "SmSdlO_BBbFO"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import datasets\n",
    "import math\n",
    "from src.utils import RNNDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG5flxTZiTAR"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Instantiate** the implemented RNNDataset.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 20544,
     "status": "ok",
     "timestamp": 1679775989036,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "FvovsTi0iTAS"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MAX_SEQ_LENGTH = 128\n",
    "rnn_dataset = RNNDataset(dataset = wikitext_dataset, max_seq_length = MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1679775989037,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "J9PMqxRZwqMA",
    "outputId": "e5f8ec7e-b1d5-49d5-b9db-475ff08792c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "print(len(rnn_dataset.data[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1679775989037,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "8KmsMdddgYUG",
    "outputId": "6ccd8629-2f69-4340-840f-be40b2479325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376835\n",
      "83883\n",
      "83883\n"
     ]
    }
   ],
   "source": [
    "print(len(rnn_dataset))\n",
    "print(len(rnn_dataset.dataset_vocab))\n",
    "print(rnn_dataset.dataset_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_woATTryiTAS"
   },
   "source": [
    "### Split data into train and test\n",
    "\n",
    "Once we have created the dataset ready for the model training pipeline, we will split it into train and test datasets. Then we will pass them to a `DataLoader` class, following the same method we saw in the exercises session. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFevD8HUiTAS"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Split** the implemented RNNDataset into train and test subsets.\n",
    "    \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1679775989037,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "YTS-9IfliTAT",
    "outputId": "e4e4db99-e7c9-4970-c03f-1eae18cee617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339151 37684\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RATIO = 0.9\n",
    "\n",
    "dataset_length = len(wikitext_dataset)\n",
    "train_length = math.floor(dataset_length * TRAIN_RATIO)\n",
    "test_length = dataset_length - train_length\n",
    "\n",
    "print(train_length,test_length)\n",
    "\n",
    "rnn_train_dataset, rnn_test_dataset = torch.utils.data.random_split(rnn_dataset,\n",
    "                                                               [train_length, test_length],\n",
    "                                                               generator=torch.Generator().manual_seed(student_seed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi1TfgHbiTAT"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "    \n",
    "üéØ Goal:  Create `DataLoader` objects using `batch_size = 8` for the train and test subsets.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1679775989038,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "GEab9WiQiTAU"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(rnn_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(rnn_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1679775989038,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "nfCOjaNNgYUH",
    "outputId": "01c1113d-5d6f-4ee3-fae6-57ce50b3d2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "torch.Size([8, 129])\n"
     ]
    }
   ],
   "source": [
    "# saniter check if batchs iteration work!\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(batch[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZpVeuyWiTAU"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #8e7cc3;background-color:#e4e1eb;border-radius: 15px;\">\n",
    "\n",
    "üéâ Excellent work! By this point, you will have made all the needed steps to make your data ready for training. \n",
    "\n",
    "#### Part 1 - Checklist\n",
    "Here are the core building blocks you created and that you will need for Part 2:\n",
    "   \n",
    "- [X] `rnn_dataset`: A Dataset obj with the data, the vocabulary, the pad index, the max sequence length, and maps of idx to word type and vice versa. \n",
    "- [X] `train_dataloader`: A DataLoader obj with your training data\n",
    "- [X] `test_dataloader`: A DataLoader obj with your testing data\n",
    "\n",
    "\n",
    "_Tip: Try to familiarize yourself with these objects and what functionalities and attributes they provide._\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPDNtdxFUvcn"
   },
   "source": [
    "---\n",
    "\n",
    "<a name=\"2\"></a>\n",
    "# PART 2:  Training Language Models ü§ó\n",
    "\n",
    "#### Language Model: a probabilistic model of a sequence of tokens.\n",
    "\n",
    "üîµ **What?**\n",
    "\n",
    "Language modeling (LM) is the use of various statistical and probabilistic techniques to determine the probability of a given sequence of words occurring in a sentence. Language models analyze bodies of text data to provide a basis for their word predictions. They are used in natural language processing (NLP) applications, particularly ones that generate text as an output. Some of these applications include, machine translation and question-answering.\n",
    "\n",
    "üü° **How?**\n",
    "\n",
    "There are several different probabilistic approaches to modeling language, which vary depending on the purpose of the language model. From a technical perspective, the various types differ by the amount of text data they analyze and the math they use to analyze it (architecture). Some LMs we've already seen and will learn about during lectures are n-gram / count-based models, Recurrent Neural Networks (RNNs), and Transformer models. \n",
    "\n",
    "üü£ **Why?**\n",
    "\n",
    "Language modeling is crucial in modern NLP applications. It is the reason that machines can understand qualitative information. Each language model type, in one way or another, turns qualitative information into quantitative information. This allows people to communicate with machines as they do with each other to a limited extent. It is used directly in a variety of industries including tech, finance, healthcare, transportation, legal, military and government. Additionally, it's likely most people reading this have interacted with a language model in some way at some point in the day, whether it be through Google search, an autocomplete text function or engaging with a voice assistant.\n",
    "\n",
    "‚ÑπÔ∏è Source: [Original article](https://www.techtarget.com/searchenterpriseai/definition/language-modeling#:~:text=Language%20models%20determine%20word%20probability,predict%20or%20produce%20new%20sentences.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_CK0Zl7iTAU"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid gray;background-color:#F3F3F3;border-radius: 15px;\">\n",
    "\n",
    "In this part, you will train your own language models using the dataset created in Part 1.\n",
    "\n",
    "More specifically, you need to implement **5 different model variants**, train and test them to compute their perplexity.\n",
    "    \n",
    "| Model | Variant | Description |\n",
    "|:---- |:----- | :----- |\n",
    "| | Token embeddings trained from scratch | An LSTM model with a trainable token Embedding layer <br>that will be initialized randomly and trained from scratch along with the LM. |\n",
    "| **LSTM** | Pre-trained token embeddings & frozen | An LSTM model with pre-trained GloVe embeddings as input <br>that will be frozen while the LM is training. |\n",
    "|  | Pre-trained token embeddings & trainable | An LSTM model with pre-trained GloVe embeddings as input <br>that will be further trained along with the LM. |\n",
    "||||\n",
    "| **Transformer** | Trained from scratch | A Transformer based model that follows the architecture of [DistilGPT2](https://huggingface.co/distilgpt2). |\n",
    "|  | Pre-trained DistilGPT2 | A pre-trained Transformer based model called [DistilGPT2](https://huggingface.co/distilgpt2) <br>and will be used only for testing (not training). |\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "po9S7IYGxb1G",
    "outputId": "d3e435b8-4c87-4aa2-ef4e-46a1262fc802"
   },
   "source": [
    "---\n",
    "<a name=\"21\"></a>\n",
    "## 2.1 LSTM-variants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Smi1xBm3iTAV"
   },
   "source": [
    "### 2.1.1 Implementing all LSTM variants in one Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7AkS2_0iTAV"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Go to the `utils.py` file, and fill in the `VanillaLSTM` class with your implemenation.**\n",
    "    \n",
    "üíª Implementation hint: You will create one model class for all variants. Try to incorporate all the different cases into one Model class.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1679775989038,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "pIdJ9c9-Uvco"
   },
   "outputs": [],
   "source": [
    "from src.utils import VanillaLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pfHmcVCiTAW"
   },
   "source": [
    "### 2.1.2 Building training and testing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3i0pjS2iTAW"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  Implement training and testing pipelines.\n",
    "  \n",
    "üíª Implementation hint: Check the pipelines we created in the exercises sessions.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1679775989039,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "eyo5izV8iTAW"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, model_type = 1):\n",
    "    \"\"\"\n",
    "    Main training pipeline. Implement the following:\n",
    "    - pass inputs to the model\n",
    "    - compute loss\n",
    "    - perform backward pass and update weights\n",
    "\n",
    "    :param model: \n",
    "    :param train_loader:\n",
    "    :param optimizer:\n",
    "    :param criterion: \n",
    "    :param device:\n",
    "    :param model_type: tensorboard for each model\n",
    "    return: \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "   \n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for epoch in range(1):\n",
    "        num_correct = 0\n",
    "        running_epoch_loss = 0.0\n",
    "        for i, batch in enumerate(tqdm(train_loader, desc='Training '), 0):\n",
    "\n",
    "            data, targets = batch \n",
    "            data = data.to(device)\n",
    "            targets  = targets.to(device)\n",
    "            \n",
    "\n",
    "            # Perform the forward pass of the model\n",
    "            output = model(data)\n",
    "            # print('output.shape', output.shape)\n",
    "\n",
    "            # Calculate loss using output and the ground-truth label\n",
    "            #loss = criterion(output, y)\n",
    "            loss = criterion(output.view(-1, output.shape[2]), targets.view(-1))\n",
    "            \n",
    "            \n",
    "            if model_type == 1:\n",
    "              # print('logs',loss, i)\n",
    "              tb_writer.add_scalar('LSTM_LM_variant_A/train_loss', loss, i)\n",
    "            elif model_type == 2:\n",
    "              tb_writer.add_scalar('LSTM_LM_variant_B/train_loss', loss, i)\n",
    "            elif model_type == 3:\n",
    "              tb_writer.add_scalar('LSTM_LM_variant_C/train_loss', loss, i)\n",
    "              \n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get predicted label\n",
    "            y_pred = output.argmax(dim=-1)\n",
    "\n",
    "            # Update statistics\n",
    "            num_correct += (y_pred == targets).sum().item()\n",
    "            running_epoch_loss += loss.item()\n",
    "            \n",
    "            # print('loss',loss.item(), i)\n",
    "\n",
    "    epoch_loss = running_epoch_loss / len(train_loader)    \n",
    "    print('epoch', epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1679775989039,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "D3MaSi_TiTAX"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device, model_type = 1):\n",
    "    \"\"\"\n",
    "    Main testing pipeline. Implement the following:\n",
    "    - pass inputs to the model\n",
    "    - compute loss\n",
    "    - compute perplexity\n",
    "\n",
    "    :param model: \n",
    "    :param test_loader:\n",
    "    :param criterion: \n",
    "    return: \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    batch_loss = 0\n",
    "    batch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    \n",
    "    # Testing loop\n",
    "    for i, batch in tqdm(enumerate(test_loader)):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # print('shape x and y', x.shape, y.shape)\n",
    "\n",
    "        # Perform the forward pass of the model\n",
    "        output = model(x)  \n",
    "\n",
    "        # Compute and print loss\n",
    "        \n",
    "        # print('shape args', output.shape, y.shape)\n",
    "        # loss = criterion(output, y)  # Step ‚ë°\n",
    "        loss = criterion(output.view(-1, output.shape[2]), y.view(-1))\n",
    "        y_pred = output.argmax(dim=1)\n",
    "\n",
    "               \n",
    "        # Get predicted label\n",
    "        y_pred = output.argmax(dim=-1)\n",
    "\n",
    "        # Update statistics\n",
    "        num_correct += (y_pred == y).sum().item()\n",
    "        running_loss += loss.item()  \n",
    "\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_perplexity = torch.exp(torch.tensor(running_loss/len(test_loader)))\n",
    "\n",
    "    if model_type == 1:\n",
    "      tb_writer.add_scalar(\"LSTM_LM_variant_A/test_loss\", test_loss, 0)\n",
    "      tb_writer.add_scalar(\"LSTM_LM_variant_A/test_perplexity\", test_perplexity, 0)\n",
    "    elif model_type == 2:\n",
    "      tb_writer.add_scalar(\"LSTM_LM_variant_B/test_loss\", test_loss, 0)\n",
    "      tb_writer.add_scalar(\"LSTM_LM_variant_B/test_perplexity\", test_perplexity, 0)\n",
    "    elif model_type == 3:\n",
    "      tb_writer.add_scalar(\"LSTM_LM_variant_C/test_loss\", test_loss, 0)\n",
    "      tb_writer.add_scalar(\"LSTM_LM_variant_C/test_perplexity\", test_perplexity, 0)        \n",
    "\n",
    "    print(f'Test loss: {test_loss:.3f}')\n",
    "    print(f'Test Perplexity: {test_perplexity:.3f}')\n",
    "\n",
    "    \n",
    "    return test_loss, test_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PyjPXYsnNI6"
   },
   "source": [
    "### 2.1.3 Train and test LSTM variants\n",
    "\n",
    "For **all the LSTM variants** you will perform the following steps:\n",
    "\n",
    "1. Set hypeparameters\n",
    "2. Load embeddings if needed\n",
    "3. Instantiate the model and set training configurations\n",
    "4. Run training pipeline (from 2.1.2)\n",
    "5. Save the model\n",
    "6. Run testing pipeline and compute perplexity (from 2.1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pro1_GX0iTAX"
   },
   "source": [
    "#### LSTM Variant A: Embeddings trained from scratch\n",
    "\n",
    "An LSTM model with a trainable Embedding layer that will be initialized randomly and trained from scratch along with the LM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYml9WJiiTAX"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Set hyperparameters according to the objective of the model.\n",
    "      \n",
    "üíª Implementation hint: You can play arround with different values for `dropout_rate`, `lr` and `num_layers`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1679775989039,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "npU3rud1iTAY",
    "outputId": "134a7bfe-cb8d-4b6e-ab00-c0e5ea7cd0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "vocab_size = rnn_dataset.dataset_vocab_size\n",
    "embedding_dim = 100\n",
    "hidden_dim = 100\n",
    "num_layers = 1 # play arround\n",
    "dropout_rate = 0.5 # play arround\n",
    "lr = 1e-4  # learning rate - play around\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqARabVmiTAY"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Instantiate the **model, optimizer and loss**.\n",
    "      \n",
    "üíª Implementation hint: Choose your training settings according to the task you need to do.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9554,
     "status": "ok",
     "timestamp": 1679775998572,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Md5wrZODiTAY",
    "outputId": "4685b1b0-1fb7-403a-a008-637e757363f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 16,941,283 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model = VanillaLSTM(vocab_size = vocab_size, \n",
    "                 embedding_dim = embedding_dim,\n",
    "                 hidden_dim = hidden_dim,\n",
    "                 num_layers = num_layers, \n",
    "                 dropout_rate = dropout_rate,\n",
    "                 device = device,\n",
    "                 embedding_weights=None,\n",
    "                 freeze_embeddings=False,\n",
    "                 verbose=False\n",
    "                   ).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = rnn_dataset.pad_idx)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqbaWk-niTAZ"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **training and testing pipelines** on **10% data** (train and test) and compute perplexity.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1679775998573,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "9NQspJsNgYUK",
    "outputId": "c9b3c600-c9a1-454f-8273-93670c39e390",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size subset 33915\n",
      "size subset 3768\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "# Using the Trainer class on 10% of data\n",
    "subset_size_train = int(len(train_dataloader.dataset) * 0.1)\n",
    "subset_size_test = int(len(test_dataloader.dataset) * 0.1)\n",
    "print('size subset', subset_size_train)\n",
    "print('size subset', subset_size_test)\n",
    "subset_train_dataset = Subset(train_dataloader.dataset, range(subset_size_train))\n",
    "subset_test_dataset = Subset(test_dataloader.dataset, range(subset_size_test))\n",
    "# Move the data to the GPU\n",
    "# subset_train_dataset.dataset.data.to(device) \n",
    "subset_train_dataloader = DataLoader(subset_train_dataset, batch_size=train_dataloader.batch_size,\n",
    "                                     shuffle=True, num_workers=4, pin_memory=True)\n",
    "subset_test_dataloader = DataLoader(subset_test_dataset, batch_size=test_dataloader.batch_size,\n",
    "                                     shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54016,
     "status": "ok",
     "timestamp": 1679776052569,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "niQ7xTIogYUK",
    "outputId": "285f0332-0200-48c5-be08-65212481ef51",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4240/4240 [00:54<00:00, 78.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7.317196613550186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, subset_train_dataloader, optimizer, criterion, device)\n",
    "# tb_writer.close()\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4146,
     "status": "ok",
     "timestamp": 1679776056705,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "zHja4vJygYUK"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/models/lstm_with_random_token_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2731,
     "status": "ok",
     "timestamp": 1679776059424,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "ddEdJenggYUK",
    "outputId": "e2339097-a5eb-42f0-c144-dd54125e21ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471it [00:02, 198.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.932\n",
      "Test Perplexity: 1024.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.931734707704775, tensor(1024.2690))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, subset_test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azom5bf9nU__"
   },
   "source": [
    "#### LSTM Variant B: Pre-trained embeddings & frozen\n",
    "\n",
    "An LSTM model with pre-trained GloVe embeddings as input that will be frozen while the LM is training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3xaQCLEiTAZ"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Download **GloVe embeddings**.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47691,
     "status": "ok",
     "timestamp": 1679776107112,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "kd7HcRw0iTAa",
    "outputId": "abd54fc1-1fbc-45c7-f808-396b9932c9ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "# Download the \"glove-wiki-gigaword-100\" embeddings\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxjduZePiTAa"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Create an embedding layer with dimensions that match the input of `VanillaLSTM` model and initialize it with random weights.\n",
    "    \n",
    "üíª API hint: Use `torch.nn.Embedding` class.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1679776107113,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "0SxSFs2NiTAa"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "initial_embedding_weight = nn.Embedding.from_pretrained(torch.randn((vocab_size, embedding_dim)), freeze=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V9MhJv_iTAa"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Add each GloVe embedding in the respective position in the Embedding layer created in previous step.\n",
    "\n",
    "üíª API hint: Use `.key_to_index` and `.word_to_index` functions.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1679776107624,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "wpb9htFliTAa",
    "outputId": "c5596603-93af-4a98-ff91-825379c788dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n",
       "        [-0.3046, -0.2365,  0.1758,  ..., -0.8456, -0.0354,  0.1704],\n",
       "        [-0.6610, -0.0730,  0.9238,  ..., -0.2256,  0.8148, -0.4405],\n",
       "        ...,\n",
       "        [-1.7233,  1.7603, -1.0270,  ...,  1.0556, -0.3491, -1.3477],\n",
       "        [-0.4523,  0.4098,  1.6814,  ...,  0.6490,  0.1573, -1.1028],\n",
       "        [ 0.7975,  0.9341,  0.0903,  ..., -0.5825,  1.7144,  1.6466]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# initial_embedding_weight.weight.data.copy_(torch.tensor(glove_vectors.vectors))\n",
    "\n",
    "# embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "embedding_matrix = np.random.randn(vocab_size, embedding_dim)\n",
    "\n",
    "for i, word in enumerate(rnn_dataset.dataset_vocab):\n",
    "    if word in glove_vectors:\n",
    "        embedding_matrix[i] = glove_vectors[word]\n",
    "        \n",
    "initial_embedding_weight.weight.data.copy_(torch.FloatTensor(embedding_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fw2Vln9miTAb"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Instantiate the **model, optimizer and loss**.\n",
    "      \n",
    "üíª Implementation hint: Choose your training settings according to the task you need to do.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1679776107624,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "85tKcWG0iTAb",
    "outputId": "fa34e711-bcaf-498b-a4b4-39a2c749d5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8,552,983 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# the parameter verbose is used for debug\n",
    "model_b = VanillaLSTM(vocab_size = vocab_size, \n",
    "                 embedding_dim = embedding_dim,\n",
    "                 hidden_dim = hidden_dim,\n",
    "                 num_layers = num_layers, \n",
    "                 dropout_rate = dropout_rate,\n",
    "                 device=device,\n",
    "                 embedding_weights=initial_embedding_weight.weight,\n",
    "                 freeze_embeddings=True,\n",
    "                 verbose=False\n",
    "                   ).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_b.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = rnn_dataset.pad_idx)\n",
    "num_params = sum(p.numel() for p in model_b.parameters() if p.requires_grad)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_Uezm3ZiTAb"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **training and testing pipelines** on **10% data** (train and test) and compute perplexity.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1679776107625,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "UpLUVxWpgYUM",
    "outputId": "c262a4c6-908e-4886-d061-420eae1d0721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size subset train 33915\n",
      "size subset test 3768\n"
     ]
    }
   ],
   "source": [
    "# Take 10% of the data\n",
    "from torch.utils.data import Subset\n",
    "# Using the Trainer class on 10% of data\n",
    "subset_size_train = int(len(train_dataloader.dataset) * 0.1)\n",
    "subset_size_test = int(len(test_dataloader.dataset) * 0.1)\n",
    "print('size subset train', subset_size_train)\n",
    "print('size subset test', subset_size_test)\n",
    "subset_train_dataset = Subset(train_dataloader.dataset, range(subset_size_train))\n",
    "subset_test_dataset = Subset(train_dataloader.dataset, range(subset_size_test))\n",
    "\n",
    "subset_train_dataloader = DataLoader(subset_train_dataset, batch_size=train_dataloader.batch_size,\n",
    "                                     shuffle=True)\n",
    "subset_test_dataloader = DataLoader(subset_test_dataset, batch_size=test_dataloader.batch_size,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53089,
     "status": "ok",
     "timestamp": 1679776160706,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "om8GetFxiTAb",
    "outputId": "40723790-fb71-423a-b9db-212d387a1f2e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4240/4240 [00:52<00:00, 80.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7.334559931057804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model_b, subset_train_dataloader, optimizer, criterion, device, model_type = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1679776162915,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Hxw-f2lJFvJz"
   },
   "outputs": [],
   "source": [
    "torch.save(model_b.state_dict(), 'drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/models/lstm_with_frozen_glove_token_embedding.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2558,
     "status": "ok",
     "timestamp": 1679776165467,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "7__Oglb9gYUM",
    "outputId": "8ae54b10-1f06-40c9-cd2b-094b1eb5376e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471it [00:02, 179.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.961\n",
      "Test Perplexity: 1055.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.961335887827944, tensor(1055.0417))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test(model_b, subset_test_dataloader, criterion, device, model_type = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jsDup2iTAb"
   },
   "source": [
    "#### LSTM Variant C: Pre-trained embeddings & trainable\t\n",
    "An LSTM model with pre-trained GloVe embeddings as input that will be further trained along with the LM.\n",
    "\n",
    "_Note: Use the same embedding layer you instantiated with GloVe embeddings in the previous step_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCr4iCXqmZPm",
    "outputId": "30f3bef5-b15c-401b-bd7b-c5ea933dd2ba"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Instantiate the **model, optimizer and loss**.\n",
    "      \n",
    "üíª Implementation hint: Choose your training settings according to the task you need to do.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1679776183549,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "ZiM8ADB0ssYv",
    "outputId": "39ab53d3-b71a-4a34-b8dd-29c338effd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 16,941,283 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model_c = VanillaLSTM(vocab_size = vocab_size, \n",
    "                 embedding_dim = embedding_dim,\n",
    "                 hidden_dim = hidden_dim,\n",
    "                 num_layers = num_layers, \n",
    "                 dropout_rate = dropout_rate,\n",
    "                 device=device,\n",
    "                 embedding_weights=initial_embedding_weight.weight,\n",
    "                 freeze_embeddings=False,\n",
    "                 verbose=False\n",
    "                   ).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_c.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = rnn_dataset.pad_idx)\n",
    "num_params = sum(p.numel() for p in model_c.parameters() if p.requires_grad)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeEbRuZ4iTAc"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **training and testing pipelines** on **10% data** (train and test) and compute perplexity.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56283,
     "status": "ok",
     "timestamp": 1679776242425,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "R7iCRJSyIIRE",
    "outputId": "79278740-153e-444c-96df-ebfdc410bdf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4240/4240 [00:56<00:00, 75.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7.302483490053213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model_c, subset_train_dataloader, optimizer, criterion, device, model_type = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1679776243688,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "-Vb2zyknILC1"
   },
   "outputs": [],
   "source": [
    "torch.save(model_c.state_dict(), 'drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/models/lstm_with_nonfreezed_glove_token_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2480,
     "status": "ok",
     "timestamp": 1679776246163,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "5vgy6soessg1",
    "outputId": "bd359c35-e874-4927-c404-dc15c56e1831",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471it [00:02, 179.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.859\n",
      "Test Perplexity: 952.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.859222997272597, tensor(952.6265))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_c, subset_test_dataloader, criterion, device, model_type = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuBG_yHto6Qz"
   },
   "source": [
    "---\n",
    "\n",
    "<a name=\"22\"></a>\n",
    "## 2.2 Transformer-variants\n",
    "\n",
    "For all Transformer vairants we will use the architecture of **DistilGPT2** model. DistilGPT2 (short for Distilled-GPT2) is an English-language model pre-trained with the supervision of the smallest version of Generative Pre-trained Transformer 2 (GPT-2). Like GPT-2, DistilGPT2 can be used to generate text. See more details in the [HuggingFace model card](https://huggingface.co/distilgpt2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieaNrQIJzow-"
   },
   "source": [
    "### 2.2.1 Train DistilGPT-2 from scratch\n",
    "\n",
    "You will perform the following steps:\n",
    "\n",
    "1. Load the config of the DistilGPT-2 model using the Transformers library.\n",
    "2. Load Model class from the config and the respective tokenizer.\n",
    "3. Change input dataset to fit with the tokenization mechanism of DistilGPT-2.\n",
    "4. Split dataset into train and test.\n",
    "5. Create DataLoaders for train and test subsets.\n",
    "6. Train the model from stratch.\n",
    "7. Test the model and compute perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679776246163,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "jUWqgNzvzoj-"
   },
   "outputs": [],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "tokenizer_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dsz8Xg36iTAd"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Load model config, model class and tokenizer.\n",
    "      \n",
    "üíª Implementation hint: You should load the **model instance** and not the pre-trained model weights. You should load the pre-trained tokenizer though.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "3e75b896342c403db09fe0e426de03de",
      "acc92b39494b4b91b7f8e6b3a34199aa",
      "b9e80facd7974e10872bc0760d80a4a7",
      "5652c227b1114bc28b0d4fa392ea37fe",
      "36cee41e59ef4750b7420791c624d634",
      "df52d3b5f08a40288cff117edbfd908d",
      "d9aa66589a2d4e62a75e910a2b0edc5f",
      "0261cdb3b98a499a9abc6eca1b85aa73",
      "fe38b364145442008abf0430f4061e5a",
      "010ccbc0e2514995a9bb9ca6b4dcbb46",
      "16d0150cb43c4e9ab561116097a3dffb",
      "2c90ab876674470c9e067784d9067dfd",
      "7718016a10454d6bbb0ba46cc5beae22",
      "63b2dd1da8884f3aa570b93cd31c64e5",
      "2b019bc3c5c04369aa6e9b51b67157b5",
      "7c43844864b447c4817c1a50ae98b1df",
      "8273c0d1bf154036a92f4c3d49e83e0a",
      "da0e7695cd45429795d43319e66b3f7f",
      "70322f5d731d4514ba3015ba2127b42d",
      "4af2d0f58bee4dcaacf579f7083da4c6",
      "9d5bc8eabe7f428f8a3a2e688ea163ef",
      "ce3cc11b9bcf47deae8fc8b9ce627eed",
      "34060cfca234472885c990b4de25547c",
      "8d8822a6d8c1430799ed05e6b955b4ff",
      "0bc7013374174522aa093855c4202292",
      "054bfe9774574154a35226760c18cce2",
      "85663c3cdbdb4fc88c856f68eb3f5951",
      "6ebee1a399704883a625c28b6d6a77b4",
      "f4bf38c2479b4f64b1c97b2d4785bdf6",
      "78a86dd6ceda4f19ac38a7f835e6f4a1",
      "46918084fafa464c97c8d110cd054c3b",
      "57ffafb4c19f4ba696d75b8e0b6e61fa",
      "e18a612645d54d08a0a25bf95bfd3c19",
      "8d8047d8ab5e478a8480a7a3588825ad",
      "cb58d44cbed8496caff8b5c48fd62515",
      "ca6ec11a7a6141609f4c5974d1a9c145",
      "5508c2d80733471fa98dcf6fafce7d0c",
      "95652bd45a39443191d5e5afb8b89f4d",
      "2a9b2d2402874e2a9a0207eb302a821b",
      "fb9edfbab78e4a85a28c3dd642aacd53",
      "0f701e9fa8ba4eccb83b61b01b6df2b1",
      "9d4e0c51b6134bb18dec240f1a17adf2",
      "6da777740e0d4d1fbf563c3977692b4d",
      "6b8ca95f9db7441ebce44df046c2e062"
     ]
    },
    "executionInfo": {
     "elapsed": 17775,
     "status": "ok",
     "timestamp": 1679776263935,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "QLaG6iasiTAd",
    "outputId": "eb214d11-c594-43b9-dab2-37a677660c13",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e75b896342c403db09fe0e426de03de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c90ab876674470c9e067784d9067dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34060cfca234472885c990b4de25547c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8047d8ab5e478a8480a7a3588825ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "# from transformers import GPT2Model\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, AutoConfig, AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model_config = AutoConfig.from_pretrained(model_name)\n",
    "gpt2_scratch_model =  GPT2LMHeadModel(model_config)\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7BA6SG-iTAd"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Implement the following steps according to the in-line comments.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1679776263935,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "wt0s6Hr4fpWl",
    "outputId": "8ccf4f45-41b2-4d12-ba9b-2bf0ca239ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 376835\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "wikitext_dataset = load_from_disk(\"wikitext_filtered\")\n",
    "print(wikitext_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1679776263936,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "KjODs2E7hqMp"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# add pad_token the same as the EOS token to not increase vocab size\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "referenced_widgets": [
      "bd66cddedd3d47e89df5dcc53a73dbd9",
      "b5724493d48f4187b54620e9a3a24467",
      "88e76ccf82414782818c76a24b665213",
      "74e926cf26d745efabd8f46ce7228caa",
      "d3a4eff41faa4344b1618ae90417b396",
      "5dabde875e3843d1ac116d6e58e08267",
      "73a85f4df0594cb89f0c52b9fa4764f3",
      "2780a9449ea94a54a02377a0a27b972c",
      "64616ab98d494e088f3cba66e9bd36d7",
      "2880b152ff834505bbc85afcf0b1f15d",
      "ddb3ff1953d04ad9ad0eb7dd43b207fb"
     ]
    },
    "executionInfo": {
     "elapsed": 31261,
     "status": "ok",
     "timestamp": 1679776295183,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "eX1z4fpFgYUO",
    "outputId": "a8b51528-500e-415c-aed8-66c8a18959c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd66cddedd3d47e89df5dcc53a73dbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/376835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 376835\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# tokenize wikitext_dataset with pre-trained DistilGPT2 tokenizer\n",
    "def preprocess_function(examples):\n",
    "    text = [example for example in examples[\"text\"]]\n",
    "    \n",
    "    # tokenize wikitext_dataset with pre-trained DistilGPT2 tokenizer\n",
    "    inputs = gpt_tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "\n",
    "    return {\"input_ids\": inputs[\"input_ids\"], \n",
    "            \"attention_mask\": inputs[\"attention_mask\"]\n",
    "           }\n",
    "\n",
    "encoded_dataset = wikitext_dataset.map(preprocess_function, batched=True)\n",
    "print(encoded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "9a92a63b5a9b4f3a84f08fb8a5de4987",
      "bdf228e7055e4e019114b159e8bf9912",
      "68122b865a00489eae74822559e4d754",
      "8e2cd2971fd34a548df4f9aece362d4e",
      "46bcad369fd840e2b7274848cee11db3",
      "4f016364f544447297be9fc464d382a6",
      "d77c64dff27b4112a372ebe15542bb16",
      "3ad034e4646c458496f5da4b1a6dd1ca",
      "894dabca82e7402a954935a599e5b6cd",
      "ceaf042c8fdd4a61a8ba86b785d36fd4",
      "5e50e102e9784a358f8df4c3fcee1363",
      "23b66c18d7414a79b45081ce33a67b31",
      "041e02f29ce14d5d8437b6459d2218a6",
      "16f05dccd4764185910bfa3db8556039",
      "8d1716114dd64588ac0a839d12b5c4fc",
      "04f5f30cf97b48bba7e562530d3dba2b",
      "d832f3b3c4e540f1b46a1b9c98e063dc",
      "2eb9d5ba745444c2b01a1d129a1c93dd",
      "5415639928ca46b1811ededf0662170e",
      "101e56ca649c49618a25094068c446f2",
      "bb0bc2eceb9a4a45a8afe14dd99fb55b",
      "7af89a84b29f4480a20a2a2fe4465071"
     ]
    },
    "executionInfo": {
     "elapsed": 79886,
     "status": "ok",
     "timestamp": 1679776375055,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "lKNQqh0khuoS",
    "outputId": "c6ce1605-e024-4df4-f4a7-8d0b6eaf2133"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a92a63b5a9b4f3a84f08fb8a5de4987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/376835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b66c18d7414a79b45081ce33a67b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/376835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "# filter to big sentence\n",
    "encoded_dataset = encoded_dataset.filter(lambda example: len(example['input_ids']) <= MAX_SEQ_LENGTH)\n",
    "encoded_dataset = encoded_dataset.filter(lambda example: len(example['attention_mask']) <= MAX_SEQ_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1679776375056,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "fbTZ8ly_RS_H",
    "outputId": "554028fe-8f38-4200-e15f-e8b53896a0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 376835\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(encoded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "91dcd4ed6dc241d9b394dc4bd66bb5f4",
      "f9a16f34ff26474fa26f33163f8ff48a",
      "e7799365bdf54b45b4c4a5adbb959016",
      "2715fb4483914908beb82df8921e31bb",
      "29f08a9e2e9f4bce9dcf20d393332dfa",
      "d8abd8aaf25e4b56868cdfd9ae4e04bc",
      "03c730ff4a4b4866b9193ca71c114e16",
      "f4f5ef4b002348c48e5196a68790ad07",
      "8c1650f8ad8f447da0588e295c728045",
      "94b0cd13f0154c8285f0333e9bc2d225",
      "1f6ec5f510d74264ac8635d3b879f3ff"
     ]
    },
    "executionInfo": {
     "elapsed": 123537,
     "status": "ok",
     "timestamp": 1679776498564,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "wy7mnEJXRc1i",
    "outputId": "143d1551-e1ee-4cb8-9921-0c3094fe99f7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dcd4ed6dc241d9b394dc4bd66bb5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/376835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limited_encoded_dataset = encoded_dataset.remove_columns(\"text\")\n",
    "limited_encoded_dataset = limited_encoded_dataset.with_format(\"torch\")\n",
    "limited_encoded_dataset = limited_encoded_dataset.map(lambda example:\n",
    "                                                      {\"labels\": example[\"input_ids\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnTTvoyMiTAe"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  **Split** the `limited_encoded_dataset` into train and test subsets.\n",
    "    \n",
    "üíª API hint: Use `torch.utils.data.random_split` method with the given `TRAIN_RATIO`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1679776498565,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "mbv9vnLyiTAe"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "TRAIN_RATIO = 0.9\n",
    "dataset_length = len(limited_encoded_dataset)\n",
    "train_length = math.floor(dataset_length * TRAIN_RATIO)\n",
    "test_length = dataset_length - train_length\n",
    "\n",
    "transformer_train_dataset, transformer_test_dataset = torch.utils.data.random_split(limited_encoded_dataset,\n",
    "                                                               [train_length, test_length],\n",
    "                                                               generator=torch.Generator().manual_seed(student_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WydKF1tIiTAf"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Set hyperparameters according to the objective of the model.\n",
    "      \n",
    "üíª Implementation hint: You can play arround with different values for `learning_rate`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1679776498565,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "JV7Zq35AiTAf",
    "outputId": "3719c4e0-5cc1-4376-bc25-604ba89940b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-wikitext103\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=1e-4, # 1e-4\n",
    "    save_steps=10000,\n",
    "    weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1679776499091,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "4-RcdNj_UVnK",
    "outputId": "b9e26996-72b5-4815-f4a2-9dd289dda550"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1679776499091,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "T42R4xAwasvj",
    "outputId": "763d63b3-94fd-44cd-c71d-0f7ba19a7c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33915\n"
     ]
    }
   ],
   "source": [
    "print(len(subset_train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLOGX_LQiTAg"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **training** using the `Trainer` class on **10% of data**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1679776499091,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "fyBsdxwmo4E7",
    "outputId": "d1e8dfe2-142c-4870-fd89-7ad8fef0e0bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size subset train 37683\n",
      "size subset test 37683\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "# Using the Trainer class on 10% of data\n",
    "subset_size_train = int(len(transformer_train_dataset.dataset) * 0.1)\n",
    "subset_size_test = int(len(transformer_test_dataset.dataset) * 0.1)\n",
    "print('size subset train', subset_size_train)\n",
    "print('size subset test', subset_size_test)\n",
    "subset_train_dataset = Subset(transformer_train_dataset.dataset, range(subset_size_train))\n",
    "subset_test_dataset = Subset(transformer_test_dataset.dataset, range(subset_size_test))\n",
    "\n",
    "                                   \n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=gpt_tokenizer, mlm=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1679776499092,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Va4FrzNpbzOZ"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=gpt2_scratch_model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=subset_train_dataset,\n",
    "    eval_dataset=subset_test_dataset,\n",
    "    data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 970061,
     "status": "ok",
     "timestamp": 1679777469140,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "jS2JzesFSuzd",
    "outputId": "40616c08-6d84-43ad-8fc4-fc978ec9753c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14133' max='14133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14133/14133 16:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.186800</td>\n",
       "      <td>5.023031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.667100</td>\n",
       "      <td>4.492862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.420200</td>\n",
       "      <td>4.268138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14133, training_loss=5.045027810921801, metrics={'train_runtime': 969.8758, 'train_samples_per_second': 116.56, 'train_steps_per_second': 14.572, 'total_flos': 3692417044709376.0, 'train_loss': 5.045027810921801, 'epoch': 3.0})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 7894,
     "status": "ok",
     "timestamp": 1679777477010,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "W9gVEQ6nUvcp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), 'drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/models/distilgpt2-lm-from-scratch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZsEBG8RiTAg"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **testing** using the `Trainer` class and compute perplexity.\n",
    "\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "executionInfo": {
     "elapsed": 65997,
     "status": "ok",
     "timestamp": 1679777542995,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "HiuwHEY6iTAg",
    "outputId": "3e1203df-f7fb-454d-dec6-e35eceabbc77",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4711' max='4711' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4711/4711 01:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity on the test dataset is 71.389\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "perplexity_from_scratch = math.exp(eval_result[\"eval_loss\"])\n",
    "print(f\"The perplexity on the test dataset is {perplexity_from_scratch:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHzd5C0inhLP"
   },
   "source": [
    "### 2.2.2 Run Pre-trained GPT-2 model\n",
    "\n",
    "After training your trained-from-scratch Transformer model in the previous section, you will now use a pre-trained model to find its perplexity. Therefore, we will only perform testing of the pre-trained model on the test dataset. \n",
    "\n",
    "You will perform the following steps:\n",
    "\n",
    "1. Load pre-trained model and tokenizer\n",
    "2. Run testing and compute perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1679777542996,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "OJpB8U-1iTAh"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "model_id = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4Ei6aFliTAh"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Load pre-trained model and tokenizer.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "2b7381466c234026ae7b99aa3961cd9c",
      "d1db98d8d52d4dc0918d774d4da6d52c",
      "9c0e0299d5fa499aacccd4fb1ae51c33",
      "190b338d56a2454a85c20367cb6fe9f9",
      "11910d5cff404ab0a8e2492552b2fc37",
      "b490bf5a52884fe3ba6618c46312059b",
      "e1c80d6d37074d6dbedf80ca3cf0b331",
      "8370276c54514f698a504c63b350111b",
      "aaeb1ef2a5fa496a97d758ce8f98ed04",
      "df06a61db60942be821f0cd0ae5cecaa",
      "093cf631b27040e28e9c89ab46d3bd7e",
      "775d47ec05974438a9b5ab31cebe3849",
      "70eb2ca771034edbbc889ab6cb585066",
      "07dc570d3e4b49f1b525107ac4b41e0c",
      "f6d3904337de461f808fb6eb563fabaf",
      "443d65b0129a4de9907748cd8bf645d9",
      "32d86cc773254a3a90b96d4391d150f0",
      "9fe8b0418c08420d81972188e9041f2a",
      "d5042cf1c58c43c880157a640f93f6c6",
      "c811ae6922a644e1808a5ab947cddb4b",
      "dd52ab9bca9644849665112935f8cb57",
      "ea3255bb892c4fd3ba071646b9a9ded2"
     ]
    },
    "executionInfo": {
     "elapsed": 7799,
     "status": "ok",
     "timestamp": 1679777550771,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Yz53m57qiTAh",
    "outputId": "9bc6af53-0afe-43ea-f657-48d2c212bb37"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7381466c234026ae7b99aa3961cd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775d47ec05974438a9b5ab31cebe3849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "gpt2_pretrained_model = GPT2LMHeadModel.from_pretrained(model_id)\n",
    "tokenizer_pretrained_gpt = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "tokenizer_pretrained_gpt.pad_token = tokenizer_pretrained_gpt.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6TGvwLXiTAh"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Set hyperparameters to set up the Trainer.\n",
    "      \n",
    "üíª Implementation hint: We will use only the inference part on the trainer.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1679777550772,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "bHrdXr64iTAh",
    "outputId": "19dcd169-1faf-4ced-b843-3116be44fb7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"pretrained_{model_id}-wikitext103\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=1e-4, # 1e-4\n",
    "    save_steps=10000,\n",
    "    weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-hvHgXTiTAi"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **testing** using the `Trainer` class and compute perplexity.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1679777550772,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "_8n7jLG2iTAi"
   },
   "outputs": [],
   "source": [
    "pretrained_trainer = Trainer(\n",
    "    model=gpt2_pretrained_model,\n",
    "    tokenizer=tokenizer_pretrained_gpt,\n",
    "    args=training_args,\n",
    "    train_dataset=subset_train_dataset,\n",
    "    eval_dataset=subset_test_dataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "executionInfo": {
     "elapsed": 65982,
     "status": "ok",
     "timestamp": 1679777616734,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Rm_7YZY6iTAi",
    "outputId": "8fafddff-f26b-49f6-fe2a-03053d868c9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4711' max='4711' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4711/4711 01:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of pretrained distilgpt2 on the test dataset is 1025.211\n"
     ]
    }
   ],
   "source": [
    "eval_result = pretrained_trainer.evaluate()\n",
    "perplexity_pretrained_model = math.exp(eval_result[\"eval_loss\"])\n",
    "print(f\"The perplexity of pretrained {model_id} on the test dataset is {perplexity_pretrained_model:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FxdACC5iTAi"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #8e7cc3;background-color:#e4e1eb;border-radius: 15px;\">\n",
    "    \n",
    "üéâ  Excellent work! By this point, you will have implemented all language model variants.\n",
    "\n",
    "#### Part 2 - Checklist\n",
    "Here are the core building blocks you created and that you will need for Part 3:\n",
    "   \n",
    "- [X] LSTM-variants checkpoints.\n",
    "- [X] LSTM-variants ppl scores.\n",
    "- [X] Transformer-variants ppl scores.\n",
    "\n",
    "_Note: Don't forget to include the tensorboard log to every model you trained, as discussed in the `README.md` of `tensorboard/` dir._\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBdlJJKhiTAi"
   },
   "source": [
    "---\n",
    "\n",
    "<a name=\"3\"></a>\n",
    "# PART 3: Fine-tune on the Text Paraphrasing task üöÄ\n",
    "\n",
    "In this part, we will fine-tune and test the language models into the downstream task of text Paraphrasing. \n",
    "\n",
    "For this task, we will use the [MRPC dataset](https://paperswithcode.com/dataset/mrpc). Microsoft Research Paraphrase Corpus (MRPC) is a corpus consisting of 5,801 sentence pairs collected from newswire articles. Each pair is labeled if it is a paraphrase or not by human annotators. \n",
    "\n",
    " ![mrpc.png](docs/mrpc.png)\n",
    " \n",
    "## Models\n",
    "For this dataset, we will select only the ones that correspond to text paraphrasing (label 1). With those, we will test the model's ability to take as input a sentence and produce as output the paraphrased one. \n",
    "\n",
    "### Encoder-Decoder architectures: \n",
    "To create a sequence2sequence model, we will create an Encoder-decoder model with an attention mechanism similar to the week 3 exercises.\n",
    "\n",
    "More specifically you need to implement the following:\n",
    "- Preprocess the dataset to match with the format of the model's input.\n",
    "- Build a Encoder-Decoder model that will be trained from stratch on the text paraphrasing task.\n",
    "- Train and test your architectures and compute the train/validation loss score. \n",
    "\n",
    "### Transformer-based architectures:\n",
    "\n",
    "You will also run experiments with the pre-trained Transformer-based model as we did in Part 2. \n",
    "You will be using again DistilGPT2. More specifically you need to implement the following:\n",
    "\n",
    "- Preprocess the dataset to match with the format of the model's input.\n",
    "- Run training (fine-tuning) of the model on train dataset.\n",
    "- Run inference on the test set and compute evaluation scores (see section below).\n",
    "\n",
    "\n",
    "#### Evaluation for the Transformer model\n",
    "\n",
    "You will evaluate your model using ROUGE scores. \n",
    " \n",
    "**ROUGE score** stands for Recall-Oriented Understudy for Gisting Evaluation. In its simplest form ROUGE score is the quotient of the matching words under the total count of words in reference sentence. Regarding the denominator ROUGE is a recall oriented metric. \n",
    "\n",
    "![rouge.png](docs/rouge.png)\n",
    "\n",
    "**ROUGE-L score** is based on the length of the longest common subsequence (LCS). To counter the disadvantages of a pure recall metric as in ROUGE-N, Rouge-L calculates the weighted harmonic mean (or f-measure) combining the precision score and the recall score.\n",
    "\n",
    "![rouge_l.png](docs/rouge_l.png)\n",
    "\n",
    "‚ÑπÔ∏è Source: [Original article](https://clementbm.github.io/theory/2021/12/23/rouge-bleu-scores.html#bleu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679777649058,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "XDfqZGSfgYUR"
   },
   "outputs": [],
   "source": [
    "# import from \n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import torch\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, AutoConfig, AutoModelWithLMHead, AutoTokenizer, DataCollatorForLanguageModeling, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qanO0ZkaiTAj"
   },
   "source": [
    "### Load MPRC dataset and extract the paraphrased ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1679777652341,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "j0jmgYZoiTAj",
    "outputId": "cecfcb03-094b-460b-c53b-5ffe60d4c0b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341,
     "referenced_widgets": [
      "72d0be40054c4568b20def93d904fe66",
      "ddd72ad558e64394b477e6f314ce5bbb",
      "e522046cce434e198e0ae262132f3f53",
      "b4cfb51252474948988e1100abdacf75",
      "9bf67e4a4d7a47df93a0b316ddcfae34",
      "504961da5c9844659036ad1a24b98c16",
      "20f433a29a284865bf234e79f5f926c3",
      "e0b571b073544ae182f7cf4efebba467",
      "acba259ea98c4b639adc6c30b1b9340d",
      "d1ce602eb9d74ac4996b7e61d2357844",
      "8d6e773857b143878e5d05b5c1568f9c",
      "c80dfc0d40f9443993143b47de53e984",
      "0dded6b545e14eb4a9d441ebfc6e331e",
      "58545776e58c4a7a9752effc1029c1ff",
      "57f6811666e74233bbcf48ab16885f90",
      "07017a06aa1140c0a9a2db743fe76aed",
      "05505a1c65304e608ca944d83950bf0d",
      "5f43cfbcc5f1461fb96a15b29c3b60bc",
      "a5c209686e3b405399a8855dd613d313",
      "d11939b1dbe1474f84e1d49fb0157a3f",
      "c2bd7c75cf53485292f39d0d9794ef94",
      "3932e020ec5c46b09d5e2acba02223ce",
      "624c612fccb34273ad36df8b738eea21",
      "caf421ee1b8c471baad792aec46f75ae",
      "9ed6e022175e45c8875711b21eee8f80",
      "ea3ac92843d44d1fb7ae7d0db3b17ced",
      "00303f3b5eb642ca96dee5196fa82489",
      "2c52bbd685b2457b859ce0b4c27ae288",
      "10cb4c999372484bb28f3397b1a9806c",
      "48b9e0b65e0b4a1099d111879792ef66",
      "7862597a6bf844b78ebc7e64022465f6",
      "a5fad3e160cb4aa8b61e1c4c215e8c50",
      "9cea5b99e3984744a614fa4c1e3c624d",
      "699b57b1d1ce43bfaa87ffa2a5fe709b",
      "20fd3a9af7314b08bf59c8a422fb603d",
      "182421ad5d544e12a02673d22f7499ee",
      "e034e99fc9bb4acf91f03fb60c14f9a3",
      "5542143e39fb4c398b4088580d7e7b02",
      "8d4a81f615f84e34bdfc8e883d9b3ad5",
      "228cfb3e6fdd40caa23f04d974a1b145",
      "95cb5a5a3523483aaea6022f548aa40f",
      "182b49967a454692bc614989118b84a8",
      "0b92055fd2bd4ca3945d847741d95e62",
      "5f3af597f68b416f904ed62233234618",
      "6b914a276c96421caa1ee399d88cc8b8",
      "bbfef9b72d3547078ecc1913dc776a99",
      "30818c7714644f3688237bb1dc98b4a6",
      "9018140e08b748a6b6d562cd07b08f6f",
      "be9a9eb1653b440b95075b90472c386f",
      "1d275dfc9f5b43d094bea2716a6fd455",
      "d4f17bdb8d4446048c88e14d2eeb4005",
      "41c0179fa990483a9cfe9364f22327c5",
      "18a6c7f63c1840888da3131f6a0ef3d3",
      "120864e1d96044c19cf2b7241f6c6fd5",
      "fdfdef15fba14fc8b1de6be5a4102551",
      "993bb92f553c4e11b74d47ddca8e9589",
      "9209400e060e46b7bda62b1a1abad130",
      "6ae6781844f24a0fa9248a22ab24db9d",
      "495fd2e8fe3f43cb951bf0c3c71b827d",
      "2681f0949b8c4259ba5ab56ff6ef0262",
      "373cf10fe18c4d50905154af83d9da1e",
      "20ccbbc80c474b6ba6b147ccb50d09df",
      "6954f0417b314a7d9d8984916f7142ab",
      "df7f50924c1c4ab3b5b0aed3dc2a2a5b",
      "557455c75dcb45a3af137e3ca20678f8",
      "ee7b27dab5f74bd99711d5795750f475",
      "8f72ad693c6e4d10b785e03a3573cba0",
      "352c0b1c4b8549e8babaf43a80e18a7d",
      "2d44d9b820e24f83bcef5555d2118d24",
      "a4e6af89d9484947b355354aa3bfaafd",
      "08176ef25535404b9fd86ec94f7381fc",
      "a8872aad0eb74a69b844d25ebe837dd6",
      "f0862d5095944af590bd5aa71c5b387e",
      "008f1118b8914fe0ba200ba98bb26c60",
      "c95b3fbaae7345e1a4388dc08e68809d",
      "7e184120eb3641199839d92d0f3b162c",
      "90dd72f801664a5c9d6af2c226633901",
      "f1028afdc7cc4b7bbe33a0a0d1043709",
      "a24911b97ac949489acbd63c096a15e5",
      "0746bf21395f4abe90e1be6a661595ab",
      "3d4131f818b74d72b70df45e123f6f76",
      "8ec47cfb489f45aa85057c9bb81cc604",
      "f18eb88af966417f96fd072b2507d733",
      "493c80b2eb564e6ab395070cdfb7b9df",
      "91370081c1fb4f129d039caba0cded07",
      "cdcc404b59674569aafc39e67d59a3d3",
      "547907ef4b524d05bada8899de8ac6f4",
      "48037d1853704a218c29fe3d968b9125",
      "56822f615b6e4915b94d2815f2758368",
      "a9ee8d0b6d6141898e120ebc0b00021b",
      "0a1eeae86ae54c78a723c58cdea576bb",
      "87a11f30c7484191ae7a1698962b3c67",
      "e3228a15b1fe45d097d64bab4833d436",
      "be94de40583f4b7f86061963e5b51a3d",
      "97d8d8118ca549d2b36ee5c5c0ee1951",
      "8da0d4d6d82f411395c95bd690023033",
      "1f5de3ccc7ba4623b2ef063154b02300",
      "d02748d235714e8fa8b3ab22946b76b7",
      "dd6cc51ba53442c08942dc3905f3427a",
      "f7455262e99145c681c3a58a5337e35a",
      "d03414a496d04b2a88f080b8d3ebf37c",
      "c3796f02e26d4cec9c6802f4d2330900",
      "18e3f6478edf4b77af4990f9411b5537",
      "a2bac6fdf03542ec8ad2d005d6dddd8a",
      "d1311b6927fd482ea0c3501ea5a61f6b",
      "6e359a8a789c467d9a03846c49739289",
      "0d8a67089196469a83f7bcdde14c8412",
      "990b0b0d9870455c909f08ae059d59b4",
      "27a9473197c14b1baa40c09f64c81d79",
      "1361606a5cab482ba39184673b9fe630",
      "4866868572564274a6ccd2d93e3533bc",
      "258c6e115e3843d1a223383a74d0b350",
      "a52ffa78c2674d66bffdd1bfd4c13dc2",
      "ac4c4fc5275944e7aa917c13a07e582f",
      "ef6f933eb4834b2d91397a964e8837e1",
      "b3ed0b0ee84f44b18d9a722d9b867acd",
      "8fb81826c5834968a8c9f4e21325e034",
      "0821c106a3c04946853af2b673871de7",
      "3fa112814133476390761f42fd5d8146",
      "4202ec836ebb45569c769b25899ad1bb",
      "e398a278f8f645c3ac99e20d435f8da2"
     ]
    },
    "executionInfo": {
     "elapsed": 10325,
     "status": "ok",
     "timestamp": 1679777663099,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "CSMYsGCfiTAk",
    "outputId": "9ad7e47b-1103-4cf7-db0b-23c29d1f3dcf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d0be40054c4568b20def93d904fe66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80dfc0d40f9443993143b47de53e984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624c612fccb34273ad36df8b738eea21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/mrpc to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699b57b1d1ce43bfaa87ffa2a5fe709b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b914a276c96421caa1ee399d88cc8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993bb92f553c4e11b74d47ddca8e9589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f72ad693c6e4d10b785e03a3573cba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1028afdc7cc4b7bbe33a0a0d1043709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56822f615b6e4915b94d2815f2758368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7455262e99145c681c3a58a5337e35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4866868572564274a6ccd2d93e3533bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset\n",
    "mrpc_dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "MAX_SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1M57YPoiTAk"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Keep only the **paraphrased pair** of sentences.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1679777663100,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "JVjicww_iTAk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "mrpc_dataset = mrpc_dataset.remove_columns(['label','idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1679777663101,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "6zvuUJTSgYUT",
    "outputId": "0df08d77-e3fa-4ce2-aed4-80aa95d29367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrpc_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFpqFEzMiTAk"
   },
   "source": [
    "<a name=\"31\"></a>\n",
    "## 3.1 Train Encoder-Decoder models on Text Paraphrasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVaWIpbWiTAk"
   },
   "source": [
    "In this part, you will preprocess the dataset to make it suitable for the Encoder-Decoder model by adding `<start>` and `<stop>` tokens on each sentences and then padding to the maximum sequence length. From now on, we will refer to sentence 1 as context and sentence 2 as reference. Finally, you will compute the train/validation loss score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMwsM3auiTAk"
   },
   "source": [
    "### Data Preprocessing for encoder-decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx7Wnw_TiTAk"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Add  `<start>` and `<stop>` tokens and pad the input to `MAX_SEQ_LENGTH` length.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1679777667309,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "4iRwgSEMgYUX"
   },
   "outputs": [],
   "source": [
    "# define the special tokens\n",
    "START_token = '<start>'\n",
    "STOP_token = '<stop>'\n",
    "PAD_token = '<pad>'\n",
    "MAX_SEQ_LENGTH = 64\n",
    "rnn_word_to_idx = rnn_dataset.word_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679777668578,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "u7LHqOJogYUX"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# tokenize and add special tokens to each sentence in the dataset\n",
    "def tokenize_sentence(sentence, word_to_idx):\n",
    "    tokenized = []\n",
    "    for token in sentence.split():\n",
    "        if token in word_to_idx:\n",
    "            tokenized.append(word_to_idx[token])\n",
    "        else:\n",
    "            tokenized.append(word_to_idx['<unk>'])\n",
    "    \n",
    "    if len(tokenized) > MAX_SEQ_LENGTH:\n",
    "        # if the sentence is too long, truncate it and add the special tokens\n",
    "        tokenized = tokenized[:MAX_SEQ_LENGTH]\n",
    "        tokenized = [word_to_idx[START_token]] + tokenized + [word_to_idx[STOP_token]]\n",
    "    else:\n",
    "        # if the sentence is shorter than the maximum length, pad it and add the special tokens\n",
    "        padding = [word_to_idx[PAD_token]] * (MAX_SEQ_LENGTH - len(tokenized))\n",
    "        tokenized = [word_to_idx[START_token]] + tokenized + [word_to_idx[STOP_token]] + padding\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1679777671704,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "qUOmtjnPgYUX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## tokenizing the texts in the mrpc\n",
    "\n",
    "train_tokenized_sentence1 = []\n",
    "train_tokenized_sentence2 = []\n",
    "val_tokenized_sentence1 = []\n",
    "val_tokenized_sentence2 = []\n",
    "test_tokenized_sentence1 = []\n",
    "test_tokenized_sentence2 = []\n",
    "\n",
    "# tokenize the sentences in the dataset\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for i in range(len(mrpc_dataset[split])):\n",
    "        # print(i, split)\n",
    "        \n",
    "        sentence1 = mrpc_dataset[split][i]['sentence1'] \n",
    "        sentence2 = mrpc_dataset[split][i]['sentence2']\n",
    "        \n",
    "        if split == 'train':\n",
    "            tokenized_sentence1 = tokenize_sentence(sentence1, rnn_word_to_idx)\n",
    "            train_tokenized_sentence1.append(tokenized_sentence1)\n",
    "            train_tokenized_sentence2.append(tokenize_sentence(sentence2, rnn_word_to_idx))\n",
    "            #print(f'Tokenized sentence 1: {tokenized_sentence1}')\n",
    "\n",
    "        elif split == 'validation':\n",
    "            val_tokenized_sentence1.append(tokenize_sentence(sentence1, rnn_word_to_idx))\n",
    "            val_tokenized_sentence2.append(tokenize_sentence(sentence2, rnn_word_to_idx))\n",
    "        \n",
    "        elif split == 'test':\n",
    "            test_tokenized_sentence1.append(tokenize_sentence(sentence1, rnn_word_to_idx))\n",
    "            test_tokenized_sentence2.append(tokenize_sentence(sentence2, rnn_word_to_idx))\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 2153,
     "status": "ok",
     "timestamp": 1679777675638,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "h_zsTkaGgYUX"
   },
   "outputs": [],
   "source": [
    "for split in mrpc_dataset.keys():\n",
    "    if split == 'train':\n",
    "        mrpc_dataset[split] = mrpc_dataset[split].add_column('context', train_tokenized_sentence1)\n",
    "        mrpc_dataset[split] = mrpc_dataset[split].add_column('text_target', train_tokenized_sentence2)\n",
    "    elif split == 'validation':\n",
    "        mrpc_dataset[split] = mrpc_dataset[split].add_column('context', val_tokenized_sentence1)\n",
    "        mrpc_dataset[split] = mrpc_dataset[split].add_column('text_target', val_tokenized_sentence2)\n",
    "    elif split == 'test':\n",
    "        mrpc_dataset[split] = mrpc_dataset[split].add_column('context', test_tokenized_sentence1)\n",
    "        mrpc_dataset[split] = mrpc_dataset[split].add_column('text_target', test_tokenized_sentence2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1679777680851,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "lv1G-Pf7iTAl"
   },
   "outputs": [],
   "source": [
    "mrpc_dataset = mrpc_dataset.remove_columns([\"sentence1\", \"sentence2\"])\n",
    "mrpc_dataset = mrpc_dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1679777681933,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "5Xj_5kHoiTAl"
   },
   "outputs": [],
   "source": [
    "mrpc_train, mrpc_validation, mrpc_test = mrpc_dataset[\"train\"], mrpc_dataset[\"validation\"], mrpc_dataset[\"test\"]\n",
    "\n",
    "mrpc_train_dataloader = DataLoader(mrpc_train, batch_size=8, shuffle=True)\n",
    "mrpc_validation_dataloader = DataLoader(mrpc_validation, batch_size=8, shuffle=False)\n",
    "mrpc_test_dataloader = DataLoader(mrpc_test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xQLggBjiTAl"
   },
   "source": [
    "### Run model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "aborted",
     "timestamp": 1679776166159,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "EQYokthFiTAl"
   },
   "outputs": [],
   "source": [
    "# import your end-dec model\n",
    "from src.utils import EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1679777693592,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "0pjwyTw_gYUY"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kO08RQdCiTAm"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal:  Implement training and testing pipelines.\n",
    "  \n",
    "üíª Implementation hint: Check the pipelines we created in the exercises sessions.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1679777877626,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "iFlZLtgqgYUZ"
   },
   "outputs": [],
   "source": [
    "def seq2seq_train(model, train_loader, eval_loader, optimizer, criterion, num_epoch, device):\n",
    "    \n",
    "    best_eval_loss = 1e3 # used to do early stopping\n",
    "    print('device', device)\n",
    "    # Training loop\n",
    "    for epoch in range(num_epoch):\n",
    "        print('epoch', epoch)\n",
    "        running_loss = 0\n",
    "        epoch_loss = 0\n",
    "        for i, data in (enumerate(tqdm(train_loader, desc='Training '), 0)):\n",
    "            \n",
    "            running_loss = 0\n",
    "            # context, text_target = data\n",
    "            context = data['context']\n",
    "            text_target = data['text_target']\n",
    "            # print('Batch',i, context.shape, text_target.shape)\n",
    "\n",
    "            context = context.to(device) \n",
    "            text_target = text_target.to(device) \n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            optimizer.zero_grad()\n",
    "            decoder_outputs = model(context, text_target)\n",
    "            # print('output',decoder_outputs.shape)\n",
    "            \n",
    "            # transpose to have [Batch, vocab_size, seq_lenght]: [8, 83883, 66]\n",
    "            running_loss = criterion(decoder_outputs.transpose(1, 2), text_target)\n",
    "            epoch_loss += running_loss\n",
    "\n",
    "\n",
    "            running_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            training_step = i\n",
    "            train_loss = running_loss\n",
    "            tb_writer.add_scalar(\"LSTM_seq2seq_attention/train_loss\", train_loss, training_step)\n",
    "            \n",
    "    print('loss', epoch_loss)\n",
    "\n",
    "    return epoch_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1679777715841,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "zwyWEq8ZgYUa"
   },
   "outputs": [],
   "source": [
    "def seq2seq_eval(model, eval_loader, criterion,  device):\n",
    "    # this function should be called in the train loop to monitor the performance in validation set while training.\n",
    "    \n",
    "    running_loss = 0\n",
    "    epoch_loss = 0\n",
    "    for i, data in (enumerate(eval_loader)):\n",
    "        # YOUR CODE HERE\n",
    "        context = data['context'].to(device)\n",
    "        text_target = data['text_target'].to(device)\n",
    "        decoder_outputs = model(context, text_target)\n",
    "        \n",
    "        running_loss = criterion(decoder_outputs.transpose(1, 2), text_target)\n",
    "        epoch_loss += running_loss\n",
    "\n",
    "        validation_loss = running_loss\n",
    "        training_step = i\n",
    "        tb_writer.add_scalar(\"LSTM_seq2seq_attention/validation_loss\", validation_loss, training_step)\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3glI_f1iTAn"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Instantiate the **model, optimizer and loss**.\n",
    "      \n",
    "üíª Implementation hint: Choose your training settings according to the task you need to do.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1679777722907,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "PM69YsT9iTAn",
    "outputId": "a3f0c9f6-3ace-4559-877a-54754fdb1917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name: cuda\n",
      "The model has 25,403,349 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device name:', device)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "seq2seq_with_attention_model = EncoderDecoder(hidden_size = 100 , vocab_size = len(rnn_word_to_idx), device=device)\n",
    "optimizer = optim.AdamW(seq2seq_with_attention_model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "criterion = nn.NLLLoss()\n",
    "num_params = sum(p.numel() for p in seq2seq_with_attention_model.parameters() if p.requires_grad)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh2RofH6iTAn"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **training and testing pipelines**.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1085159,
     "status": "ok",
     "timestamp": 1679778969751,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "ONqeXDy3iTAn",
    "outputId": "6f89858a-686a-47ba-ef6c-79fc10f7c9f0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training :   0%|          | 0/459 [00:00<?, ?it/s]\u001b[A\n",
      "Training :   0%|          | 1/459 [00:00<01:46,  4.29it/s]\u001b[A\n",
      "Training :   0%|          | 2/459 [00:00<01:45,  4.32it/s]\u001b[A\n",
      "Training :   1%|          | 3/459 [00:00<01:45,  4.32it/s]\u001b[A\n",
      "Training :   1%|          | 4/459 [00:00<01:45,  4.32it/s]\u001b[A\n",
      "Training :   1%|          | 5/459 [00:01<01:45,  4.31it/s]\u001b[A\n",
      "Training :   1%|‚ñè         | 6/459 [00:01<01:45,  4.29it/s]\u001b[A\n",
      "Training :   2%|‚ñè         | 7/459 [00:01<01:45,  4.29it/s]\u001b[A\n",
      "Training :   2%|‚ñè         | 8/459 [00:01<01:45,  4.29it/s]\u001b[A\n",
      "Training :   2%|‚ñè         | 9/459 [00:02<01:45,  4.26it/s]\u001b[A\n",
      "Training :   2%|‚ñè         | 10/459 [00:02<01:45,  4.26it/s]\u001b[A\n",
      "Training :   2%|‚ñè         | 11/459 [00:02<01:45,  4.26it/s]\u001b[A\n",
      "Training :   3%|‚ñé         | 12/459 [00:02<01:44,  4.27it/s]\u001b[A\n",
      "Training :   3%|‚ñé         | 13/459 [00:03<01:46,  4.19it/s]\u001b[A\n",
      "Training :   3%|‚ñé         | 14/459 [00:03<01:45,  4.21it/s]\u001b[A\n",
      "Training :   3%|‚ñé         | 15/459 [00:03<01:45,  4.22it/s]\u001b[A\n",
      "Training :   3%|‚ñé         | 16/459 [00:03<01:44,  4.22it/s]\u001b[A\n",
      "Training :   4%|‚ñé         | 17/459 [00:03<01:44,  4.23it/s]\u001b[A\n",
      "Training :   4%|‚ñç         | 18/459 [00:04<01:45,  4.19it/s]\u001b[A\n",
      "Training :   4%|‚ñç         | 19/459 [00:04<01:45,  4.19it/s]\u001b[A\n",
      "Training :   4%|‚ñç         | 20/459 [00:04<01:44,  4.20it/s]\u001b[A\n",
      "Training :   5%|‚ñç         | 21/459 [00:04<01:44,  4.20it/s]\u001b[A\n",
      "Training :   5%|‚ñç         | 22/459 [00:05<01:44,  4.20it/s]\u001b[A\n",
      "Training :   5%|‚ñå         | 23/459 [00:05<01:44,  4.19it/s]\u001b[A\n",
      "Training :   5%|‚ñå         | 24/459 [00:05<01:43,  4.21it/s]\u001b[A\n",
      "Training :   5%|‚ñå         | 25/459 [00:05<01:42,  4.25it/s]\u001b[A\n",
      "Training :   6%|‚ñå         | 26/459 [00:06<01:41,  4.25it/s]\u001b[A\n",
      "Training :   6%|‚ñå         | 27/459 [00:06<01:41,  4.24it/s]\u001b[A\n",
      "Training :   6%|‚ñå         | 28/459 [00:06<01:40,  4.28it/s]\u001b[A\n",
      "Training :   6%|‚ñã         | 29/459 [00:06<01:40,  4.27it/s]\u001b[A\n",
      "Training :   7%|‚ñã         | 30/459 [00:07<01:39,  4.30it/s]\u001b[A\n",
      "Training :   7%|‚ñã         | 31/459 [00:07<01:39,  4.31it/s]\u001b[A\n",
      "Training :   7%|‚ñã         | 32/459 [00:07<01:39,  4.29it/s]\u001b[A\n",
      "Training :   7%|‚ñã         | 33/459 [00:07<01:39,  4.29it/s]\u001b[A\n",
      "Training :   7%|‚ñã         | 34/459 [00:07<01:39,  4.29it/s]\u001b[A\n",
      "Training :   8%|‚ñä         | 35/459 [00:08<01:38,  4.30it/s]\u001b[A\n",
      "Training :   8%|‚ñä         | 36/459 [00:08<01:38,  4.29it/s]\u001b[A\n",
      "Training :   8%|‚ñä         | 37/459 [00:08<01:38,  4.28it/s]\u001b[A\n",
      "Training :   8%|‚ñä         | 38/459 [00:08<01:38,  4.27it/s]\u001b[A\n",
      "Training :   8%|‚ñä         | 39/459 [00:09<01:38,  4.26it/s]\u001b[A\n",
      "Training :   9%|‚ñä         | 40/459 [00:09<01:37,  4.29it/s]\u001b[A\n",
      "Training :   9%|‚ñâ         | 41/459 [00:09<01:37,  4.29it/s]\u001b[A\n",
      "Training :   9%|‚ñâ         | 42/459 [00:09<01:37,  4.30it/s]\u001b[A\n",
      "Training :   9%|‚ñâ         | 43/459 [00:10<01:36,  4.29it/s]\u001b[A\n",
      "Training :  10%|‚ñâ         | 44/459 [00:10<01:36,  4.28it/s]\u001b[A\n",
      "Training :  10%|‚ñâ         | 45/459 [00:10<01:36,  4.30it/s]\u001b[A\n",
      "Training :  10%|‚ñà         | 46/459 [00:10<01:35,  4.32it/s]\u001b[A\n",
      "Training :  10%|‚ñà         | 47/459 [00:11<01:34,  4.34it/s]\u001b[A\n",
      "Training :  10%|‚ñà         | 48/459 [00:11<01:35,  4.33it/s]\u001b[A\n",
      "Training :  11%|‚ñà         | 49/459 [00:11<01:34,  4.33it/s]\u001b[A\n",
      "Training :  11%|‚ñà         | 50/459 [00:11<01:34,  4.33it/s]\u001b[A\n",
      "Training :  11%|‚ñà         | 51/459 [00:11<01:33,  4.34it/s]\u001b[A\n",
      "Training :  11%|‚ñà‚ñè        | 52/459 [00:12<01:33,  4.36it/s]\u001b[A\n",
      "Training :  12%|‚ñà‚ñè        | 53/459 [00:12<01:33,  4.36it/s]\u001b[A\n",
      "Training :  12%|‚ñà‚ñè        | 54/459 [00:12<01:32,  4.36it/s]\u001b[A\n",
      "Training :  12%|‚ñà‚ñè        | 55/459 [00:12<01:32,  4.36it/s]\u001b[A\n",
      "Training :  12%|‚ñà‚ñè        | 56/459 [00:13<01:32,  4.35it/s]\u001b[A\n",
      "Training :  12%|‚ñà‚ñè        | 57/459 [00:13<01:32,  4.36it/s]\u001b[A\n",
      "Training :  13%|‚ñà‚ñé        | 58/459 [00:13<01:32,  4.34it/s]\u001b[A\n",
      "Training :  13%|‚ñà‚ñé        | 59/459 [00:13<01:32,  4.34it/s]\u001b[A\n",
      "Training :  13%|‚ñà‚ñé        | 60/459 [00:14<01:31,  4.35it/s]\u001b[A\n",
      "Training :  13%|‚ñà‚ñé        | 61/459 [00:14<01:31,  4.35it/s]\u001b[A\n",
      "Training :  14%|‚ñà‚ñé        | 62/459 [00:14<01:31,  4.34it/s]\u001b[A\n",
      "Training :  14%|‚ñà‚ñé        | 63/459 [00:14<01:31,  4.33it/s]\u001b[A\n",
      "Training :  14%|‚ñà‚ñç        | 64/459 [00:14<01:31,  4.33it/s]\u001b[A\n",
      "Training :  14%|‚ñà‚ñç        | 65/459 [00:15<01:31,  4.32it/s]\u001b[A\n",
      "Training :  14%|‚ñà‚ñç        | 66/459 [00:15<01:31,  4.31it/s]\u001b[A\n",
      "Training :  15%|‚ñà‚ñç        | 67/459 [00:15<01:31,  4.30it/s]\u001b[A\n",
      "Training :  15%|‚ñà‚ñç        | 68/459 [00:15<01:30,  4.30it/s]\u001b[A\n",
      "Training :  15%|‚ñà‚ñå        | 69/459 [00:16<01:31,  4.28it/s]\u001b[A\n",
      "Training :  15%|‚ñà‚ñå        | 70/459 [00:16<01:30,  4.28it/s]\u001b[A\n",
      "Training :  15%|‚ñà‚ñå        | 71/459 [00:16<01:30,  4.29it/s]\u001b[A\n",
      "Training :  16%|‚ñà‚ñå        | 72/459 [00:16<01:30,  4.30it/s]\u001b[A\n",
      "Training :  16%|‚ñà‚ñå        | 73/459 [00:17<01:29,  4.30it/s]\u001b[A\n",
      "Training :  16%|‚ñà‚ñå        | 74/459 [00:17<01:29,  4.31it/s]\u001b[A\n",
      "Training :  16%|‚ñà‚ñã        | 75/459 [00:17<01:29,  4.31it/s]\u001b[A\n",
      "Training :  17%|‚ñà‚ñã        | 76/459 [00:17<01:30,  4.25it/s]\u001b[A\n",
      "Training :  17%|‚ñà‚ñã        | 77/459 [00:17<01:29,  4.25it/s]\u001b[A\n",
      "Training :  17%|‚ñà‚ñã        | 78/459 [00:18<01:29,  4.24it/s]\u001b[A\n",
      "Training :  17%|‚ñà‚ñã        | 79/459 [00:18<01:29,  4.24it/s]\u001b[A\n",
      "Training :  17%|‚ñà‚ñã        | 80/459 [00:18<01:28,  4.26it/s]\u001b[A\n",
      "Training :  18%|‚ñà‚ñä        | 81/459 [00:18<01:28,  4.29it/s]\u001b[A\n",
      "Training :  18%|‚ñà‚ñä        | 82/459 [00:19<01:27,  4.31it/s]\u001b[A\n",
      "Training :  18%|‚ñà‚ñä        | 83/459 [00:19<01:27,  4.32it/s]\u001b[A\n",
      "Training :  18%|‚ñà‚ñä        | 84/459 [00:19<01:27,  4.31it/s]\u001b[A\n",
      "Training :  19%|‚ñà‚ñä        | 85/459 [00:19<01:26,  4.32it/s]\u001b[A\n",
      "Training :  19%|‚ñà‚ñä        | 86/459 [00:20<01:26,  4.31it/s]\u001b[A\n",
      "Training :  19%|‚ñà‚ñâ        | 87/459 [00:20<01:26,  4.30it/s]\u001b[A\n",
      "Training :  19%|‚ñà‚ñâ        | 88/459 [00:20<01:27,  4.25it/s]\u001b[A\n",
      "Training :  19%|‚ñà‚ñâ        | 89/459 [00:20<01:26,  4.27it/s]\u001b[A\n",
      "Training :  20%|‚ñà‚ñâ        | 90/459 [00:20<01:26,  4.28it/s]\u001b[A\n",
      "Training :  20%|‚ñà‚ñâ        | 91/459 [00:21<01:25,  4.29it/s]\u001b[A\n",
      "Training :  20%|‚ñà‚ñà        | 92/459 [00:21<01:27,  4.21it/s]\u001b[A\n",
      "Training :  20%|‚ñà‚ñà        | 93/459 [00:21<01:26,  4.24it/s]\u001b[A\n",
      "Training :  20%|‚ñà‚ñà        | 94/459 [00:21<01:26,  4.24it/s]\u001b[A\n",
      "Training :  21%|‚ñà‚ñà        | 95/459 [00:22<01:25,  4.24it/s]\u001b[A\n",
      "Training :  21%|‚ñà‚ñà        | 96/459 [00:22<01:25,  4.23it/s]\u001b[A\n",
      "Training :  21%|‚ñà‚ñà        | 97/459 [00:22<01:26,  4.19it/s]\u001b[A\n",
      "Training :  21%|‚ñà‚ñà‚ñè       | 98/459 [00:22<01:26,  4.20it/s]\u001b[A\n",
      "Training :  22%|‚ñà‚ñà‚ñè       | 99/459 [00:23<01:25,  4.20it/s]\u001b[A\n",
      "Training :  22%|‚ñà‚ñà‚ñè       | 100/459 [00:23<01:25,  4.20it/s]\u001b[A\n",
      "Training :  22%|‚ñà‚ñà‚ñè       | 101/459 [00:23<01:25,  4.20it/s]\u001b[A\n",
      "Training :  22%|‚ñà‚ñà‚ñè       | 102/459 [00:23<01:25,  4.19it/s]\u001b[A\n",
      "Training :  22%|‚ñà‚ñà‚ñè       | 103/459 [00:24<01:24,  4.20it/s]\u001b[A\n",
      "Training :  23%|‚ñà‚ñà‚ñé       | 104/459 [00:24<01:24,  4.19it/s]\u001b[A\n",
      "Training :  23%|‚ñà‚ñà‚ñé       | 105/459 [00:24<01:24,  4.19it/s]\u001b[A\n",
      "Training :  23%|‚ñà‚ñà‚ñé       | 106/459 [00:24<01:24,  4.20it/s]\u001b[A\n",
      "Training :  23%|‚ñà‚ñà‚ñé       | 107/459 [00:25<01:23,  4.22it/s]\u001b[A\n",
      "Training :  24%|‚ñà‚ñà‚ñé       | 108/459 [00:25<01:22,  4.23it/s]\u001b[A\n",
      "Training :  24%|‚ñà‚ñà‚ñé       | 109/459 [00:25<01:22,  4.25it/s]\u001b[A\n",
      "Training :  24%|‚ñà‚ñà‚ñç       | 110/459 [00:25<01:22,  4.25it/s]\u001b[A\n",
      "Training :  24%|‚ñà‚ñà‚ñç       | 111/459 [00:25<01:21,  4.27it/s]\u001b[A\n",
      "Training :  24%|‚ñà‚ñà‚ñç       | 112/459 [00:26<01:21,  4.27it/s]\u001b[A\n",
      "Training :  25%|‚ñà‚ñà‚ñç       | 113/459 [00:26<01:21,  4.27it/s]\u001b[A\n",
      "Training :  25%|‚ñà‚ñà‚ñç       | 114/459 [00:26<01:20,  4.26it/s]\u001b[A\n",
      "Training :  25%|‚ñà‚ñà‚ñå       | 115/459 [00:26<01:20,  4.25it/s]\u001b[A\n",
      "Training :  25%|‚ñà‚ñà‚ñå       | 116/459 [00:27<01:20,  4.26it/s]\u001b[A\n",
      "Training :  25%|‚ñà‚ñà‚ñå       | 117/459 [00:27<01:20,  4.26it/s]\u001b[A\n",
      "Training :  26%|‚ñà‚ñà‚ñå       | 118/459 [00:27<01:19,  4.29it/s]\u001b[A\n",
      "Training :  26%|‚ñà‚ñà‚ñå       | 119/459 [00:27<01:18,  4.30it/s]\u001b[A\n",
      "Training :  26%|‚ñà‚ñà‚ñå       | 120/459 [00:28<01:18,  4.31it/s]\u001b[A\n",
      "Training :  26%|‚ñà‚ñà‚ñã       | 121/459 [00:28<01:18,  4.33it/s]\u001b[A\n",
      "Training :  27%|‚ñà‚ñà‚ñã       | 122/459 [00:28<01:17,  4.34it/s]\u001b[A\n",
      "Training :  27%|‚ñà‚ñà‚ñã       | 123/459 [00:28<01:18,  4.26it/s]\u001b[A\n",
      "Training :  27%|‚ñà‚ñà‚ñã       | 124/459 [00:29<01:18,  4.25it/s]\u001b[A\n",
      "Training :  27%|‚ñà‚ñà‚ñã       | 125/459 [00:29<01:18,  4.27it/s]\u001b[A\n",
      "Training :  27%|‚ñà‚ñà‚ñã       | 126/459 [00:29<01:18,  4.27it/s]\u001b[A\n",
      "Training :  28%|‚ñà‚ñà‚ñä       | 127/459 [00:29<01:18,  4.22it/s]\u001b[A\n",
      "Training :  28%|‚ñà‚ñà‚ñä       | 128/459 [00:29<01:18,  4.22it/s]\u001b[A\n",
      "Training :  28%|‚ñà‚ñà‚ñä       | 129/459 [00:30<01:18,  4.22it/s]\u001b[A\n",
      "Training :  28%|‚ñà‚ñà‚ñä       | 130/459 [00:30<01:17,  4.22it/s]\u001b[A\n",
      "Training :  29%|‚ñà‚ñà‚ñä       | 131/459 [00:30<01:18,  4.20it/s]\u001b[A\n",
      "Training :  29%|‚ñà‚ñà‚ñâ       | 132/459 [00:30<01:17,  4.21it/s]\u001b[A\n",
      "Training :  29%|‚ñà‚ñà‚ñâ       | 133/459 [00:31<01:17,  4.19it/s]\u001b[A\n",
      "Training :  29%|‚ñà‚ñà‚ñâ       | 134/459 [00:31<01:17,  4.21it/s]\u001b[A\n",
      "Training :  29%|‚ñà‚ñà‚ñâ       | 135/459 [00:31<01:17,  4.17it/s]\u001b[A\n",
      "Training :  30%|‚ñà‚ñà‚ñâ       | 136/459 [00:31<01:17,  4.19it/s]\u001b[A\n",
      "Training :  30%|‚ñà‚ñà‚ñâ       | 137/459 [00:32<01:16,  4.20it/s]\u001b[A\n",
      "Training :  30%|‚ñà‚ñà‚ñà       | 138/459 [00:32<01:16,  4.22it/s]\u001b[A\n",
      "Training :  30%|‚ñà‚ñà‚ñà       | 139/459 [00:32<01:15,  4.24it/s]\u001b[A\n",
      "Training :  31%|‚ñà‚ñà‚ñà       | 140/459 [00:32<01:15,  4.24it/s]\u001b[A\n",
      "Training :  31%|‚ñà‚ñà‚ñà       | 141/459 [00:33<01:14,  4.26it/s]\u001b[A\n",
      "Training :  31%|‚ñà‚ñà‚ñà       | 142/459 [00:33<01:14,  4.27it/s]\u001b[A\n",
      "Training :  31%|‚ñà‚ñà‚ñà       | 143/459 [00:33<01:13,  4.29it/s]\u001b[A\n",
      "Training :  31%|‚ñà‚ñà‚ñà‚ñè      | 144/459 [00:33<01:13,  4.29it/s]\u001b[A\n",
      "Training :  32%|‚ñà‚ñà‚ñà‚ñè      | 145/459 [00:33<01:13,  4.27it/s]\u001b[A\n",
      "Training :  32%|‚ñà‚ñà‚ñà‚ñè      | 146/459 [00:34<01:13,  4.24it/s]\u001b[A\n",
      "Training :  32%|‚ñà‚ñà‚ñà‚ñè      | 147/459 [00:34<01:13,  4.27it/s]\u001b[A\n",
      "Training :  32%|‚ñà‚ñà‚ñà‚ñè      | 148/459 [00:34<01:12,  4.28it/s]\u001b[A\n",
      "Training :  32%|‚ñà‚ñà‚ñà‚ñè      | 149/459 [00:34<01:12,  4.27it/s]\u001b[A\n",
      "Training :  33%|‚ñà‚ñà‚ñà‚ñé      | 150/459 [00:35<01:11,  4.30it/s]\u001b[A\n",
      "Training :  33%|‚ñà‚ñà‚ñà‚ñé      | 151/459 [00:35<01:11,  4.31it/s]\u001b[A\n",
      "Training :  33%|‚ñà‚ñà‚ñà‚ñé      | 152/459 [00:35<01:11,  4.32it/s]\u001b[A\n",
      "Training :  33%|‚ñà‚ñà‚ñà‚ñé      | 153/459 [00:35<01:11,  4.30it/s]\u001b[A\n",
      "Training :  34%|‚ñà‚ñà‚ñà‚ñé      | 154/459 [00:36<01:10,  4.32it/s]\u001b[A\n",
      "Training :  34%|‚ñà‚ñà‚ñà‚ñç      | 155/459 [00:36<01:10,  4.29it/s]\u001b[A\n",
      "Training :  34%|‚ñà‚ñà‚ñà‚ñç      | 156/459 [00:36<01:10,  4.32it/s]\u001b[A\n",
      "Training :  34%|‚ñà‚ñà‚ñà‚ñç      | 157/459 [00:36<01:09,  4.32it/s]\u001b[A\n",
      "Training :  34%|‚ñà‚ñà‚ñà‚ñç      | 158/459 [00:36<01:09,  4.33it/s]\u001b[A\n",
      "Training :  35%|‚ñà‚ñà‚ñà‚ñç      | 159/459 [00:37<01:09,  4.32it/s]\u001b[A\n",
      "Training :  35%|‚ñà‚ñà‚ñà‚ñç      | 160/459 [00:37<01:08,  4.33it/s]\u001b[A\n",
      "Training :  35%|‚ñà‚ñà‚ñà‚ñå      | 161/459 [00:37<01:09,  4.30it/s]\u001b[A\n",
      "Training :  35%|‚ñà‚ñà‚ñà‚ñå      | 162/459 [00:37<01:09,  4.28it/s]\u001b[A\n",
      "Training :  36%|‚ñà‚ñà‚ñà‚ñå      | 163/459 [00:38<01:09,  4.29it/s]\u001b[A\n",
      "Training :  36%|‚ñà‚ñà‚ñà‚ñå      | 164/459 [00:38<01:08,  4.28it/s]\u001b[A\n",
      "Training :  36%|‚ñà‚ñà‚ñà‚ñå      | 165/459 [00:38<01:08,  4.28it/s]\u001b[A\n",
      "Training :  36%|‚ñà‚ñà‚ñà‚ñå      | 166/459 [00:38<01:08,  4.28it/s]\u001b[A\n",
      "Training :  36%|‚ñà‚ñà‚ñà‚ñã      | 167/459 [00:39<01:08,  4.26it/s]\u001b[A\n",
      "Training :  37%|‚ñà‚ñà‚ñà‚ñã      | 168/459 [00:39<01:08,  4.24it/s]\u001b[A\n",
      "Training :  37%|‚ñà‚ñà‚ñà‚ñã      | 169/459 [00:39<01:08,  4.25it/s]\u001b[A\n",
      "Training :  37%|‚ñà‚ñà‚ñà‚ñã      | 170/459 [00:39<01:07,  4.26it/s]\u001b[A\n",
      "Training :  37%|‚ñà‚ñà‚ñà‚ñã      | 171/459 [00:40<01:07,  4.26it/s]\u001b[A\n",
      "Training :  37%|‚ñà‚ñà‚ñà‚ñã      | 172/459 [00:40<01:07,  4.27it/s]\u001b[A\n",
      "Training :  38%|‚ñà‚ñà‚ñà‚ñä      | 173/459 [00:40<01:07,  4.27it/s]\u001b[A\n",
      "Training :  38%|‚ñà‚ñà‚ñà‚ñä      | 174/459 [00:40<01:06,  4.26it/s]\u001b[A\n",
      "Training :  38%|‚ñà‚ñà‚ñà‚ñä      | 175/459 [00:40<01:06,  4.27it/s]\u001b[A\n",
      "Training :  38%|‚ñà‚ñà‚ñà‚ñä      | 176/459 [00:41<01:06,  4.25it/s]\u001b[A\n",
      "Training :  39%|‚ñà‚ñà‚ñà‚ñä      | 177/459 [00:41<01:06,  4.26it/s]\u001b[A\n",
      "Training :  39%|‚ñà‚ñà‚ñà‚ñâ      | 178/459 [00:41<01:05,  4.26it/s]\u001b[A\n",
      "Training :  39%|‚ñà‚ñà‚ñà‚ñâ      | 179/459 [00:41<01:05,  4.27it/s]\u001b[A\n",
      "Training :  39%|‚ñà‚ñà‚ñà‚ñâ      | 180/459 [00:42<01:05,  4.23it/s]\u001b[A\n",
      "Training :  39%|‚ñà‚ñà‚ñà‚ñâ      | 181/459 [00:42<01:05,  4.24it/s]\u001b[A\n",
      "Training :  40%|‚ñà‚ñà‚ñà‚ñâ      | 182/459 [00:42<01:05,  4.24it/s]\u001b[A\n",
      "Training :  40%|‚ñà‚ñà‚ñà‚ñâ      | 183/459 [00:42<01:04,  4.25it/s]\u001b[A\n",
      "Training :  40%|‚ñà‚ñà‚ñà‚ñà      | 184/459 [00:43<01:04,  4.25it/s]\u001b[A\n",
      "Training :  40%|‚ñà‚ñà‚ñà‚ñà      | 185/459 [00:43<01:04,  4.26it/s]\u001b[A\n",
      "Training :  41%|‚ñà‚ñà‚ñà‚ñà      | 186/459 [00:43<01:03,  4.27it/s]\u001b[A\n",
      "Training :  41%|‚ñà‚ñà‚ñà‚ñà      | 187/459 [00:43<01:03,  4.28it/s]\u001b[A\n",
      "Training :  41%|‚ñà‚ñà‚ñà‚ñà      | 188/459 [00:44<01:03,  4.27it/s]\u001b[A\n",
      "Training :  41%|‚ñà‚ñà‚ñà‚ñà      | 189/459 [00:44<01:03,  4.22it/s]\u001b[A\n",
      "Training :  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 190/459 [00:44<01:03,  4.20it/s]\u001b[A\n",
      "Training :  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 191/459 [00:44<01:03,  4.21it/s]\u001b[A\n",
      "Training :  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 192/459 [00:45<01:04,  4.14it/s]\u001b[A\n",
      "Training :  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 193/459 [00:45<01:03,  4.17it/s]\u001b[A\n",
      "Training :  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 194/459 [00:45<01:03,  4.20it/s]\u001b[A\n",
      "Training :  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 195/459 [00:45<01:02,  4.23it/s]\u001b[A\n",
      "Training :  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 196/459 [00:45<01:01,  4.25it/s]\u001b[A\n",
      "Training :  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 197/459 [00:46<01:01,  4.25it/s]\u001b[A\n",
      "Training :  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 198/459 [00:46<01:01,  4.26it/s]\u001b[A\n",
      "Training :  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 199/459 [00:46<01:00,  4.29it/s]\u001b[A\n",
      "Training :  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 200/459 [00:46<01:00,  4.29it/s]\u001b[A\n",
      "Training :  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 201/459 [00:47<01:01,  4.23it/s]\u001b[A\n",
      "Training :  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 202/459 [00:47<01:00,  4.24it/s]\u001b[A\n",
      "Training :  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 203/459 [00:47<01:01,  4.17it/s]\u001b[A\n",
      "Training :  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 204/459 [00:47<01:01,  4.14it/s]\u001b[A\n",
      "Training :  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 205/459 [00:48<01:00,  4.16it/s]\u001b[A\n",
      "Training :  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 206/459 [00:48<01:01,  4.14it/s]\u001b[A\n",
      "Training :  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 207/459 [00:48<01:01,  4.10it/s]\u001b[A\n",
      "Training :  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 208/459 [00:48<01:00,  4.16it/s]\u001b[A\n",
      "Training :  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 209/459 [00:49<00:59,  4.18it/s]\u001b[A\n",
      "Training :  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 210/459 [00:49<00:59,  4.19it/s]\u001b[A\n",
      "Training :  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 211/459 [00:49<00:59,  4.20it/s]\u001b[A\n",
      "Training :  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 212/459 [00:49<00:58,  4.20it/s]\u001b[A\n",
      "Training :  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 213/459 [00:49<00:58,  4.19it/s]\u001b[A\n",
      "Training :  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 214/459 [00:50<00:58,  4.19it/s]\u001b[A\n",
      "Training :  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 215/459 [00:50<00:58,  4.20it/s]\u001b[A\n",
      "Training :  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 216/459 [00:50<00:57,  4.20it/s]\u001b[A\n",
      "Training :  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 217/459 [00:50<00:57,  4.21it/s]\u001b[A\n",
      "Training :  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 218/459 [00:51<00:57,  4.18it/s]\u001b[A\n",
      "Training :  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 219/459 [00:51<00:57,  4.19it/s]\u001b[A\n",
      "Training :  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 220/459 [00:51<00:56,  4.21it/s]\u001b[A\n",
      "Training :  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 221/459 [00:51<00:56,  4.21it/s]\u001b[A\n",
      "Training :  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 222/459 [00:52<00:56,  4.21it/s]\u001b[A\n",
      "Training :  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 223/459 [00:52<00:56,  4.21it/s]\u001b[A\n",
      "Training :  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 224/459 [00:52<00:56,  4.20it/s]\u001b[A\n",
      "Training :  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 225/459 [00:52<00:55,  4.23it/s]\u001b[A\n",
      "Training :  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 226/459 [00:53<00:55,  4.21it/s]\u001b[A\n",
      "Training :  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 227/459 [00:53<00:54,  4.24it/s]\u001b[A\n",
      "Training :  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 228/459 [00:53<00:54,  4.25it/s]\u001b[A\n",
      "Training :  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 229/459 [00:53<00:53,  4.26it/s]\u001b[A\n",
      "Training :  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 230/459 [00:54<00:53,  4.25it/s]\u001b[A\n",
      "Training :  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 231/459 [00:54<00:54,  4.19it/s]\u001b[A\n",
      "Training :  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 232/459 [00:54<00:53,  4.22it/s]\u001b[A\n",
      "Training :  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 233/459 [00:54<00:53,  4.21it/s]\u001b[A\n",
      "Training :  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 234/459 [00:54<00:53,  4.22it/s]\u001b[A\n",
      "Training :  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 235/459 [00:55<00:53,  4.18it/s]\u001b[A\n",
      "Training :  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 236/459 [00:55<00:54,  4.13it/s]\u001b[A\n",
      "Training :  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 237/459 [00:55<00:53,  4.15it/s]\u001b[A\n",
      "Training :  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 238/459 [00:55<00:53,  4.14it/s]\u001b[A\n",
      "Training :  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 239/459 [00:56<00:53,  4.14it/s]\u001b[A\n",
      "Training :  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 240/459 [00:56<00:53,  4.09it/s]\u001b[A\n",
      "Training :  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 241/459 [00:56<00:53,  4.11it/s]\u001b[A\n",
      "Training :  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 242/459 [00:56<00:52,  4.13it/s]\u001b[A\n",
      "Training :  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 243/459 [00:57<00:51,  4.16it/s]\u001b[A\n",
      "Training :  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 244/459 [00:57<00:51,  4.17it/s]\u001b[A\n",
      "Training :  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 245/459 [00:57<00:51,  4.17it/s]\u001b[A\n",
      "Training :  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 246/459 [00:57<00:51,  4.17it/s]\u001b[A\n",
      "Training :  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 247/459 [00:58<00:50,  4.18it/s]\u001b[A\n",
      "Training :  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 248/459 [00:58<00:51,  4.12it/s]\u001b[A\n",
      "Training :  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 249/459 [00:58<00:51,  4.08it/s]\u001b[A\n",
      "Training :  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 250/459 [00:58<00:50,  4.11it/s]\u001b[A\n",
      "Training :  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 251/459 [00:59<00:50,  4.16it/s]\u001b[A\n",
      "Training :  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 252/459 [00:59<00:49,  4.20it/s]\u001b[A\n",
      "Training :  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 253/459 [00:59<00:48,  4.23it/s]\u001b[A\n",
      "Training :  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 254/459 [00:59<00:48,  4.26it/s]\u001b[A\n",
      "Training :  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 255/459 [01:00<00:47,  4.27it/s]\u001b[A\n",
      "Training :  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 256/459 [01:00<00:47,  4.27it/s]\u001b[A\n",
      "Training :  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 257/459 [01:00<00:47,  4.27it/s]\u001b[A\n",
      "Training :  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 258/459 [01:00<00:47,  4.26it/s]\u001b[A\n",
      "Training :  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 259/459 [01:00<00:46,  4.27it/s]\u001b[A\n",
      "Training :  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 260/459 [01:01<00:46,  4.25it/s]\u001b[A\n",
      "Training :  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 261/459 [01:01<00:46,  4.22it/s]\u001b[A\n",
      "Training :  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 262/459 [01:01<00:46,  4.23it/s]\u001b[A\n",
      "Training :  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 263/459 [01:01<00:46,  4.25it/s]\u001b[A\n",
      "Training :  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 264/459 [01:02<00:45,  4.26it/s]\u001b[A\n",
      "Training :  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 265/459 [01:02<00:45,  4.27it/s]\u001b[A\n",
      "Training :  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 266/459 [01:02<00:45,  4.29it/s]\u001b[A\n",
      "Training :  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 267/459 [01:02<00:44,  4.29it/s]\u001b[A\n",
      "Training :  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 268/459 [01:03<00:44,  4.27it/s]\u001b[A\n",
      "Training :  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 269/459 [01:03<00:44,  4.26it/s]\u001b[A\n",
      "Training :  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 270/459 [01:03<00:44,  4.27it/s]\u001b[A\n",
      "Training :  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 271/459 [01:03<00:43,  4.28it/s]\u001b[A\n",
      "Training :  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 272/459 [01:04<00:43,  4.27it/s]\u001b[A\n",
      "Training :  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 273/459 [01:04<00:43,  4.26it/s]\u001b[A\n",
      "Training :  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 274/459 [01:04<00:43,  4.25it/s]\u001b[A\n",
      "Training :  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 275/459 [01:04<00:43,  4.23it/s]\u001b[A\n",
      "Training :  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 276/459 [01:04<00:43,  4.24it/s]\u001b[A\n",
      "Training :  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 277/459 [01:05<00:42,  4.23it/s]\u001b[A\n",
      "Training :  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 278/459 [01:05<00:42,  4.23it/s]\u001b[A\n",
      "Training :  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 279/459 [01:05<00:42,  4.22it/s]\u001b[A\n",
      "Training :  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 280/459 [01:05<00:42,  4.23it/s]\u001b[A\n",
      "Training :  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 281/459 [01:06<00:42,  4.23it/s]\u001b[A\n",
      "Training :  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 282/459 [01:06<00:41,  4.23it/s]\u001b[A\n",
      "Training :  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 283/459 [01:06<00:41,  4.23it/s]\u001b[A\n",
      "Training :  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 284/459 [01:06<00:41,  4.24it/s]\u001b[A\n",
      "Training :  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 285/459 [01:07<00:40,  4.25it/s]\u001b[A\n",
      "Training :  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 286/459 [01:07<00:40,  4.26it/s]\u001b[A\n",
      "Training :  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 287/459 [01:07<00:40,  4.24it/s]\u001b[A\n",
      "Training :  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 288/459 [01:07<00:40,  4.24it/s]\u001b[A\n",
      "Training :  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 289/459 [01:08<00:40,  4.24it/s]\u001b[A\n",
      "Training :  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 290/459 [01:08<00:39,  4.25it/s]\u001b[A\n",
      "Training :  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 291/459 [01:08<00:39,  4.25it/s]\u001b[A\n",
      "Training :  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 292/459 [01:08<00:39,  4.25it/s]\u001b[A\n",
      "Training :  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 293/459 [01:08<00:39,  4.24it/s]\u001b[A\n",
      "Training :  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 294/459 [01:09<00:38,  4.24it/s]\u001b[A\n",
      "Training :  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 295/459 [01:09<00:38,  4.24it/s]\u001b[A\n",
      "Training :  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 296/459 [01:09<00:38,  4.24it/s]\u001b[A\n",
      "Training :  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 297/459 [01:09<00:38,  4.25it/s]\u001b[A\n",
      "Training :  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 298/459 [01:10<00:37,  4.26it/s]\u001b[A\n",
      "Training :  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 299/459 [01:10<00:37,  4.25it/s]\u001b[A\n",
      "Training :  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 300/459 [01:10<00:37,  4.25it/s]\u001b[A\n",
      "Training :  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 301/459 [01:10<00:37,  4.24it/s]\u001b[A\n",
      "Training :  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 302/459 [01:11<00:37,  4.23it/s]\u001b[A\n",
      "Training :  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 303/459 [01:11<00:36,  4.24it/s]\u001b[A\n",
      "Training :  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 304/459 [01:11<00:36,  4.23it/s]\u001b[A\n",
      "Training :  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 305/459 [01:11<00:36,  4.21it/s]\u001b[A\n",
      "Training :  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 306/459 [01:12<00:36,  4.22it/s]\u001b[A\n",
      "Training :  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 307/459 [01:12<00:35,  4.25it/s]\u001b[A\n",
      "Training :  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 308/459 [01:12<00:35,  4.27it/s]\u001b[A\n",
      "Training :  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 309/459 [01:12<00:35,  4.20it/s]\u001b[A\n",
      "Training :  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 310/459 [01:12<00:35,  4.21it/s]\u001b[A\n",
      "Training :  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 311/459 [01:13<00:34,  4.24it/s]\u001b[A\n",
      "Training :  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 312/459 [01:13<00:34,  4.26it/s]\u001b[A\n",
      "Training :  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 313/459 [01:13<00:34,  4.25it/s]\u001b[A\n",
      "Training :  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 314/459 [01:13<00:34,  4.26it/s]\u001b[A\n",
      "Training :  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 315/459 [01:14<00:33,  4.25it/s]\u001b[A\n",
      "Training :  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 316/459 [01:14<00:33,  4.27it/s]\u001b[A\n",
      "Training :  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 317/459 [01:14<00:33,  4.28it/s]\u001b[A\n",
      "Training :  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 318/459 [01:14<00:33,  4.27it/s]\u001b[A\n",
      "Training :  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 319/459 [01:15<00:32,  4.29it/s]\u001b[A\n",
      "Training :  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 320/459 [01:15<00:32,  4.31it/s]\u001b[A\n",
      "Training :  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 321/459 [01:15<00:31,  4.33it/s]\u001b[A\n",
      "Training :  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 322/459 [01:15<00:31,  4.34it/s]\u001b[A\n",
      "Training :  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 323/459 [01:15<00:31,  4.35it/s]\u001b[A\n",
      "Training :  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 324/459 [01:16<00:31,  4.35it/s]\u001b[A\n",
      "Training :  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 325/459 [01:16<00:30,  4.32it/s]\u001b[A\n",
      "Training :  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 326/459 [01:16<00:30,  4.32it/s]\u001b[A\n",
      "Training :  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 327/459 [01:16<00:30,  4.34it/s]\u001b[A\n",
      "Training :  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 328/459 [01:17<00:30,  4.32it/s]\u001b[A\n",
      "Training :  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 329/459 [01:17<00:29,  4.35it/s]\u001b[A\n",
      "Training :  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 330/459 [01:17<00:29,  4.35it/s]\u001b[A\n",
      "Training :  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 331/459 [01:17<00:29,  4.36it/s]\u001b[A\n",
      "Training :  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 332/459 [01:18<00:29,  4.35it/s]\u001b[A\n",
      "Training :  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 333/459 [01:18<00:29,  4.33it/s]\u001b[A\n",
      "Training :  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 334/459 [01:18<00:28,  4.33it/s]\u001b[A\n",
      "Training :  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 335/459 [01:18<00:28,  4.31it/s]\u001b[A\n",
      "Training :  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 336/459 [01:19<00:28,  4.30it/s]\u001b[A\n",
      "Training :  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 337/459 [01:19<00:28,  4.30it/s]\u001b[A\n",
      "Training :  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 338/459 [01:19<00:28,  4.32it/s]\u001b[A\n",
      "Training :  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 339/459 [01:19<00:27,  4.31it/s]\u001b[A\n",
      "Training :  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 340/459 [01:19<00:28,  4.23it/s]\u001b[A\n",
      "Training :  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 341/459 [01:20<00:27,  4.24it/s]\u001b[A\n",
      "Training :  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 342/459 [01:20<00:27,  4.26it/s]\u001b[A\n",
      "Training :  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 343/459 [01:20<00:27,  4.27it/s]\u001b[A\n",
      "Training :  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 344/459 [01:20<00:27,  4.23it/s]\u001b[A\n",
      "Training :  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 345/459 [01:21<00:26,  4.26it/s]\u001b[A\n",
      "Training :  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 346/459 [01:21<00:26,  4.27it/s]\u001b[A\n",
      "Training :  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 347/459 [01:21<00:26,  4.28it/s]\u001b[A\n",
      "Training :  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 348/459 [01:21<00:25,  4.30it/s]\u001b[A\n",
      "Training :  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 349/459 [01:22<00:25,  4.30it/s]\u001b[A\n",
      "Training :  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 350/459 [01:22<00:25,  4.24it/s]\u001b[A\n",
      "Training :  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 351/459 [01:22<00:25,  4.25it/s]\u001b[A\n",
      "Training :  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 352/459 [01:22<00:25,  4.26it/s]\u001b[A\n",
      "Training :  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 353/459 [01:22<00:24,  4.28it/s]\u001b[A\n",
      "Training :  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 354/459 [01:23<00:24,  4.28it/s]\u001b[A\n",
      "Training :  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 355/459 [01:23<00:24,  4.30it/s]\u001b[A\n",
      "Training :  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 356/459 [01:23<00:23,  4.29it/s]\u001b[A\n",
      "Training :  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 357/459 [01:23<00:23,  4.27it/s]\u001b[A\n",
      "Training :  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 358/459 [01:24<00:23,  4.27it/s]\u001b[A\n",
      "Training :  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 359/459 [01:24<00:23,  4.26it/s]\u001b[A\n",
      "Training :  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 360/459 [01:24<00:23,  4.28it/s]\u001b[A\n",
      "Training :  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 361/459 [01:24<00:22,  4.26it/s]\u001b[A\n",
      "Training :  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 362/459 [01:25<00:23,  4.16it/s]\u001b[A\n",
      "Training :  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 363/459 [01:25<00:23,  4.14it/s]\u001b[A\n",
      "Training :  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 364/459 [01:25<00:22,  4.18it/s]\u001b[A\n",
      "Training :  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 365/459 [01:25<00:22,  4.21it/s]\u001b[A\n",
      "Training :  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 366/459 [01:26<00:22,  4.21it/s]\u001b[A\n",
      "Training :  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 367/459 [01:26<00:21,  4.24it/s]\u001b[A\n",
      "Training :  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 368/459 [01:26<00:21,  4.24it/s]\u001b[A\n",
      "Training :  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 369/459 [01:26<00:21,  4.25it/s]\u001b[A\n",
      "Training :  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 370/459 [01:27<00:21,  4.23it/s]\u001b[A\n",
      "Training :  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 371/459 [01:27<00:20,  4.25it/s]\u001b[A\n",
      "Training :  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 372/459 [01:27<00:20,  4.26it/s]\u001b[A\n",
      "Training :  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 373/459 [01:27<00:20,  4.27it/s]\u001b[A\n",
      "Training :  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 374/459 [01:28<00:26,  3.16it/s]\u001b[A\n",
      "Training :  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 375/459 [01:28<00:24,  3.44it/s]\u001b[A\n",
      "Training :  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 376/459 [01:28<00:22,  3.65it/s]\u001b[A\n",
      "Training :  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 377/459 [01:28<00:21,  3.81it/s]\u001b[A\n",
      "Training :  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 378/459 [01:29<00:20,  3.92it/s]\u001b[A\n",
      "Training :  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 379/459 [01:29<00:20,  3.99it/s]\u001b[A\n",
      "Training :  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 380/459 [01:29<00:19,  4.07it/s]\u001b[A\n",
      "Training :  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 381/459 [01:29<00:18,  4.13it/s]\u001b[A\n",
      "Training :  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 382/459 [01:30<00:18,  4.16it/s]\u001b[A\n",
      "Training :  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 383/459 [01:30<00:18,  4.19it/s]\u001b[A\n",
      "Training :  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 384/459 [01:30<00:17,  4.19it/s]\u001b[A\n",
      "Training :  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 385/459 [01:30<00:17,  4.20it/s]\u001b[A\n",
      "Training :  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 386/459 [01:31<00:17,  4.23it/s]\u001b[A\n",
      "Training :  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 387/459 [01:31<00:16,  4.26it/s]\u001b[A\n",
      "Training :  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 388/459 [01:31<00:16,  4.29it/s]\u001b[A\n",
      "Training :  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 389/459 [01:31<00:16,  4.28it/s]\u001b[A\n",
      "Training :  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 390/459 [01:31<00:16,  4.28it/s]\u001b[A\n",
      "Training :  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 391/459 [01:32<00:15,  4.31it/s]\u001b[A\n",
      "Training :  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 392/459 [01:32<00:15,  4.31it/s]\u001b[A\n",
      "Training :  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 393/459 [01:32<00:15,  4.33it/s]\u001b[A\n",
      "Training :  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 394/459 [01:32<00:14,  4.33it/s]\u001b[A\n",
      "Training :  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 395/459 [01:33<00:14,  4.34it/s]\u001b[A\n",
      "Training :  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 396/459 [01:33<00:14,  4.32it/s]\u001b[A\n",
      "Training :  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 397/459 [01:33<00:14,  4.31it/s]\u001b[A\n",
      "Training :  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 398/459 [01:33<00:14,  4.32it/s]\u001b[A\n",
      "Training :  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 399/459 [01:34<00:13,  4.31it/s]\u001b[A\n",
      "Training :  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 400/459 [01:34<00:13,  4.33it/s]\u001b[A\n",
      "Training :  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 401/459 [01:34<00:13,  4.34it/s]\u001b[A\n",
      "Training :  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 402/459 [01:34<00:13,  4.34it/s]\u001b[A\n",
      "Training :  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 403/459 [01:34<00:12,  4.31it/s]\u001b[A\n",
      "Training :  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 404/459 [01:35<00:12,  4.30it/s]\u001b[A\n",
      "Training :  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 405/459 [01:35<00:12,  4.29it/s]\u001b[A\n",
      "Training :  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 406/459 [01:35<00:12,  4.24it/s]\u001b[A\n",
      "Training :  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 407/459 [01:35<00:12,  4.23it/s]\u001b[A\n",
      "Training :  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 408/459 [01:36<00:12,  4.20it/s]\u001b[A\n",
      "Training :  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 409/459 [01:36<00:11,  4.21it/s]\u001b[A\n",
      "Training :  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 410/459 [01:36<00:11,  4.20it/s]\u001b[A\n",
      "Training :  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 411/459 [01:36<00:11,  4.23it/s]\u001b[A\n",
      "Training :  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 412/459 [01:37<00:11,  4.23it/s]\u001b[A\n",
      "Training :  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 413/459 [01:37<00:10,  4.20it/s]\u001b[A\n",
      "Training :  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 414/459 [01:37<00:10,  4.19it/s]\u001b[A\n",
      "Training :  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 415/459 [01:37<00:10,  4.18it/s]\u001b[A\n",
      "Training :  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 416/459 [01:38<00:10,  4.17it/s]\u001b[A\n",
      "Training :  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 417/459 [01:38<00:10,  4.11it/s]\u001b[A\n",
      "Training :  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 418/459 [01:38<00:10,  4.09it/s]\u001b[A\n",
      "Training :  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 419/459 [01:38<00:09,  4.15it/s]\u001b[A\n",
      "Training :  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 420/459 [01:39<00:09,  4.17it/s]\u001b[A\n",
      "Training :  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 421/459 [01:39<00:09,  4.20it/s]\u001b[A\n",
      "Training :  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 422/459 [01:39<00:08,  4.23it/s]\u001b[A\n",
      "Training :  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 423/459 [01:39<00:08,  4.25it/s]\u001b[A\n",
      "Training :  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 424/459 [01:39<00:08,  4.24it/s]\u001b[A\n",
      "Training :  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 425/459 [01:40<00:07,  4.25it/s]\u001b[A\n",
      "Training :  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 426/459 [01:40<00:07,  4.26it/s]\u001b[A\n",
      "Training :  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 427/459 [01:40<00:07,  4.28it/s]\u001b[A\n",
      "Training :  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 428/459 [01:40<00:07,  4.28it/s]\u001b[A\n",
      "Training :  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 429/459 [01:41<00:07,  4.26it/s]\u001b[A\n",
      "Training :  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 430/459 [01:41<00:06,  4.27it/s]\u001b[A\n",
      "Training :  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 431/459 [01:41<00:06,  4.29it/s]\u001b[A\n",
      "Training :  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 432/459 [01:41<00:06,  4.28it/s]\u001b[A\n",
      "Training :  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 433/459 [01:42<00:06,  4.29it/s]\u001b[A\n",
      "Training :  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 434/459 [01:42<00:05,  4.25it/s]\u001b[A\n",
      "Training :  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 435/459 [01:42<00:05,  4.25it/s]\u001b[A\n",
      "Training :  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 436/459 [01:42<00:05,  4.28it/s]\u001b[A\n",
      "Training :  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 437/459 [01:43<00:05,  4.30it/s]\u001b[A\n",
      "Training :  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 438/459 [01:43<00:04,  4.29it/s]\u001b[A\n",
      "Training :  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 439/459 [01:43<00:04,  4.29it/s]\u001b[A\n",
      "Training :  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 440/459 [01:43<00:04,  4.31it/s]\u001b[A\n",
      "Training :  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 441/459 [01:43<00:04,  4.32it/s]\u001b[A\n",
      "Training :  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 442/459 [01:44<00:03,  4.33it/s]\u001b[A\n",
      "Training :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 443/459 [01:44<00:03,  4.32it/s]\u001b[A\n",
      "Training :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 444/459 [01:44<00:03,  4.31it/s]\u001b[A\n",
      "Training :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 445/459 [01:44<00:03,  4.30it/s]\u001b[A\n",
      "Training :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 446/459 [01:45<00:03,  4.32it/s]\u001b[A\n",
      "Training :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 447/459 [01:45<00:02,  4.32it/s]\u001b[A\n",
      "Training :  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 448/459 [01:45<00:02,  4.26it/s]\u001b[A\n",
      "Training :  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 449/459 [01:45<00:02,  4.27it/s]\u001b[A\n",
      "Training :  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 450/459 [01:46<00:02,  4.26it/s]\u001b[A\n",
      "Training :  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 451/459 [01:46<00:01,  4.23it/s]\u001b[A\n",
      "Training :  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 452/459 [01:46<00:01,  4.18it/s]\u001b[A\n",
      "Training :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 453/459 [01:46<00:01,  4.21it/s]\u001b[A\n",
      "Training :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 454/459 [01:46<00:01,  4.23it/s]\u001b[A\n",
      "Training :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 455/459 [01:47<00:00,  4.25it/s]\u001b[A\n",
      "Training :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 456/459 [01:47<00:00,  4.28it/s]\u001b[A\n",
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 457/459 [01:47<00:00,  4.27it/s]\u001b[A\n",
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 458/459 [01:47<00:00,  4.27it/s]\u001b[A\n",
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:48<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:46<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459/459 [01:47<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(825.3700, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seq2seq_train(model=seq2seq_with_attention_model.to(device), \n",
    "              train_loader=mrpc_train_dataloader,\n",
    "              eval_loader=mrpc_test_dataloader,\n",
    "              optimizer=optimizer, \n",
    "              criterion=nn.NLLLoss(),\n",
    "              num_epoch=10,\n",
    "              device=device)\n",
    "# saving the model\n",
    "torch.save(seq2seq_with_attention_model.state_dict(), \"drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/models/rnn_seq2seq_with_attention.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1679778969752,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "KOwQcaAbXuhv"
   },
   "outputs": [],
   "source": [
    "torch.save(seq2seq_with_attention_model.state_dict(), \"drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/models/rnn_seq2seq_with_attention.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W06_v7iiTAo"
   },
   "source": [
    "<a name=\"32\"></a>\n",
    "## 3.2 Run Transformer on Text Paraphrasing\n",
    "\n",
    "In this part you will need to concatinate the paraphrased pair of sentences into one sequence to serve as input. Then we will use this input to pass it to the DistilGPT2 model for fine-tuning and testing.\n",
    "The input should be the following:\n",
    "```\n",
    "<sentence_1> <eos> <sentence_2> <eos>\n",
    "```\n",
    "where `<eos>` is the tokenizer's end-of-sequence token.\n",
    "\n",
    "From now on, we will refer to sentence 1 as `context` and sentence 2 as `reference`. \n",
    "\n",
    "Here, we use a decoder-only model (DistilGPT2) which gets the **context** as input and generates the **reference** sequence (token-by-token). Given this token-by-token generation, the nature of the model is very similar to a language model; the major difference is that in general causal language models try to predict the next token for the whole input, whereas in this case, the model should generate only the **reference**. (i.e., the **context** should be masked for loss computation).  \n",
    "\n",
    "Finally, you will compute the ROUGE scores as follows:\n",
    "\n",
    "1. You will generate 5 sequences given each context.\n",
    "2. You will compute the ROUGE-L score among these 5 generations and the **context** => `ROUGE(context, generationX)`\n",
    "3. You will select the best generation (among the 5 ones) as the predicted reference.\n",
    "4. You will compute the ROUGE-(1, 2, L) scores between the top generation (from step 3) and the **reference** => `ROUGE(reference, top-generation)`\n",
    "5. You will provide the average ROUGE-(1, 2, L) scores for all the test dataset samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp3K01PyiTAo"
   },
   "source": [
    "### Data Preprocessing for Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEn_yV-LiTAo"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Load pre-trained **model** and **tokenizer**.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "2cfbdfc56b454e9799b3eb55406a01d8",
      "f9ec3e18275a4ee29abd4dab083ad0ab",
      "a2639a7167124813bab5d06897777fa4",
      "53e45d0f22b14483ab2e9b17f293e75c",
      "a8d764b099be462cb0d99ab47cabf795",
      "635a3dc3f4e7440abb1bc8beebfbc72a",
      "e8417066a1ae4fb8a501527a92899d52",
      "a5d2b520162a434e8d3774fbf37b1809",
      "76ec6279597c4b7ea6a348a1638b3368",
      "a6d9cc02e34b45f28ea7102e6a823ebf",
      "81064c9250024b628bbbf46593c00c83"
     ]
    },
    "executionInfo": {
     "elapsed": 12238,
     "status": "ok",
     "timestamp": 1679779063703,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "ltHbaf6riTAo",
    "outputId": "367a6fef-a947-4eec-e865-fa8b8db02091"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfbdfc56b454e9799b3eb55406a01d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model_id = \"distilgpt2\"\n",
    "mrpc_dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tokenizer_pretrained_gpt = AutoTokenizer.from_pretrained(model_id)\n",
    "gpt2_pretrained_model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1679779063704,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "5SzIaHhxgYUb",
    "outputId": "6871846d-ae3b-4c8e-889d-9c84917ad45b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrpc_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMuY-DEciTAo"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Concatenate sentences, pass them to the tokenizer and clip to `MAX_SEQ_LENGTH` length.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1679779071835,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "2AqjBxq6gYUb"
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer_pretrained_gpt.pad_token = tokenizer_pretrained_gpt.eos_token\n",
    "eos_token = tokenizer_pretrained_gpt.eos_token\n",
    "eos_token_id = tokenizer_pretrained_gpt.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "aborted",
     "timestamp": 1679776166166,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "g2vZsSofiTAp"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1679779076395,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "y_n6agYlgYUb"
   },
   "outputs": [],
   "source": [
    "# Define a function to preprocess each example\n",
    "def preprocess_function(examples):\n",
    "    context = [example1 + eos_token + example2 + eos_token for example1, example2 in zip(examples[\"sentence1\"],examples[\"sentence2\"])]\n",
    "    #targets = [example + eos_token for example in examples[\"sentence2\"]]\n",
    "    #sentences = [context + targets ]\n",
    "    #print('sentences', context)\n",
    "    \n",
    "     # Tokenize the concatenated inputs and targets\n",
    "    inputs = tokenizer_pretrained_gpt(context, padding=\"max_length\", truncation=True, max_length=64)\n",
    "    #targets = tokenizer(targets, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    #model_inputs = tokenizer(context, text_target=targets, max_length=128, truncation=True)\n",
    "    #print('nn', model_inputs)\n",
    "    return {\"input_ids\": inputs[\"input_ids\"], \n",
    "            \"attention_mask\": inputs[\"attention_mask\"]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "17b539cd49434a408e31e1a4cff04a7e",
      "e89972329a434905b73be0d286a89252",
      "e4e57b9c248a43059e520c6d5a15b345",
      "254a0f89fd2c43caab70c05ab483a7bc",
      "480bb59530b643db882f87b1bfa79e80",
      "3f7d04071a0a4431910a0013568de54e",
      "b0d1e8f0d9464ab8807f8b8c422ab583",
      "189f1e3ab92b4119b755058721c7725c",
      "885269ef0de54abf86fa70761ec755c9",
      "8f30d0e06b764e37a005f19cc38d431f",
      "74bc4e48edfa4fbfbfe2a1930153c239",
      "3f986b885d97476eb90c7ec95b73999b",
      "724cfd132b904744bbfe4138b0ece89a",
      "e4061c1ac61049e3bf746ecbb84e9cd7",
      "51dfb0edd18b4488b8d7e848890261f7",
      "2080327f3074438fbb66f3496ca6914b",
      "bbb7f62cab6841988c6e763bbba5fad3",
      "ec3346e665e549a89dc748098f79a47f",
      "3e128f13e76741438ef40955e78b322a",
      "f72f1764917546749035c684cacd6b2a",
      "7eda3e84d8d748f79749c8bad7afea3c",
      "73bedfa0ab6647139dd8bab9556d4ae8",
      "b42aaf18a360487a9cf109e26e505413",
      "0419bd1af52c455e8a7ad74f5fedcf08",
      "292139b678ff48389ccc93b0f9ce3ba4",
      "42d2e16f2b6b43609200e61dec7138b3",
      "6d88f83b9cfe41709ab9135e2548c853",
      "29462914755147409fdab6dac096a51c",
      "737a6e0a8a1144f8a6d2e38003483d4a",
      "c9db2881669f46f6abfd77320050d3ae",
      "b3e24c4f517a43f2bb47e28d5ccf468b",
      "b01725f1a1644f7690017717b41be096",
      "106fe34e583546f487974307927a5d52"
     ]
    },
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1679779079538,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "R5lBsGu4gYUb",
    "outputId": "d0409fb5-cf39-4919-bc27-9d65ffa4330e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b539cd49434a408e31e1a4cff04a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f986b885d97476eb90c7ec95b73999b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42aaf18a360487a9cf109e26e505413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# concatenate sentences along with <eos> and pass them to the tokenizer\n",
    "mrpc_dataset = mrpc_dataset.map(preprocess_function, batched=True)\n",
    "print(mrpc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1679779085995,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "KUIuHU4lgYUc"
   },
   "outputs": [],
   "source": [
    "mrpc_dataset = mrpc_dataset.remove_columns(['label','idx','attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "280WIHFXgYUc"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Apply the masking technique described above (mask context sequence).\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "9e87f1de685e447cbe2579c3d24e6d9a",
      "9149a721c8d14156bc1a73f45d39dee5",
      "e9ef1c4478884f5db90eaa5c0191d969",
      "26fe951220d943fbb5332a1a65d2ebbf",
      "a14ebcd71f7a4fda94fa0285ad3597ca",
      "e509e1f127b04fc9bcce1fbbc6fa00bd",
      "5a609fb42ebf42698e0e65fb6a8f775b",
      "e65202a1ff2d41e1bf6f8c8bdee8b11a",
      "ba343ff4c52c41a88455900b02bbfb4a",
      "14bb2d784be347fda495631b4fe7a325",
      "703fcd6d7afa4a11bb37479ef795b894",
      "12f11a3d76254e03adce99d6fabedcec",
      "53b6b5a44c4641c993dc3f9352e0a1a2",
      "9283a38c12cc4e37afb125cd6640f380",
      "a5565ba1109947139a072058c7b4c10b",
      "9ca4f0ec13e44c328d964e3ba960dad5",
      "eb432719d2e6428c81619703601b2adf",
      "63ea57d5d5444c1c969369710b97ecac",
      "37d958a6eaa44fc7b1ed3ebad15ae276",
      "e8e938e840e74e789f62c74576e8f0f9",
      "75148d05fbe34f8f838b515a1df1dd7a",
      "11bb038065a241ea9dd9950306568ca9",
      "e96ab36b48d74a3d8c25f411ce37d4ac",
      "ff1cade2f62246ebba857ad29fb1dfd9",
      "526ec5029aaa489f92c05252605d6ae0",
      "3bad0bf894d74571beced63502ef78ed",
      "a1642a2fb7fc4bfd96bc724157e803df",
      "bc750f8412a5492a8ea42fa1a0c1de94",
      "c29484cac22b42d68599566caf64e0fb",
      "8bdcb30568a243d4beb85f300c1d521c",
      "a70725ebdae5458f991371bb32bba37e",
      "a12d9d06c0ae4562bcf4bd7bb018c182",
      "a089c01c7f384e94a8ee15fa6030275e"
     ]
    },
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1679779095309,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "A_PMOpb0iTAp",
    "outputId": "a498e7b9-e05b-4447-c4d8-895f6f1f2133",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e87f1de685e447cbe2579c3d24e6d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f11a3d76254e03adce99d6fabedcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96ab36b48d74a3d8c25f411ce37d4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_sample_label(sample):\n",
    "    # this function masks the context (by assigning -100), and makes the paraphrase the target labels\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    sentences = sample[\"input_ids\"]\n",
    "    labels = sentences.copy()\n",
    "    \n",
    "    idx = sentences.index(eos_token_id)\n",
    "    \n",
    "    labels[:(idx+1)] = (idx+1)*[-100]\n",
    "\n",
    "    \n",
    "    return {\"labels\": labels} \n",
    "\n",
    "\n",
    "\n",
    "mrpc_dataset = mrpc_dataset.map(get_sample_label)\n",
    "\n",
    "mrpc_dataset = mrpc_dataset.with_format(\"torch\")\n",
    "mrpc_train_dataset, mrpc_eval_dataset = mrpc_dataset[\"train\"], mrpc_dataset[\"validation\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679779098283,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "iM16a5pqgYUc",
    "outputId": "b0888c60-c078-4ad6-a711-034055887e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100, 46238,  1806,   284,   683,   355,   691,   366,\n",
       "          262,  4973,   366,   837,  1703,   305, 17027,  5371,   465,  3956,\n",
       "          286, 14593,  1233, 24707,   465,  2370,   764, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saniterary check\n",
    "print(len(mrpc_dataset['train']['labels'][0]), type(mrpc_dataset['train']['labels'][0]))\n",
    "mrpc_dataset['train']['labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WWoQKHXiTAp"
   },
   "source": [
    "### Run model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn2VyeWHiTAp"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Set hyperparameters according to the objective of the model.\n",
    "      \n",
    "üíª Implementation hint: You can play arround with different values for `learning_rate`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1679779109834,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "A46RPZ1xiTAq"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, AutoModelForCausalLM\n",
    "\n",
    "# create the finetuning trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"finetune_{model_id}-MRPC\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=20,\n",
    "    save_steps=10000,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\")\n",
    "\n",
    "gpt2_pretrained_model.transformer.wte.weight.requires_grad = False\n",
    "gpt2_pretrained_model.lm_head.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xlS2JYqiTAq"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: Run **training** using the `Trainer` class.\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1679779115458,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "Obg-hCQtiTAq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paraphrasing_trainer = Trainer(model=gpt2_pretrained_model,\n",
    "    tokenizer=tokenizer_pretrained_gpt,\n",
    "    args=training_args,\n",
    "    train_dataset= mrpc_dataset['train'],\n",
    "    eval_dataset=mrpc_dataset['validation']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813
    },
    "executionInfo": {
     "elapsed": 325843,
     "status": "ok",
     "timestamp": 1679779443709,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "xHQL45h4dBk_",
    "outputId": "f3ee85db-6f75-43f2-d7c4-d3b661fd71dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9180' max='9180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9180/9180 05:25, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.261200</td>\n",
       "      <td>1.160586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.062800</td>\n",
       "      <td>1.141607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.908300</td>\n",
       "      <td>1.165164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.768200</td>\n",
       "      <td>1.224455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.638100</td>\n",
       "      <td>1.278316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.569100</td>\n",
       "      <td>1.374381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>1.464629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.401200</td>\n",
       "      <td>1.524544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>1.626415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>1.696149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>1.734017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>1.793280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>1.804073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>1.856734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>1.851581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>1.868893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>1.897581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>1.911836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>1.915928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>1.920967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9180, training_loss=0.4081472438924453, metrics={'train_runtime': 325.6595, 'train_samples_per_second': 225.266, 'train_steps_per_second': 28.189, 'total_flos': 1198045601464320.0, 'train_loss': 0.4081472438924453, 'epoch': 20.0})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrasing_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1679779495420,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "0tkGrdR8ZjWg"
   },
   "outputs": [],
   "source": [
    "torch.save(paraphrasing_trainer.model.state_dict(), 'drive/MyDrive/Colab Notebooks/modern-nlp/a1-xav-nal/models/finetune-distilgpt2-mrpc.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0honxSuiTAq"
   },
   "source": [
    "### Evaluate model with ROUGE scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-9rIf4tiTAq"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "üéØ Goal: For each sample in evaluation set, generate 5 outputs and perform the ROUGE evaluation as presented in the question description above.\n",
    "\n",
    "üíª Implementation hint: Use the following API call to get top-k generations\n",
    "    \n",
    "    generated_sequences = paraphrasing_trainer.model.generate(\n",
    "        context_ids,\n",
    "        do_sample=True, \n",
    "        max_length=MAX_SEQ_LENGTH, \n",
    "        top_k=20, \n",
    "        top_p=0.95, \n",
    "        no_repeat_ngram_size=2, \n",
    "        num_return_sequences=5\n",
    "    )\n",
    "\n",
    "_Note 1: For simplicity, you can ignore the contexts that have more than 1 sentence._\n",
    "\n",
    "_Note 2: On the generated reference, if there is more that 1 sentence generated, keep only the first one._\n",
    "\n",
    "_Note 3: To split into sentences, you can use [`nltk.sent_tokenize()`](https://www.nltk.org/api/nltk.tokenize.html)._\n",
    "\n",
    "_Note 4: Use the [`evaluate.load('rouge')`](https://huggingface.co/spaces/evaluate-metric/rouge) function to compute the ROUGE metrics._\n",
    "\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12324,
     "status": "ok",
     "timestamp": 1679779538987,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "rGw85Mq5HnCx",
    "outputId": "5da46dc0-ca80-44c7-a2a4-06cea30fb94b"
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate\n",
    "# !pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "792d3e4af11b497db68ae35f130bac23",
      "9b7f1f6f657847eaae67f463bb733088",
      "1affc5b79a21401ca297c8143e30a8ec",
      "bf4a8cc2d00249e292933c0ce80f1cae",
      "12b176ccc6f64e48a31d983ceb48f477",
      "fe7bb7657a0d4893b710bb8a56cf5d1c",
      "d8d8a46754864182b58297ba2a4adcc4",
      "9b557e2df2d74089bc7668ac157b8036",
      "eec81435eb5346a19f598a5e6c6bcd81",
      "be2d8981f7d94bd2b4e54e90ba32c863",
      "90b960381f3f490b8747b5386488dfbc"
     ]
    },
    "executionInfo": {
     "elapsed": 17615,
     "status": "ok",
     "timestamp": 1679779565296,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "XXQhXiOOgYUd",
    "outputId": "9c4bbcaa-9e82-4b1f-fddb-d83362d3a7cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792d3e4af11b497db68ae35f130bac23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/408 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  0%|          | 1/408 [00:01<11:30,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  1%|          | 5/408 [00:01<01:52,  3.57it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  2%|‚ñè         | 9/408 [00:01<00:57,  6.93it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  3%|‚ñé         | 13/408 [00:02<00:36, 10.70it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  4%|‚ñç         | 17/408 [00:02<00:26, 14.53it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  5%|‚ñå         | 21/408 [00:02<00:21, 18.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  6%|‚ñå         | 25/408 [00:02<00:18, 20.98it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  7%|‚ñã         | 29/408 [00:02<00:15, 24.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  8%|‚ñä         | 33/408 [00:02<00:14, 26.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  9%|‚ñâ         | 37/408 [00:02<00:13, 28.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 10%|‚ñà         | 41/408 [00:02<00:12, 30.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 11%|‚ñà         | 45/408 [00:03<00:11, 31.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 12%|‚ñà‚ñè        | 49/408 [00:03<00:11, 31.69it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 13%|‚ñà‚ñé        | 53/408 [00:03<00:11, 31.61it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 14%|‚ñà‚ñç        | 57/408 [00:03<00:10, 32.78it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 15%|‚ñà‚ñç        | 61/408 [00:03<00:10, 33.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 16%|‚ñà‚ñå        | 65/408 [00:03<00:10, 32.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 17%|‚ñà‚ñã        | 69/408 [00:03<00:10, 32.62it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 18%|‚ñà‚ñä        | 73/408 [00:03<00:10, 33.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 19%|‚ñà‚ñâ        | 77/408 [00:03<00:09, 33.84it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 20%|‚ñà‚ñâ        | 81/408 [00:04<00:09, 32.82it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 21%|‚ñà‚ñà        | 85/408 [00:04<00:09, 32.79it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 22%|‚ñà‚ñà‚ñè       | 89/408 [00:04<00:09, 32.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 23%|‚ñà‚ñà‚ñé       | 93/408 [00:04<00:09, 32.46it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 24%|‚ñà‚ñà‚ñç       | 97/408 [00:04<00:09, 33.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 25%|‚ñà‚ñà‚ñç       | 101/408 [00:04<00:09, 33.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 26%|‚ñà‚ñà‚ñå       | 105/408 [00:04<00:08, 34.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 27%|‚ñà‚ñà‚ñã       | 110/408 [00:04<00:08, 36.96it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 28%|‚ñà‚ñà‚ñä       | 114/408 [00:05<00:08, 35.91it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 29%|‚ñà‚ñà‚ñâ       | 118/408 [00:05<00:08, 35.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 30%|‚ñà‚ñà‚ñâ       | 122/408 [00:05<00:08, 34.63it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 31%|‚ñà‚ñà‚ñà       | 126/408 [00:05<00:08, 34.64it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 130/408 [00:05<00:08, 34.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 134/408 [00:05<00:08, 32.62it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 138/408 [00:05<00:08, 32.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 142/408 [00:05<00:08, 30.48it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 146/408 [00:06<00:08, 30.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 150/408 [00:06<00:08, 30.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 154/408 [00:06<00:08, 31.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 158/408 [00:06<00:07, 31.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 162/408 [00:06<00:07, 31.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 166/408 [00:06<00:07, 30.87it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 171/408 [00:06<00:06, 33.99it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 175/408 [00:06<00:07, 33.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 179/408 [00:07<00:06, 33.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 183/408 [00:07<00:07, 31.95it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 187/408 [00:07<00:06, 32.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 191/408 [00:07<00:06, 32.80it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 195/408 [00:07<00:06, 31.72it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 199/408 [00:07<00:06, 30.77it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 203/408 [00:07<00:06, 31.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 207/408 [00:07<00:06, 31.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 211/408 [00:08<00:06, 31.53it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 215/408 [00:08<00:05, 32.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 219/408 [00:08<00:05, 32.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 223/408 [00:08<00:05, 33.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 227/408 [00:08<00:05, 32.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 231/408 [00:08<00:05, 31.45it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 235/408 [00:08<00:05, 30.82it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 239/408 [00:09<00:05, 30.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 243/408 [00:09<00:05, 32.45it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 247/408 [00:09<00:04, 32.46it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 251/408 [00:09<00:04, 32.87it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 255/408 [00:09<00:04, 31.55it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 259/408 [00:09<00:04, 31.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 263/408 [00:09<00:04, 29.62it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 266/408 [00:09<00:04, 29.55it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 269/408 [00:09<00:04, 29.50it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 272/408 [00:10<00:04, 29.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 276/408 [00:10<00:04, 30.41it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 280/408 [00:10<00:04, 30.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 284/408 [00:10<00:04, 29.92it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 288/408 [00:10<00:03, 30.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 292/408 [00:10<00:03, 31.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 296/408 [00:10<00:03, 30.38it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 300/408 [00:10<00:03, 30.86it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 304/408 [00:11<00:03, 31.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 308/408 [00:11<00:03, 31.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 312/408 [00:11<00:03, 31.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 318/408 [00:11<00:02, 36.46it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 322/408 [00:11<00:02, 33.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 326/408 [00:11<00:02, 32.74it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 330/408 [00:11<00:02, 31.49it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 334/408 [00:12<00:02, 31.85it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 338/408 [00:12<00:02, 32.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 343/408 [00:12<00:01, 35.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 348/408 [00:12<00:01, 37.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 352/408 [00:12<00:01, 35.60it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 356/408 [00:12<00:01, 33.88it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 360/408 [00:12<00:01, 33.76it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 364/408 [00:12<00:01, 32.62it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 369/408 [00:13<00:01, 34.69it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 373/408 [00:13<00:01, 33.79it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 377/408 [00:13<00:00, 33.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 382/408 [00:13<00:00, 35.74it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 386/408 [00:13<00:00, 34.78it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 390/408 [00:13<00:00, 33.90it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 394/408 [00:13<00:00, 32.78it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 398/408 [00:13<00:00, 31.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 402/408 [00:14<00:00, 31.96it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 406/408 [00:14<00:00, 31.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 408/408 [00:14<00:00, 28.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# tokenizer_pretrained_gpt\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "rouge_values = []\n",
    "for sample in tqdm(mrpc_eval_dataset):\n",
    "    if len(nltk.sent_tokenize(sample['sentence1'])) == 1:\n",
    "    \n",
    "        # Generate 5 paraphrased outputs\n",
    "        generated_sequences = paraphrasing_trainer.model.generate( \n",
    "            sample['input_ids'].reshape(1, -1).to('cuda'),\n",
    "            do_sample=True,\n",
    "            max_length=MAX_SEQ_LENGTH,\n",
    "            top_k=20,\n",
    "            top_p=0.95,\n",
    "            no_repeat_ngram_size=2,\n",
    "            num_return_sequences=5)\n",
    "        \n",
    "        generated_sentences = [nltk.sent_tokenize(tokenizer_pretrained_gpt.decode(sequence, skip_special_tokens=True))[0] \n",
    "                                    for sequence in generated_sequences]\n",
    "\n",
    "        # pick the best candidate given ROUGE similarity to context\n",
    "        generated_sentence = generated_sentences[0]\n",
    "        \n",
    "\n",
    "        reference_sentence = nltk.sent_tokenize(sample['sentence2'])[0]\n",
    "\n",
    "        # compute the ROUGE value of the best candidate with the reference\n",
    "        rouge_score = rouge.compute(predictions=[generated_sentence], \n",
    "                                    references=[reference_sentence],\n",
    "                                    use_aggregator=False)\n",
    "   \n",
    "        rouge_values.append(rouge_score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1679779565297,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "rJ3lIFcvHdKs",
    "outputId": "6ebccd1b-3ed8-4940-a6d2-08277cf69ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 0.6634838751097124\n",
      "rouge2 0.6300494846475121\n",
      "rougeL 0.6491479462951292\n",
      "rougeLsum 0.6491479462951292\n"
     ]
    }
   ],
   "source": [
    "avg_dict = {}\n",
    "\n",
    "# Loop over each dictionary in the list\n",
    "for rouge_scores in rouge_values:\n",
    "    # Loop over each key in the dictionary\n",
    "    for key, value in rouge_scores.items():\n",
    "        # If key not already in avg_dict, add it with value equal to the first score\n",
    "        if key not in avg_dict:\n",
    "            avg_dict[key] = value[0]\n",
    "        # If key already in avg_dict, add the score to the running total\n",
    "        else:\n",
    "            avg_dict[key] += value[0]\n",
    "    \n",
    "# Compute the average for each key\n",
    "num_samples = len(rouge_values)\n",
    "for key, value in avg_dict.items():\n",
    "    avg_dict[key] = value / num_samples\n",
    "    \n",
    "# Print the average for each key\n",
    "for key, value in avg_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "aborted",
     "timestamp": 1679776166171,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -60
    },
    "id": "WpoPef6kPFtR"
   },
   "outputs": [],
   "source": [
    "tb_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbWpKRKpiTAr"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #8e7cc3;background-color:#e4e1eb;border-radius: 15px;\">\n",
    "\n",
    "üéâ Excellent work! You just finished the code implementation parts of the assignment. \n",
    "\n",
    "#### Part 3 - Checklist\n",
    "Here are the elements you will need for the report in Part 4:\n",
    "   \n",
    "- [X] LSTM-variants scores on perplexity and their checkpoints.\n",
    "- [X] DistilGPT2 score on perplexity and its checkpoint.\n",
    "- [X] Encoder-decoder variant train/validation loss score and its checkpoint.\n",
    "- [X] DistilGPT2 ROUGE scores and its fine-tuned checkpoint.\n",
    "\n",
    "_Note: Don't forget to include the tensorboard log to every model you trained._\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drEstqDkUvcp"
   },
   "source": [
    "---\n",
    "\n",
    "<a name=\"4\"></a>\n",
    "# PART 4: Write your report üìò\n",
    "\n",
    "Fill in the tables with the respective scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaCft7HUw4uh"
   },
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;text-align:center;\">\n",
    "\n",
    "#### Perplexity results on Language Models\n",
    "\n",
    "| Model - Variant | PPL |\n",
    "|:--------- | :-----: |\n",
    "| LSTM Variant A - Embeddings trained from scratch | 1024.269 |\n",
    "| LSTM Variant B - Pre-trained embeddings & frozen | 1055.042 |\n",
    "| LSTM Variant C - Pre-trained embeddings & trainable | 952.626 |\n",
    "||||\n",
    "| DistilGPT2 - Trained from scratch | 71.389 |\n",
    "| Pre-trained DistilGPT2 | 1025.211 |\n",
    "    \n",
    "#### Performance scores on Text Paraphrasing\n",
    "| Model - Variant | ROUGE-1 | ROUGE-2 | ROUGE-L | ROUGE-Lsum |\n",
    "|:--------- | :-----: | :-----: |  :-----: |  :-----: | \n",
    "| Pre-trained DistilGPT2 | 0.6634838751097124 |0.6300494846475121 |  0.6491479462951292 |0.6491479462951292 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000cf54d7a994e76b3c8ed6e5a7fa8ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "00303f3b5eb642ca96dee5196fa82489": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "008f1118b8914fe0ba200ba98bb26c60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "010ccbc0e2514995a9bb9ca6b4dcbb46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01ba31f819094461b5b9673535c48a55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "025f242e19564a05bf9b553678bad44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67a4f961064e432580e6b455708604dc",
      "max": 6838,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5efc29c94753456a8ff1bd42c53a52ca",
      "value": 6838
     }
    },
    "0261cdb3b98a499a9abc6eca1b85aa73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03c730ff4a4b4866b9193ca71c114e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0419bd1af52c455e8a7ad74f5fedcf08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29462914755147409fdab6dac096a51c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_737a6e0a8a1144f8a6d2e38003483d4a",
      "value": "Map: 100%"
     }
    },
    "041e02f29ce14d5d8437b6459d2218a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d832f3b3c4e540f1b46a1b9c98e063dc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2eb9d5ba745444c2b01a1d129a1c93dd",
      "value": "Filter: 100%"
     }
    },
    "04f5f30cf97b48bba7e562530d3dba2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "054bfe9774574154a35226760c18cce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57ffafb4c19f4ba696d75b8e0b6e61fa",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e18a612645d54d08a0a25bf95bfd3c19",
      "value": " 456k/456k [00:00&lt;00:00, 491kB/s]"
     }
    },
    "05505a1c65304e608ca944d83950bf0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06892332c4a84e36896a78114647a91c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06cf13ee150c496bbd31da7d6569360c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07017a06aa1140c0a9a2db743fe76aed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0746bf21395f4abe90e1be6a661595ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91370081c1fb4f129d039caba0cded07",
      "max": 3668,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdcc404b59674569aafc39e67d59a3d3",
      "value": 3668
     }
    },
    "07c75c51ca214472b10a87b8d7ad2948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa2ae5e20c554addab4c3d467f62655a",
       "IPY_MODEL_32685da210ad44dc9943b45fa935bf51",
       "IPY_MODEL_a315d162401746d4b76fab00aa97b654"
      ],
      "layout": "IPY_MODEL_a8ea751547ba42a6ab8464316904bc3b"
     }
    },
    "07dc570d3e4b49f1b525107ac4b41e0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5042cf1c58c43c880157a640f93f6c6",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c811ae6922a644e1808a5ab947cddb4b",
      "value": 124
     }
    },
    "08176ef25535404b9fd86ec94f7381fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0821c106a3c04946853af2b673871de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "086ca127059e4c68888f86480f27cb0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85c6c1b69ceb493ca68f31a897016b54",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_213257cf28d74bccb7e242750febcd72",
      "value": "Filter:  98%"
     }
    },
    "09201791427b4c84b15256669ad148fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "093cf631b27040e28e9c89ab46d3bd7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a1eeae86ae54c78a723c58cdea576bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8da0d4d6d82f411395c95bd690023033",
      "max": 408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f5de3ccc7ba4623b2ef063154b02300",
      "value": 408
     }
    },
    "0af258e7f83b423382f53beca0ff7f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_086ca127059e4c68888f86480f27cb0f",
       "IPY_MODEL_1d00cf3cc9fa4489ae0ca0f179f229ea",
       "IPY_MODEL_fee951e3317c4fe7bdc6a49c71414486"
      ],
      "layout": "IPY_MODEL_54e7b4b3da4d4a3aaf4aa974c6688194"
     }
    },
    "0b92055fd2bd4ca3945d847741d95e62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bb7ef7760b84b67af5bcb72c294a40e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bc7013374174522aa093855c4202292": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78a86dd6ceda4f19ac38a7f835e6f4a1",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46918084fafa464c97c8d110cd054c3b",
      "value": 456318
     }
    },
    "0c876787b40f4573bec3a52fde8be8de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ca7a531653e409485df5872820d612b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b44e8ed0163498584a679bb3caa7e82",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2981ac58ca60496c9cf71acb28c20b99",
      "value": "Flattening the indices:  98%"
     }
    },
    "0d77624d8ab541709df0c2a95d617c98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d8a67089196469a83f7bcdde14c8412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dded6b545e14eb4a9d441ebfc6e331e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05505a1c65304e608ca944d83950bf0d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5f43cfbcc5f1461fb96a15b29c3b60bc",
      "value": "Downloading metadata: 100%"
     }
    },
    "0f701e9fa8ba4eccb83b61b01b6df2b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "101e56ca649c49618a25094068c446f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "106fe34e583546f487974307927a5d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10cb4c999372484bb28f3397b1a9806c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11910d5cff404ab0a8e2492552b2fc37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11bb038065a241ea9dd9950306568ca9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "120864e1d96044c19cf2b7241f6c6fd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12b176ccc6f64e48a31d983ceb48f477": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12f11a3d76254e03adce99d6fabedcec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53b6b5a44c4641c993dc3f9352e0a1a2",
       "IPY_MODEL_9283a38c12cc4e37afb125cd6640f380",
       "IPY_MODEL_a5565ba1109947139a072058c7b4c10b"
      ],
      "layout": "IPY_MODEL_9ca4f0ec13e44c328d964e3ba960dad5"
     }
    },
    "1361606a5cab482ba39184673b9fe630": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "144a862f034548ea86d3ebf4f2854ab6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b150a3bef194727a3ebc2699817d79b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_cf920b95527949a6ad3de089f12c5f9b",
      "value": " 4358/4358 [00:12&lt;00:00, 34549.60 examples/s]"
     }
    },
    "14bb2d784be347fda495631b4fe7a325": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15a14e16ac044e2abaf91aaa45d10570": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16d0150cb43c4e9ab561116097a3dffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16f05dccd4764185910bfa3db8556039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5415639928ca46b1811ededf0662170e",
      "max": 376835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_101e56ca649c49618a25094068c446f2",
      "value": 376835
     }
    },
    "171604fac3c74d3fbcdaa01f23cb45d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b539cd49434a408e31e1a4cff04a7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e89972329a434905b73be0d286a89252",
       "IPY_MODEL_e4e57b9c248a43059e520c6d5a15b345",
       "IPY_MODEL_254a0f89fd2c43caab70c05ab483a7bc"
      ],
      "layout": "IPY_MODEL_480bb59530b643db882f87b1bfa79e80"
     }
    },
    "182421ad5d544e12a02673d22f7499ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95cb5a5a3523483aaea6022f548aa40f",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_182b49967a454692bc614989118b84a8",
      "value": 3
     }
    },
    "182b49967a454692bc614989118b84a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "18987a269dfc4a4fb8bdd57b6aa0c5ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "189f1e3ab92b4119b755058721c7725c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18a6c7f63c1840888da3131f6a0ef3d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "18e3f6478edf4b77af4990f9411b5537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27a9473197c14b1baa40c09f64c81d79",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1361606a5cab482ba39184673b9fe630",
      "value": " 1725/1725 [00:15&lt;00:00, 16527.91 examples/s]"
     }
    },
    "190b338d56a2454a85c20367cb6fe9f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df06a61db60942be821f0cd0ae5cecaa",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_093cf631b27040e28e9c89ab46d3bd7e",
      "value": " 353M/353M [00:00&lt;00:00, 507MB/s]"
     }
    },
    "1a45aeeb3906466c9c3004dc5f528fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ac291c00dfd4ec492f30ae43a44ff8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1affc5b79a21401ca297c8143e30a8ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b557e2df2d74089bc7668ac157b8036",
      "max": 6270,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eec81435eb5346a19f598a5e6c6bcd81",
      "value": 6270
     }
    },
    "1b44e8ed0163498584a679bb3caa7e82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c9d774078b74375a0e89fecd991eed6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d00cf3cc9fa4489ae0ca0f179f229ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f0963a36b2a408abb8b7d64230ec827",
      "max": 826663,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59af41e4807b4f8d81045f9351a2a095",
      "value": 826663
     }
    },
    "1d275dfc9f5b43d094bea2716a6fd455": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f5de3ccc7ba4623b2ef063154b02300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f6ec5f510d74264ac8635d3b879f3ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2080327f3074438fbb66f3496ca6914b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "20ccbbc80c474b6ba6b147ccb50d09df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20f433a29a284865bf234e79f5f926c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20fd3a9af7314b08bf59c8a422fb603d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d4a81f615f84e34bdfc8e883d9b3ad5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_228cfb3e6fdd40caa23f04d974a1b145",
      "value": "Downloading data files: 100%"
     }
    },
    "213257cf28d74bccb7e242750febcd72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "226ec8ae56f340a8a33de465e611a69e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "228cfb3e6fdd40caa23f04d974a1b145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22ee8d4fdf9e4b82a9b7f671e942755c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23b66c18d7414a79b45081ce33a67b31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_041e02f29ce14d5d8437b6459d2218a6",
       "IPY_MODEL_16f05dccd4764185910bfa3db8556039",
       "IPY_MODEL_8d1716114dd64588ac0a839d12b5c4fc"
      ],
      "layout": "IPY_MODEL_04f5f30cf97b48bba7e562530d3dba2b"
     }
    },
    "254a0f89fd2c43caab70c05ab483a7bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f30d0e06b764e37a005f19cc38d431f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_74bc4e48edfa4fbfbfe2a1930153c239",
      "value": " 2000/3668 [00:00&lt;00:00, 14536.22 examples/s]"
     }
    },
    "258c6e115e3843d1a223383a74d0b350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3ed0b0ee84f44b18d9a722d9b867acd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8fb81826c5834968a8c9f4e21325e034",
      "value": "100%"
     }
    },
    "26637a3cecff475480064279ef7e36c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93fbda9a67cb4fd49c3512854325dea0",
       "IPY_MODEL_f7f88bc4a0a741af87dc0d60bf071477",
       "IPY_MODEL_29da6946d5f54607b13b8e161640a3de"
      ],
      "layout": "IPY_MODEL_dae125af277b4375986e41e0bed34ede"
     }
    },
    "2681f0949b8c4259ba5ab56ff6ef0262": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "269e33af121a4b6c924dfd4d3aa1d898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb64cfa2be5e42adb40540f8667dd117",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_efd909b842ea4ee6b3a6e2844f7f406e",
      "value": " 527000/551037 [00:01&lt;00:00, 312579.94 examples/s]"
     }
    },
    "26fe951220d943fbb5332a1a65d2ebbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14bb2d784be347fda495631b4fe7a325",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_703fcd6d7afa4a11bb37479ef795b894",
      "value": " 3246/3668 [00:00&lt;00:00, 10527.57 examples/s]"
     }
    },
    "2715fb4483914908beb82df8921e31bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94b0cd13f0154c8285f0333e9bc2d225",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1f6ec5f510d74264ac8635d3b879f3ff",
      "value": " 376686/376835 [02:03&lt;00:00, 2295.85 examples/s]"
     }
    },
    "274c571165ad49b8b951c98637de3b8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99590e9aa62b43c1af8bdfcf4100f50c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f14d8ff493af428d931d743619c05bd2",
      "value": " 376835/376835 [00:00&lt;00:00, 1680448.04 examples/s]"
     }
    },
    "2780a9449ea94a54a02377a0a27b972c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27a9473197c14b1baa40c09f64c81d79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2880b152ff834505bbc85afcf0b1f15d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28b10dd4609a498ab08ad3cfeca2be8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c876787b40f4573bec3a52fde8be8de",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f297e5ff171240d885126866d4dc373c",
      "value": " 6.84k/6.84k [00:00&lt;00:00, 581kB/s]"
     }
    },
    "292139b678ff48389ccc93b0f9ce3ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9db2881669f46f6abfd77320050d3ae",
      "max": 1725,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3e24c4f517a43f2bb47e28d5ccf468b",
      "value": 1725
     }
    },
    "29462914755147409fdab6dac096a51c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2981ac58ca60496c9cf71acb28c20b99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29da6946d5f54607b13b8e161640a3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cb6f7a17e444e2b8b1d62d04279a91f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c0891a63b30e47f9b93aef3ef19c22dd",
      "value": " 825806/826663 [01:03&lt;00:00, 12636.19 examples/s]"
     }
    },
    "29f08a9e2e9f4bce9dcf20d393332dfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "29f8282ce02c44efb836baf310eeb88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a9b2d2402874e2a9a0207eb302a821b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2af9b39de1b0470e9023721f6dbfd97d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b019bc3c5c04369aa6e9b51b67157b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d5bc8eabe7f428f8a3a2e688ea163ef",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ce3cc11b9bcf47deae8fc8b9ce627eed",
      "value": " 1.04M/1.04M [00:01&lt;00:00, 901kB/s]"
     }
    },
    "2b7381466c234026ae7b99aa3961cd9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1db98d8d52d4dc0918d774d4da6d52c",
       "IPY_MODEL_9c0e0299d5fa499aacccd4fb1ae51c33",
       "IPY_MODEL_190b338d56a2454a85c20367cb6fe9f9"
      ],
      "layout": "IPY_MODEL_11910d5cff404ab0a8e2492552b2fc37"
     }
    },
    "2c1a87385c4c4aa28551e0deb21852d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab5818844fd74e309381fe7244ff27a2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f97a7c1f127b4748a028fb1b4341cb2a",
      "value": " 448000/461250 [00:02&lt;00:00, 162091.08 examples/s]"
     }
    },
    "2c52bbd685b2457b859ce0b4c27ae288": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c90ab876674470c9e067784d9067dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7718016a10454d6bbb0ba46cc5beae22",
       "IPY_MODEL_63b2dd1da8884f3aa570b93cd31c64e5",
       "IPY_MODEL_2b019bc3c5c04369aa6e9b51b67157b5"
      ],
      "layout": "IPY_MODEL_7c43844864b447c4817c1a50ae98b1df"
     }
    },
    "2cfbdfc56b454e9799b3eb55406a01d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9ec3e18275a4ee29abd4dab083ad0ab",
       "IPY_MODEL_a2639a7167124813bab5d06897777fa4",
       "IPY_MODEL_53e45d0f22b14483ab2e9b17f293e75c"
      ],
      "layout": "IPY_MODEL_a8d764b099be462cb0d99ab47cabf795"
     }
    },
    "2d44d9b820e24f83bcef5555d2118d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_008f1118b8914fe0ba200ba98bb26c60",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c95b3fbaae7345e1a4388dc08e68809d",
      "value": 1
     }
    },
    "2d62ec78e3a34e57884c97305ffdec2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2eaac12254044bcf8c3200a4677709d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb31da671c549f4a90122ea1c8e583e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71a29f6d0871401ca4db0d71eab7cc37",
       "IPY_MODEL_de36110ca4af4a6e809bb8ddf04038d0",
       "IPY_MODEL_144a862f034548ea86d3ebf4f2854ab6"
      ],
      "layout": "IPY_MODEL_770fc153b46243c4b4c42940a05bf4c8"
     }
    },
    "2eb3b4764ba84657a55834e01814b630": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4783ccb33d88473fb349c804b212d255",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d0e1cc77d4b045fca1eee7cbc1e9ed00",
      "value": " 411000/415138 [00:07&lt;00:00, 59912.92 examples/s]"
     }
    },
    "2eb9d5ba745444c2b01a1d129a1c93dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd028ca78464d46b313736ca6c26a4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9570391d6cfe4f7382dc888a32c826a0",
       "IPY_MODEL_f87816bee388448eb40b4b2212293636",
       "IPY_MODEL_8acfef37376641ed92dc344587c128ad"
      ],
      "layout": "IPY_MODEL_9a86c946a63449efa04938836b37d711"
     }
    },
    "30818c7714644f3688237bb1dc98b4a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41c0179fa990483a9cfe9364f22327c5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18a6c7f63c1840888da3131f6a0ef3d3",
      "value": 1
     }
    },
    "308442a8a1c44a8583cbb62125962068": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32685da210ad44dc9943b45fa935bf51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d77624d8ab541709df0c2a95d617c98",
      "max": 3760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aaaeecbd3f854fe784e399fc0690babc",
      "value": 3760
     }
    },
    "32d86cc773254a3a90b96d4391d150f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33200a33a7c044abb69fbae569464073": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bf499efa43a489bb40ce97811b15a63",
       "IPY_MODEL_af1d7cc540d4474087481c5b419f1998",
       "IPY_MODEL_b19027e8ea574d7ab773e280d25a2c3a"
      ],
      "layout": "IPY_MODEL_5f374cd198f64204a3daeeffae300a92"
     }
    },
    "34060cfca234472885c990b4de25547c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d8822a6d8c1430799ed05e6b955b4ff",
       "IPY_MODEL_0bc7013374174522aa093855c4202292",
       "IPY_MODEL_054bfe9774574154a35226760c18cce2"
      ],
      "layout": "IPY_MODEL_85663c3cdbdb4fc88c856f68eb3f5951"
     }
    },
    "352c0b1c4b8549e8babaf43a80e18a7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8872aad0eb74a69b844d25ebe837dd6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f0862d5095944af590bd5aa71c5b387e",
      "value": "Downloading data: "
     }
    },
    "35d752525c9349f790fed9c47a7c09f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2eaac12254044bcf8c3200a4677709d3",
      "max": 190229076,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f40482551384b978b4fe2a829f506fc",
      "value": 190229076
     }
    },
    "36581e29d6444968b551d831df14be43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36868ebb18b140389df9a0ad5565a2a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36cee41e59ef4750b7420791c624d634": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36f3a0a2c5924ce8bce8945b56dc31df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5178c6b9715475b967e7fef7a4b2453",
       "IPY_MODEL_9e7bbfed279d4965ac919d1df9c8e421",
       "IPY_MODEL_a369666f68744bba925a590c8ef8dd3e"
      ],
      "layout": "IPY_MODEL_b209c6c467084a45833e58c72a3aa1a0"
     }
    },
    "373cf10fe18c4d50905154af83d9da1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37d958a6eaa44fc7b1ed3ebad15ae276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3932e020ec5c46b09d5e2acba02223ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39e1c7fcf7a7431a9e9c195a859d7968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c05a9dc5cc4141baa0ddd4dcb03c4b15",
       "IPY_MODEL_443ea0050e2f4828a5a74fee720d6bb3",
       "IPY_MODEL_465c0385cd8a475c98826353a70e5e5f"
      ],
      "layout": "IPY_MODEL_7d0f88ae81cc4cd3aee435e5aaebd873"
     }
    },
    "3ad034e4646c458496f5da4b1a6dd1ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b6738de1bb4438d918b820e0b62a8cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bad0bf894d74571beced63502ef78ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a12d9d06c0ae4562bcf4bd7bb018c182",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a089c01c7f384e94a8ee15fa6030275e",
      "value": " 1072/1725 [00:00&lt;00:00, 9663.38 examples/s]"
     }
    },
    "3d4131f818b74d72b70df45e123f6f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_547907ef4b524d05bada8899de8ac6f4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_48037d1853704a218c29fe3d968b9125",
      "value": " 3668/3668 [00:15&lt;00:00, 14693.14 examples/s]"
     }
    },
    "3e128f13e76741438ef40955e78b322a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e75b896342c403db09fe0e426de03de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acc92b39494b4b91b7f8e6b3a34199aa",
       "IPY_MODEL_b9e80facd7974e10872bc0760d80a4a7",
       "IPY_MODEL_5652c227b1114bc28b0d4fa392ea37fe"
      ],
      "layout": "IPY_MODEL_36cee41e59ef4750b7420791c624d634"
     }
    },
    "3e9c47e91062408cac3f4eb3cdc0b8b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f7d04071a0a4431910a0013568de54e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f986b885d97476eb90c7ec95b73999b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_724cfd132b904744bbfe4138b0ece89a",
       "IPY_MODEL_e4061c1ac61049e3bf746ecbb84e9cd7",
       "IPY_MODEL_51dfb0edd18b4488b8d7e848890261f7"
      ],
      "layout": "IPY_MODEL_2080327f3074438fbb66f3496ca6914b"
     }
    },
    "3fa112814133476390761f42fd5d8146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fd61e57948c489ba28f36cd98f5e44c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "41c0179fa990483a9cfe9364f22327c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "41f83a1a34f54058a8f15c64dca44254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "4202ec836ebb45569c769b25899ad1bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42d2e16f2b6b43609200e61dec7138b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b01725f1a1644f7690017717b41be096",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_106fe34e583546f487974307927a5d52",
      "value": " 1725/1725 [00:00&lt;00:00, 16094.62 examples/s]"
     }
    },
    "443d65b0129a4de9907748cd8bf645d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "443ea0050e2f4828a5a74fee720d6bb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c43ffb6fe16045318ab4666c1cfc93eb",
      "max": 1801350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac4514fb3e574d4f874d174896401952",
      "value": 1801350
     }
    },
    "44f52a5791fa487f9e4757de3c485e84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "465c0385cd8a475c98826353a70e5e5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d54870203074c71a305ce304ee0945c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7ec015b596e14d5a94f4d9a4f8a0af79",
      "value": " 1801350/1801350 [00:51&lt;00:00, 48652.36 examples/s]"
     }
    },
    "46918084fafa464c97c8d110cd054c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46bcad369fd840e2b7274848cee11db3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "4783ccb33d88473fb349c804b212d255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48037d1853704a218c29fe3d968b9125": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "480bb59530b643db882f87b1bfa79e80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "4866868572564274a6ccd2d93e3533bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_258c6e115e3843d1a223383a74d0b350",
       "IPY_MODEL_a52ffa78c2674d66bffdd1bfd4c13dc2",
       "IPY_MODEL_ac4c4fc5275944e7aa917c13a07e582f"
      ],
      "layout": "IPY_MODEL_ef6f933eb4834b2d91397a964e8837e1"
     }
    },
    "48b9e0b65e0b4a1099d111879792ef66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "493c80b2eb564e6ab395070cdfb7b9df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "495fd2e8fe3f43cb951bf0c3c71b827d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_557455c75dcb45a3af137e3ca20678f8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ee7b27dab5f74bd99711d5795750f475",
      "value": " 1.05M/? [00:00&lt;00:00, 38.5MB/s]"
     }
    },
    "49a348ba2027403585844a28edf3e571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64ae5659a2284405b58d29256078de2d",
      "max": 1165029,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15a14e16ac044e2abaf91aaa45d10570",
      "value": 1165029
     }
    },
    "4ad7b16fdfd5483cae339aa49fddff0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36868ebb18b140389df9a0ad5565a2a5",
      "max": 415138,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe04aabeb8f344c48825f32206332b47",
      "value": 415138
     }
    },
    "4af2d0f58bee4dcaacf579f7083da4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bf1f5718b0e462eabd49678333f34e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4dd935a314e34a8889261bc587d8f73f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f016364f544447297be9fc464d382a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "504961da5c9844659036ad1a24b98c16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "510c23a6481746e69e530c5a7a37851c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51dfb0edd18b4488b8d7e848890261f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7eda3e84d8d748f79749c8bad7afea3c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_73bedfa0ab6647139dd8bab9556d4ae8",
      "value": " 0/408 [00:00&lt;?, ? examples/s]"
     }
    },
    "526ec5029aaa489f92c05252605d6ae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bdcb30568a243d4beb85f300c1d521c",
      "max": 1725,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a70725ebdae5458f991371bb32bba37e",
      "value": 1725
     }
    },
    "53b6b5a44c4641c993dc3f9352e0a1a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb432719d2e6428c81619703601b2adf",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_63ea57d5d5444c1c969369710b97ecac",
      "value": "Map:   0%"
     }
    },
    "53e45d0f22b14483ab2e9b17f293e75c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6d9cc02e34b45f28ea7102e6a823ebf",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_81064c9250024b628bbbf46593c00c83",
      "value": " 3/3 [00:00&lt;00:00, 171.56it/s]"
     }
    },
    "53f9c5eb29974620880ab132cf160c46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e9c47e91062408cac3f4eb3cdc0b8b3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b78632f5893341d88e9c468ab66bca91",
      "value": "Filter: 100%"
     }
    },
    "5415639928ca46b1811ededf0662170e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "547907ef4b524d05bada8899de8ac6f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54e7b4b3da4d4a3aaf4aa974c6688194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "5508c2d80733471fa98dcf6fafce7d0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6da777740e0d4d1fbf563c3977692b4d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6b8ca95f9db7441ebce44df046c2e062",
      "value": " 1.36M/1.36M [00:01&lt;00:00, 1.20MB/s]"
     }
    },
    "5542143e39fb4c398b4088580d7e7b02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "557455c75dcb45a3af137e3ca20678f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "561847ce5f5144caa303db28f1cf2906": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5652c227b1114bc28b0d4fa392ea37fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_010ccbc0e2514995a9bb9ca6b4dcbb46",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_16d0150cb43c4e9ab561116097a3dffb",
      "value": " 762/762 [00:00&lt;00:00, 53.8kB/s]"
     }
    },
    "56822f615b6e4915b94d2815f2758368": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a9ee8d0b6d6141898e120ebc0b00021b",
       "IPY_MODEL_0a1eeae86ae54c78a723c58cdea576bb",
       "IPY_MODEL_87a11f30c7484191ae7a1698962b3c67"
      ],
      "layout": "IPY_MODEL_e3228a15b1fe45d097d64bab4833d436"
     }
    },
    "57f6811666e74233bbcf48ab16885f90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2bd7c75cf53485292f39d0d9794ef94",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3932e020ec5c46b09d5e2acba02223ce",
      "value": " 28.7k/28.7k [00:00&lt;00:00, 91.0kB/s]"
     }
    },
    "57ffafb4c19f4ba696d75b8e0b6e61fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58545776e58c4a7a9752effc1029c1ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5c209686e3b405399a8855dd613d313",
      "max": 28682,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d11939b1dbe1474f84e1d49fb0157a3f",
      "value": 28682
     }
    },
    "59af41e4807b4f8d81045f9351a2a095": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "59e61f302b6b4d068f1aa2bbe961ac97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a609fb42ebf42698e0e65fb6a8f775b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5acaa02e1f0e4b01b25f4c9703207fdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_631e539166704bb6b69854731f6099c8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5e9c1496dda043f6ac74dca1009d036f",
      "value": " 1165029/1165029 [00:19&lt;00:00, 58348.39 examples/s]"
     }
    },
    "5bf499efa43a489bb40ce97811b15a63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76be472206e44e4293cd9f66bc131733",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_308442a8a1c44a8583cbb62125962068",
      "value": "Map: 100%"
     }
    },
    "5c39a6e6a35e45f68165eebeca871e5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d49f44429cd4fcc9084ea07b1d3bf70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dabde875e3843d1ac116d6e58e08267": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e50e102e9784a358f8df4c3fcee1363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e9c1496dda043f6ac74dca1009d036f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ef7d65286614bbbaced24ee49816531": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5efc29c94753456a8ff1bd42c53a52ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f0963a36b2a408abb8b7d64230ec827": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f374cd198f64204a3daeeffae300a92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "5f3af597f68b416f904ed62233234618": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f43cfbcc5f1461fb96a15b29c3b60bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6144aa3e44a2437cbc45bb3c1c75f273": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "624c612fccb34273ad36df8b738eea21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_caf421ee1b8c471baad792aec46f75ae",
       "IPY_MODEL_9ed6e022175e45c8875711b21eee8f80",
       "IPY_MODEL_ea3ac92843d44d1fb7ae7d0db3b17ced"
      ],
      "layout": "IPY_MODEL_00303f3b5eb642ca96dee5196fa82489"
     }
    },
    "631e539166704bb6b69854731f6099c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "635a3dc3f4e7440abb1bc8beebfbc72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63b2dd1da8884f3aa570b93cd31c64e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70322f5d731d4514ba3015ba2127b42d",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4af2d0f58bee4dcaacf579f7083da4c6",
      "value": 1042301
     }
    },
    "63ea57d5d5444c1c969369710b97ecac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64616ab98d494e088f3cba66e9bd36d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "64ae5659a2284405b58d29256078de2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "679cecd59fb54ace8e72d95344bc3490": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc06c0eeba5a4cd6bdbdeea2b3ada254",
       "IPY_MODEL_4ad7b16fdfd5483cae339aa49fddff0b",
       "IPY_MODEL_2eb3b4764ba84657a55834e01814b630"
      ],
      "layout": "IPY_MODEL_b2dfe8e49084416082a3a4d10360d447"
     }
    },
    "67a4f961064e432580e6b455708604dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68122b865a00489eae74822559e4d754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ad034e4646c458496f5da4b1a6dd1ca",
      "max": 376835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_894dabca82e7402a954935a599e5b6cd",
      "value": 376835
     }
    },
    "6954f0417b314a7d9d8984916f7142ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "699b57b1d1ce43bfaa87ffa2a5fe709b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_20fd3a9af7314b08bf59c8a422fb603d",
       "IPY_MODEL_182421ad5d544e12a02673d22f7499ee",
       "IPY_MODEL_e034e99fc9bb4acf91f03fb60c14f9a3"
      ],
      "layout": "IPY_MODEL_5542143e39fb4c398b4088580d7e7b02"
     }
    },
    "6ae6781844f24a0fa9248a22ab24db9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6954f0417b314a7d9d8984916f7142ab",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df7f50924c1c4ab3b5b0aed3dc2a2a5b",
      "value": 1
     }
    },
    "6af28750e5a24a748cf955506848a3c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7d53085374c4e0298fa60595eec89aa",
      "max": 376835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4dd935a314e34a8889261bc587d8f73f",
      "value": 376835
     }
    },
    "6b8ca95f9db7441ebce44df046c2e062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b914a276c96421caa1ee399d88cc8b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbfef9b72d3547078ecc1913dc776a99",
       "IPY_MODEL_30818c7714644f3688237bb1dc98b4a6",
       "IPY_MODEL_9018140e08b748a6b6d562cd07b08f6f"
      ],
      "layout": "IPY_MODEL_be9a9eb1653b440b95075b90472c386f"
     }
    },
    "6bb7b0998f684ca1880bd3c29f160c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0ce9505c0924043a8bef24fc74330e0",
       "IPY_MODEL_74e3fb2bd354439f88613e0005337f24",
       "IPY_MODEL_2c1a87385c4c4aa28551e0deb21852d7"
      ],
      "layout": "IPY_MODEL_41f83a1a34f54058a8f15c64dca44254"
     }
    },
    "6cb6f7a17e444e2b8b1d62d04279a91f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d88f83b9cfe41709ab9135e2548c853": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "6da777740e0d4d1fbf563c3977692b4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6df94057dba24663b23c9527cff45a34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e359a8a789c467d9a03846c49739289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ebee1a399704883a625c28b6d6a77b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70322f5d731d4514ba3015ba2127b42d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "703fcd6d7afa4a11bb37479ef795b894": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70eb2ca771034edbbc889ab6cb585066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32d86cc773254a3a90b96d4391d150f0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9fe8b0418c08420d81972188e9041f2a",
      "value": "Downloading (‚Ä¶)neration_config.json: 100%"
     }
    },
    "71a29f6d0871401ca4db0d71eab7cc37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5fc9575b72549c0b5ffa370efca03a2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_09201791427b4c84b15256669ad148fc",
      "value": "Generating test split: 100%"
     }
    },
    "724cfd132b904744bbfe4138b0ece89a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbb7f62cab6841988c6e763bbba5fad3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ec3346e665e549a89dc748098f79a47f",
      "value": "Map:   0%"
     }
    },
    "72d0be40054c4568b20def93d904fe66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddd72ad558e64394b477e6f314ce5bbb",
       "IPY_MODEL_e522046cce434e198e0ae262132f3f53",
       "IPY_MODEL_b4cfb51252474948988e1100abdacf75"
      ],
      "layout": "IPY_MODEL_9bf67e4a4d7a47df93a0b316ddcfae34"
     }
    },
    "737a6e0a8a1144f8a6d2e38003483d4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73a85f4df0594cb89f0c52b9fa4764f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73bedfa0ab6647139dd8bab9556d4ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73e21b2a2c7f41f3a43e685fa4d11661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74bc4e48edfa4fbfbfe2a1930153c239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74e3fb2bd354439f88613e0005337f24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7914efe566764982bf5e7e730b6f41f7",
      "max": 461250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5436e2862a04ff3bf2485f02f3e0ef2",
      "value": 461250
     }
    },
    "74e926cf26d745efabd8f46ce7228caa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2880b152ff834505bbc85afcf0b1f15d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ddb3ff1953d04ad9ad0eb7dd43b207fb",
      "value": " 376000/376835 [00:31&lt;00:00, 11701.08 examples/s]"
     }
    },
    "75148d05fbe34f8f838b515a1df1dd7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76acca8861394988a064605cce1d842a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76be472206e44e4293cd9f66bc131733": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76ec6279597c4b7ea6a348a1638b3368": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "770fc153b46243c4b4c42940a05bf4c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "7718016a10454d6bbb0ba46cc5beae22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8273c0d1bf154036a92f4c3d49e83e0a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_da0e7695cd45429795d43319e66b3f7f",
      "value": "Downloading (‚Ä¶)olve/main/vocab.json: 100%"
     }
    },
    "775d47ec05974438a9b5ab31cebe3849": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70eb2ca771034edbbc889ab6cb585066",
       "IPY_MODEL_07dc570d3e4b49f1b525107ac4b41e0c",
       "IPY_MODEL_f6d3904337de461f808fb6eb563fabaf"
      ],
      "layout": "IPY_MODEL_443d65b0129a4de9907748cd8bf645d9"
     }
    },
    "7862597a6bf844b78ebc7e64022465f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "78a86dd6ceda4f19ac38a7f835e6f4a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78e3ad377b414579ac2c6da8cf7dba90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1808aa90409413a8073dd37e9a94de2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a42d00425a824e2b8b3d3ad0ab4efdb3",
      "value": "Downloading metadata: 100%"
     }
    },
    "7914efe566764982bf5e7e730b6f41f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "792d3e4af11b497db68ae35f130bac23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b7f1f6f657847eaae67f463bb733088",
       "IPY_MODEL_1affc5b79a21401ca297c8143e30a8ec",
       "IPY_MODEL_bf4a8cc2d00249e292933c0ce80f1cae"
      ],
      "layout": "IPY_MODEL_12b176ccc6f64e48a31d983ceb48f477"
     }
    },
    "79e309e661bf44dc93be16b5712e8491": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7af89a84b29f4480a20a2a2fe4465071": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b5ba65a7bc14774a920e01c6a800e96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94326579ed4c41c8be462f9eb5def04b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_29f8282ce02c44efb836baf310eeb88d",
      "value": "Map: 100%"
     }
    },
    "7c43844864b447c4817c1a50ae98b1df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cc0781f7c534819adae03e75d068b2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d0f88ae81cc4cd3aee435e5aaebd873": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "7e184120eb3641199839d92d0f3b162c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ec015b596e14d5a94f4d9a4f8a0af79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7eda3e84d8d748f79749c8bad7afea3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f40482551384b978b4fe2a829f506fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "807fa2d1d12f4d4bb9de1e9ff6a88f85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81064c9250024b628bbbf46593c00c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8273c0d1bf154036a92f4c3d49e83e0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83654b33cc2946d787b6d4bd782abd81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8370276c54514f698a504c63b350111b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "841206ab98c044cba8bd439428b83c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cc0781f7c534819adae03e75d068b2f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_cd550588ac0d4e57b17cb3933c45206f",
      "value": "Saving the dataset (1/1 shards): 100%"
     }
    },
    "85663c3cdbdb4fc88c856f68eb3f5951": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85c6c1b69ceb493ca68f31a897016b54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87721358a94442e488281df8ce9cc14a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87a11f30c7484191ae7a1698962b3c67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d02748d235714e8fa8b3ab22946b76b7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_dd6cc51ba53442c08942dc3905f3427a",
      "value": " 408/408 [00:00&lt;00:00, 3982.05 examples/s]"
     }
    },
    "8839b54691a44686b71bba32e9e1cf75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "885269ef0de54abf86fa70761ec755c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88e76ccf82414782818c76a24b665213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2780a9449ea94a54a02377a0a27b972c",
      "max": 376835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64616ab98d494e088f3cba66e9bd36d7",
      "value": 376835
     }
    },
    "894dabca82e7402a954935a599e5b6cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "89982609fcee4f78a3f682e84bfde852": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8acfef37376641ed92dc344587c128ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f32b937e9f404e879feeeba76c6d53cd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5ef7d65286614bbbaced24ee49816531",
      "value": " 9.25k/9.25k [00:00&lt;00:00, 576kB/s]"
     }
    },
    "8bdcb30568a243d4beb85f300c1d521c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c1650f8ad8f447da0588e295c728045": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d1716114dd64588ac0a839d12b5c4fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb0bc2eceb9a4a45a8afe14dd99fb55b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7af89a84b29f4480a20a2a2fe4465071",
      "value": " 376000/376835 [00:41&lt;00:00, 9152.90 examples/s]"
     }
    },
    "8d4a81f615f84e34bdfc8e883d9b3ad5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d6e773857b143878e5d05b5c1568f9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d8047d8ab5e478a8480a7a3588825ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb58d44cbed8496caff8b5c48fd62515",
       "IPY_MODEL_ca6ec11a7a6141609f4c5974d1a9c145",
       "IPY_MODEL_5508c2d80733471fa98dcf6fafce7d0c"
      ],
      "layout": "IPY_MODEL_95652bd45a39443191d5e5afb8b89f4d"
     }
    },
    "8d8822a6d8c1430799ed05e6b955b4ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ebee1a399704883a625c28b6d6a77b4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f4bf38c2479b4f64b1c97b2d4785bdf6",
      "value": "Downloading (‚Ä¶)olve/main/merges.txt: 100%"
     }
    },
    "8da0d4d6d82f411395c95bd690023033": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e2cd2971fd34a548df4f9aece362d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ceaf042c8fdd4a61a8ba86b785d36fd4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5e50e102e9784a358f8df4c3fcee1363",
      "value": " 376000/376835 [00:38&lt;00:00, 9826.20 examples/s]"
     }
    },
    "8ec47cfb489f45aa85057c9bb81cc604": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "8f30d0e06b764e37a005f19cc38d431f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f72ad693c6e4d10b785e03a3573cba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_352c0b1c4b8549e8babaf43a80e18a7d",
       "IPY_MODEL_2d44d9b820e24f83bcef5555d2118d24",
       "IPY_MODEL_a4e6af89d9484947b355354aa3bfaafd"
      ],
      "layout": "IPY_MODEL_08176ef25535404b9fd86ec94f7381fc"
     }
    },
    "8fb81826c5834968a8c9f4e21325e034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9018140e08b748a6b6d562cd07b08f6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_120864e1d96044c19cf2b7241f6c6fd5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fdfdef15fba14fc8b1de6be5a4102551",
      "value": " 6.22k/? [00:00&lt;00:00, 437kB/s]"
     }
    },
    "9018602694384bb9b47e21db15c085fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90b960381f3f490b8747b5386488dfbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90dd72f801664a5c9d6af2c226633901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91370081c1fb4f129d039caba0cded07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9149a721c8d14156bc1a73f45d39dee5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e509e1f127b04fc9bcce1fbbc6fa00bd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5a609fb42ebf42698e0e65fb6a8f775b",
      "value": "Map:  88%"
     }
    },
    "91dcd4ed6dc241d9b394dc4bd66bb5f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9a16f34ff26474fa26f33163f8ff48a",
       "IPY_MODEL_e7799365bdf54b45b4c4a5adbb959016",
       "IPY_MODEL_2715fb4483914908beb82df8921e31bb"
      ],
      "layout": "IPY_MODEL_29f08a9e2e9f4bce9dcf20d393332dfa"
     }
    },
    "9209400e060e46b7bda62b1a1abad130": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_373cf10fe18c4d50905154af83d9da1e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_20ccbbc80c474b6ba6b147ccb50d09df",
      "value": "Downloading data: "
     }
    },
    "9283a38c12cc4e37afb125cd6640f380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37d958a6eaa44fc7b1ed3ebad15ae276",
      "max": 408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8e938e840e74e789f62c74576e8f0f9",
      "value": 408
     }
    },
    "93fbda9a67cb4fd49c3512854325dea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c39a6e6a35e45f68165eebeca871e5f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_226ec8ae56f340a8a33de465e611a69e",
      "value": "Map: 100%"
     }
    },
    "94326579ed4c41c8be462f9eb5def04b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94b0cd13f0154c8285f0333e9bc2d225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95652bd45a39443191d5e5afb8b89f4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9570391d6cfe4f7382dc888a32c826a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_171604fac3c74d3fbcdaa01f23cb45d9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8839b54691a44686b71bba32e9e1cf75",
      "value": "Downloading readme: 100%"
     }
    },
    "95cb5a5a3523483aaea6022f548aa40f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971574a5243045febe0dac53d7782159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e071d3e7d9ac4386b56d9e74fc151bea",
      "max": 551037,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f181e720a2b548c8b1ce0f4ea2b1580d",
      "value": 551037
     }
    },
    "97d8d8118ca549d2b36ee5c5c0ee1951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98ac5d3ecb9542799910f5e1853bcc61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "990b0b0d9870455c909f08ae059d59b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "993bb92f553c4e11b74d47ddca8e9589": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9209400e060e46b7bda62b1a1abad130",
       "IPY_MODEL_6ae6781844f24a0fa9248a22ab24db9d",
       "IPY_MODEL_495fd2e8fe3f43cb951bf0c3c71b827d"
      ],
      "layout": "IPY_MODEL_2681f0949b8c4259ba5ab56ff6ef0262"
     }
    },
    "99590e9aa62b43c1af8bdfcf4100f50c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a86c946a63449efa04938836b37d711": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a92a63b5a9b4f3a84f08fb8a5de4987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bdf228e7055e4e019114b159e8bf9912",
       "IPY_MODEL_68122b865a00489eae74822559e4d754",
       "IPY_MODEL_8e2cd2971fd34a548df4f9aece362d4e"
      ],
      "layout": "IPY_MODEL_46bcad369fd840e2b7274848cee11db3"
     }
    },
    "9b150a3bef194727a3ebc2699817d79b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b3531590e7f411987d75576eb8af05c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98ac5d3ecb9542799910f5e1853bcc61",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c8b675c5337a43bba40826d012ed30b3",
      "value": "Downloading data: 100%"
     }
    },
    "9b557e2df2d74089bc7668ac157b8036": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b7f1f6f657847eaae67f463bb733088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe7bb7657a0d4893b710bb8a56cf5d1c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d8d8a46754864182b58297ba2a4adcc4",
      "value": "Downloading builder script: 100%"
     }
    },
    "9bf67e4a4d7a47df93a0b316ddcfae34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c0e0299d5fa499aacccd4fb1ae51c33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8370276c54514f698a504c63b350111b",
      "max": 352833716,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aaeb1ef2a5fa496a97d758ce8f98ed04",
      "value": 352833716
     }
    },
    "9ca4f0ec13e44c328d964e3ba960dad5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "9cea5b99e3984744a614fa4c1e3c624d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d4e0c51b6134bb18dec240f1a17adf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d54870203074c71a305ce304ee0945c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d5bc8eabe7f428f8a3a2e688ea163ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d60b69a42254880b663c2d92eeb488e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6df94057dba24663b23c9527cff45a34",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b54098cbda6c44c08f56667edf64a582",
      "value": "Filter:  96%"
     }
    },
    "9e7bbfed279d4965ac919d1df9c8e421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c9d774078b74375a0e89fecd991eed6",
      "max": 1801350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ecad496b93e242edb40cced29c6db8bf",
      "value": 1801350
     }
    },
    "9e87f1de685e447cbe2579c3d24e6d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9149a721c8d14156bc1a73f45d39dee5",
       "IPY_MODEL_e9ef1c4478884f5db90eaa5c0191d969",
       "IPY_MODEL_26fe951220d943fbb5332a1a65d2ebbf"
      ],
      "layout": "IPY_MODEL_a14ebcd71f7a4fda94fa0285ad3597ca"
     }
    },
    "9ed6e022175e45c8875711b21eee8f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48b9e0b65e0b4a1099d111879792ef66",
      "max": 27887,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7862597a6bf844b78ebc7e64022465f6",
      "value": 27887
     }
    },
    "9fe8b0418c08420d81972188e9041f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a089c01c7f384e94a8ee15fa6030275e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a12d9d06c0ae4562bcf4bd7bb018c182": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a14ebcd71f7a4fda94fa0285ad3597ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a1642a2fb7fc4bfd96bc724157e803df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a24911b97ac949489acbd63c096a15e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f18eb88af966417f96fd072b2507d733",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_493c80b2eb564e6ab395070cdfb7b9df",
      "value": "Generating train split: 100%"
     }
    },
    "a2639a7167124813bab5d06897777fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5d2b520162a434e8d3774fbf37b1809",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76ec6279597c4b7ea6a348a1638b3368",
      "value": 3
     }
    },
    "a2bac6fdf03542ec8ad2d005d6dddd8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a315d162401746d4b76fab00aa97b654": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44f52a5791fa487f9e4757de3c485e84",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0bb7ef7760b84b67af5bcb72c294a40e",
      "value": " 0/3760 [00:00&lt;?, ? examples/s]"
     }
    },
    "a369666f68744bba925a590c8ef8dd3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22ee8d4fdf9e4b82a9b7f671e942755c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_01ba31f819094461b5b9673535c48a55",
      "value": " 1801000/1801350 [00:10&lt;00:00, 172023.50 examples/s]"
     }
    },
    "a3900f2f2d0b4bbb98385d0716cb152d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a42d00425a824e2b8b3d3ad0ab4efdb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4e6af89d9484947b355354aa3bfaafd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e184120eb3641199839d92d0f3b162c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_90dd72f801664a5c9d6af2c226633901",
      "value": " 441k/? [00:00&lt;00:00, 19.3MB/s]"
     }
    },
    "a52ffa78c2674d66bffdd1bfd4c13dc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0821c106a3c04946853af2b673871de7",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fa112814133476390761f42fd5d8146",
      "value": 3
     }
    },
    "a5565ba1109947139a072058c7b4c10b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75148d05fbe34f8f838b515a1df1dd7a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_11bb038065a241ea9dd9950306568ca9",
      "value": " 0/408 [00:00&lt;?, ? examples/s]"
     }
    },
    "a5c209686e3b405399a8855dd613d313": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5d2b520162a434e8d3774fbf37b1809": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5fad3e160cb4aa8b61e1c4c215e8c50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5fc9575b72549c0b5ffa370efca03a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a68646357761487f80be410354f638aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6d9cc02e34b45f28ea7102e6a823ebf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a70725ebdae5458f991371bb32bba37e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a7bf2383162c427f93f7db57a8682f05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_807fa2d1d12f4d4bb9de1e9ff6a88f85",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_36581e29d6444968b551d831df14be43",
      "value": "Downloading builder script: 100%"
     }
    },
    "a7d53085374c4e0298fa60595eec89aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8872aad0eb74a69b844d25ebe837dd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8d764b099be462cb0d99ab47cabf795": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8ea751547ba42a6ab8464316904bc3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a924aadadc694854b51f8afc9b658378": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a9ee8d0b6d6141898e120ebc0b00021b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be94de40583f4b7f86061963e5b51a3d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_97d8d8118ca549d2b36ee5c5c0ee1951",
      "value": "Generating validation split: 100%"
     }
    },
    "aa2ae5e20c554addab4c3d467f62655a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de817ad07eca41cb998f81e6df7a808e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_da1f6761c0da40b3a98fc1214f10a61c",
      "value": "Generating validation split:   0%"
     }
    },
    "aaaeecbd3f854fe784e399fc0690babc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aaeb1ef2a5fa496a97d758ce8f98ed04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab5818844fd74e309381fe7244ff27a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac4514fb3e574d4f874d174896401952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ac4c4fc5275944e7aa917c13a07e582f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4202ec836ebb45569c769b25899ad1bb",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e398a278f8f645c3ac99e20d435f8da2",
      "value": " 3/3 [00:00&lt;00:00, 191.48it/s]"
     }
    },
    "acba259ea98c4b639adc6c30b1b9340d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "acc92b39494b4b91b7f8e6b3a34199aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df52d3b5f08a40288cff117edbfd908d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d9aa66589a2d4e62a75e910a2b0edc5f",
      "value": "Downloading (‚Ä¶)lve/main/config.json: 100%"
     }
    },
    "af1d7cc540d4474087481c5b419f1998": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1924555bfb04c5d834c93b3e89ff35b",
      "max": 551037,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8cbdc1c4470477fac7d57e9841edb32",
      "value": 551037
     }
    },
    "af6dbb2893ac472d8213175b68a55c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_841206ab98c044cba8bd439428b83c4c",
       "IPY_MODEL_6af28750e5a24a748cf955506848a3c6",
       "IPY_MODEL_274c571165ad49b8b951c98637de3b8c"
      ],
      "layout": "IPY_MODEL_cdc95de5485d4a3b86f09944443cb667"
     }
    },
    "afa9834bbbc74f5283418c0ce59fc009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53f9c5eb29974620880ab132cf160c46",
       "IPY_MODEL_49a348ba2027403585844a28edf3e571",
       "IPY_MODEL_5acaa02e1f0e4b01b25f4c9703207fdc"
      ],
      "layout": "IPY_MODEL_18987a269dfc4a4fb8bdd57b6aa0c5ed"
     }
    },
    "b01725f1a1644f7690017717b41be096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0750a0ba06f4fd4b8fb8eb1f76e2961": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76acca8861394988a064605cce1d842a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_dac642df43b84c328d3125a2d6072661",
      "value": " 461144/461250 [00:42&lt;00:00, 10081.97 examples/s]"
     }
    },
    "b0d1e8f0d9464ab8807f8b8c422ab583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b19027e8ea574d7ab773e280d25a2c3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcbd371a0c00498f995c5b41d5c1a161",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1a45aeeb3906466c9c3004dc5f528fa3",
      "value": " 550324/551037 [01:17&lt;00:00, 7186.03 examples/s]"
     }
    },
    "b209c6c467084a45833e58c72a3aa1a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "b29b1168dca94462ae55636774096aa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b6738de1bb4438d918b820e0b62a8cf",
      "max": 8482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06cf13ee150c496bbd31da7d6569360c",
      "value": 8482
     }
    },
    "b2dfe8e49084416082a3a4d10360d447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "b3e24c4f517a43f2bb47e28d5ccf468b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3ed0b0ee84f44b18d9a722d9b867acd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b42aaf18a360487a9cf109e26e505413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0419bd1af52c455e8a7ad74f5fedcf08",
       "IPY_MODEL_292139b678ff48389ccc93b0f9ce3ba4",
       "IPY_MODEL_42d2e16f2b6b43609200e61dec7138b3"
      ],
      "layout": "IPY_MODEL_6d88f83b9cfe41709ab9135e2548c853"
     }
    },
    "b490bf5a52884fe3ba6618c46312059b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4c563f6674d4b0496ae03dfdfae29ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d60b69a42254880b663c2d92eeb488e",
       "IPY_MODEL_971574a5243045febe0dac53d7782159",
       "IPY_MODEL_269e33af121a4b6c924dfd4d3aa1d898"
      ],
      "layout": "IPY_MODEL_3fd61e57948c489ba28f36cd98f5e44c"
     }
    },
    "b4cfb51252474948988e1100abdacf75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1ce602eb9d74ac4996b7e61d2357844",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8d6e773857b143878e5d05b5c1568f9c",
      "value": " 28.8k/28.8k [00:00&lt;00:00, 91.9kB/s]"
     }
    },
    "b54098cbda6c44c08f56667edf64a582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5724493d48f4187b54620e9a3a24467": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dabde875e3843d1ac116d6e58e08267",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_73a85f4df0594cb89f0c52b9fa4764f3",
      "value": "Map: 100%"
     }
    },
    "b78632f5893341d88e9c468ab66bca91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7d43c9c45704760934a7f4b5f5c569f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b87060d8716445d2bb1915f8c6baffd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b973ae1f891b422b81fb945cdeda3337": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ca7a531653e409485df5872820d612b",
       "IPY_MODEL_d3a8b092d677406c98101ef81941f608",
       "IPY_MODEL_d74a7f92c7924dcd998f499efc2c1dd2"
      ],
      "layout": "IPY_MODEL_6144aa3e44a2437cbc45bb3c1c75f273"
     }
    },
    "b9e80facd7974e10872bc0760d80a4a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0261cdb3b98a499a9abc6eca1b85aa73",
      "max": 762,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe38b364145442008abf0430f4061e5a",
      "value": 762
     }
    },
    "ba343ff4c52c41a88455900b02bbfb4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb0bc2eceb9a4a45a8afe14dd99fb55b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbb7f62cab6841988c6e763bbba5fad3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbfef9b72d3547078ecc1913dc776a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d275dfc9f5b43d094bea2716a6fd455",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d4f17bdb8d4446048c88e14d2eeb4005",
      "value": "Downloading data: "
     }
    },
    "bc750f8412a5492a8ea42fa1a0c1de94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd66cddedd3d47e89df5dcc53a73dbd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5724493d48f4187b54620e9a3a24467",
       "IPY_MODEL_88e76ccf82414782818c76a24b665213",
       "IPY_MODEL_74e926cf26d745efabd8f46ce7228caa"
      ],
      "layout": "IPY_MODEL_d3a4eff41faa4344b1618ae90417b396"
     }
    },
    "bdf228e7055e4e019114b159e8bf9912": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f016364f544447297be9fc464d382a6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d77c64dff27b4112a372ebe15542bb16",
      "value": "Filter: 100%"
     }
    },
    "be2d8981f7d94bd2b4e54e90ba32c863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be94de40583f4b7f86061963e5b51a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be9a9eb1653b440b95075b90472c386f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf122a0867834256ba6f9b017555ad4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf4a8cc2d00249e292933c0ce80f1cae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be2d8981f7d94bd2b4e54e90ba32c863",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_90b960381f3f490b8747b5386488dfbc",
      "value": " 6.27k/6.27k [00:00&lt;00:00, 450kB/s]"
     }
    },
    "c05a9dc5cc4141baa0ddd4dcb03c4b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73e21b2a2c7f41f3a43e685fa4d11661",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_dba1c7baf21c45a2931788783b84745d",
      "value": "Generating train split: 100%"
     }
    },
    "c0891a63b30e47f9b93aef3ef19c22dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0ce9505c0924043a8bef24fc74330e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_561847ce5f5144caa303db28f1cf2906",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_06892332c4a84e36896a78114647a91c",
      "value": "Filter:  97%"
     }
    },
    "c1924555bfb04c5d834c93b3e89ff35b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c29484cac22b42d68599566caf64e0fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2bd7c75cf53485292f39d0d9794ef94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3796f02e26d4cec9c6802f4d2330900": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d8a67089196469a83f7bcdde14c8412",
      "max": 1725,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_990b0b0d9870455c909f08ae059d59b4",
      "value": 1725
     }
    },
    "c43ffb6fe16045318ab4666c1cfc93eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c494739760624207bcbe68869bc2ec18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c80dfc0d40f9443993143b47de53e984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dded6b545e14eb4a9d441ebfc6e331e",
       "IPY_MODEL_58545776e58c4a7a9752effc1029c1ff",
       "IPY_MODEL_57f6811666e74233bbcf48ab16885f90"
      ],
      "layout": "IPY_MODEL_07017a06aa1140c0a9a2db743fe76aed"
     }
    },
    "c811ae6922a644e1808a5ab947cddb4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c8b675c5337a43bba40826d012ed30b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95b3fbaae7345e1a4388dc08e68809d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c9db2881669f46f6abfd77320050d3ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca6ec11a7a6141609f4c5974d1a9c145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f701e9fa8ba4eccb83b61b01b6df2b1",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d4e0c51b6134bb18dec240f1a17adf2",
      "value": 1355256
     }
    },
    "caf421ee1b8c471baad792aec46f75ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c52bbd685b2457b859ce0b4c27ae288",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_10cb4c999372484bb28f3397b1a9806c",
      "value": "Downloading readme: 100%"
     }
    },
    "cb58d44cbed8496caff8b5c48fd62515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a9b2d2402874e2a9a0207eb302a821b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fb9edfbab78e4a85a28c3dd642aacd53",
      "value": "Downloading (‚Ä¶)/main/tokenizer.json: 100%"
     }
    },
    "cb86bf0487f2493f981198ab8e7a6987": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc59c287c3454140bd328409d98efc63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7d43c9c45704760934a7f4b5f5c569f",
      "max": 461250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9e4261d7084455c88a7688dffe9e3a2",
      "value": 461250
     }
    },
    "cd550588ac0d4e57b17cb3933c45206f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdc95de5485d4a3b86f09944443cb667": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "cdcc404b59674569aafc39e67d59a3d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce3cc11b9bcf47deae8fc8b9ce627eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ceaf042c8fdd4a61a8ba86b785d36fd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf920b95527949a6ad3de089f12c5f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d02748d235714e8fa8b3ab22946b76b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03414a496d04b2a88f080b8d3ebf37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1311b6927fd482ea0c3501ea5a61f6b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6e359a8a789c467d9a03846c49739289",
      "value": "Generating test split: 100%"
     }
    },
    "d0e1cc77d4b045fca1eee7cbc1e9ed00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d11939b1dbe1474f84e1d49fb0157a3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1311b6927fd482ea0c3501ea5a61f6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ce602eb9d74ac4996b7e61d2357844": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1db98d8d52d4dc0918d774d4da6d52c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b490bf5a52884fe3ba6618c46312059b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e1c80d6d37074d6dbedf80ca3cf0b331",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "d2a6aa142fb040b49bc587f359d28ec9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3a4eff41faa4344b1618ae90417b396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "d3a8b092d677406c98101ef81941f608": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c494739760624207bcbe68869bc2ec18",
      "max": 376835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_000cf54d7a994e76b3c8ed6e5a7fa8ea",
      "value": 376835
     }
    },
    "d4f17bdb8d4446048c88e14d2eeb4005": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5042cf1c58c43c880157a640f93f6c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d74a7f92c7924dcd998f499efc2c1dd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59e61f302b6b4d068f1aa2bbe961ac97",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_89982609fcee4f78a3f682e84bfde852",
      "value": " 370000/376835 [00:03&lt;00:00, 105043.02 examples/s]"
     }
    },
    "d77c64dff27b4112a372ebe15542bb16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7be444614614cdebefd632eab00274e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78e3ad377b414579ac2c6da8cf7dba90",
       "IPY_MODEL_025f242e19564a05bf9b553678bad44c",
       "IPY_MODEL_28b10dd4609a498ab08ad3cfeca2be8a"
      ],
      "layout": "IPY_MODEL_9018602694384bb9b47e21db15c085fa"
     }
    },
    "d832f3b3c4e540f1b46a1b9c98e063dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8abd8aaf25e4b56868cdfd9ae4e04bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8cbdc1c4470477fac7d57e9841edb32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d8d8a46754864182b58297ba2a4adcc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d963008f79e94d1386897fcae8e9a696": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d49f44429cd4fcc9084ea07b1d3bf70",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2d62ec78e3a34e57884c97305ffdec2a",
      "value": " 190M/190M [00:17&lt;00:00, 12.4MB/s]"
     }
    },
    "d9aa66589a2d4e62a75e910a2b0edc5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9f84ccd34824ba1a3c26e8e8f39e124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7bf2383162c427f93f7db57a8682f05",
       "IPY_MODEL_b29b1168dca94462ae55636774096aa9",
       "IPY_MODEL_ff03838c865a4d2ea5ecb535421d2769"
      ],
      "layout": "IPY_MODEL_a68646357761487f80be410354f638aa"
     }
    },
    "da0e7695cd45429795d43319e66b3f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da1f6761c0da40b3a98fc1214f10a61c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da839139d26f4f5f85fbc52b09ba0ae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b5ba65a7bc14774a920e01c6a800e96",
       "IPY_MODEL_cc59c287c3454140bd328409d98efc63",
       "IPY_MODEL_b0750a0ba06f4fd4b8fb8eb1f76e2961"
      ],
      "layout": "IPY_MODEL_a924aadadc694854b51f8afc9b658378"
     }
    },
    "dac642df43b84c328d3125a2d6072661": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dae125af277b4375986e41e0bed34ede": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "dba1c7baf21c45a2931788783b84745d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc06c0eeba5a4cd6bdbdeea2b3ada254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2a6aa142fb040b49bc587f359d28ec9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4bf1f5718b0e462eabd49678333f34e2",
      "value": "Filter:  99%"
     }
    },
    "dd52ab9bca9644849665112935f8cb57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd6cc51ba53442c08942dc3905f3427a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddb3ff1953d04ad9ad0eb7dd43b207fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddd72ad558e64394b477e6f314ce5bbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_504961da5c9844659036ad1a24b98c16",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_20f433a29a284865bf234e79f5f926c3",
      "value": "Downloading builder script: 100%"
     }
    },
    "de36110ca4af4a6e809bb8ddf04038d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83654b33cc2946d787b6d4bd782abd81",
      "max": 4358,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2af9b39de1b0470e9023721f6dbfd97d",
      "value": 4358
     }
    },
    "de817ad07eca41cb998f81e6df7a808e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df06a61db60942be821f0cd0ae5cecaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df52d3b5f08a40288cff117edbfd908d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df7f50924c1c4ab3b5b0aed3dc2a2a5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e034e99fc9bb4acf91f03fb60c14f9a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b92055fd2bd4ca3945d847741d95e62",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5f3af597f68b416f904ed62233234618",
      "value": " 3/3 [00:00&lt;00:00,  6.97it/s]"
     }
    },
    "e071d3e7d9ac4386b56d9e74fc151bea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0b571b073544ae182f7cf4efebba467": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e150516900614b2ab6197bcf1cb2bf9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1808aa90409413a8073dd37e9a94de2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e18a612645d54d08a0a25bf95bfd3c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1c80d6d37074d6dbedf80ca3cf0b331": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3228a15b1fe45d097d64bab4833d436": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "e398a278f8f645c3ac99e20d435f8da2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4061c1ac61049e3bf746ecbb84e9cd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e128f13e76741438ef40955e78b322a",
      "max": 408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f72f1764917546749035c684cacd6b2a",
      "value": 408
     }
    },
    "e4e57b9c248a43059e520c6d5a15b345": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_189f1e3ab92b4119b755058721c7725c",
      "max": 3668,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_885269ef0de54abf86fa70761ec755c9",
      "value": 3668
     }
    },
    "e509e1f127b04fc9bcce1fbbc6fa00bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5178c6b9715475b967e7fef7a4b2453": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3900f2f2d0b4bbb98385d0716cb152d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_87721358a94442e488281df8ce9cc14a",
      "value": "Filter: 100%"
     }
    },
    "e522046cce434e198e0ae262132f3f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0b571b073544ae182f7cf4efebba467",
      "max": 28751,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_acba259ea98c4b639adc6c30b1b9340d",
      "value": 28751
     }
    },
    "e65202a1ff2d41e1bf6f8c8bdee8b11a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7799365bdf54b45b4c4a5adbb959016": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4f5ef4b002348c48e5196a68790ad07",
      "max": 376835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c1650f8ad8f447da0588e295c728045",
      "value": 376835
     }
    },
    "e7fb00ef48dc4a1f9c44bb78052265df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b3531590e7f411987d75576eb8af05c",
       "IPY_MODEL_35d752525c9349f790fed9c47a7c09f5",
       "IPY_MODEL_d963008f79e94d1386897fcae8e9a696"
      ],
      "layout": "IPY_MODEL_cb86bf0487f2493f981198ab8e7a6987"
     }
    },
    "e8417066a1ae4fb8a501527a92899d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e89972329a434905b73be0d286a89252": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f7d04071a0a4431910a0013568de54e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b0d1e8f0d9464ab8807f8b8c422ab583",
      "value": "Map:  55%"
     }
    },
    "e8e938e840e74e789f62c74576e8f0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e96ab36b48d74a3d8c25f411ce37d4ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff1cade2f62246ebba857ad29fb1dfd9",
       "IPY_MODEL_526ec5029aaa489f92c05252605d6ae0",
       "IPY_MODEL_3bad0bf894d74571beced63502ef78ed"
      ],
      "layout": "IPY_MODEL_a1642a2fb7fc4bfd96bc724157e803df"
     }
    },
    "e9e4261d7084455c88a7688dffe9e3a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9ef1c4478884f5db90eaa5c0191d969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e65202a1ff2d41e1bf6f8c8bdee8b11a",
      "max": 3668,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba343ff4c52c41a88455900b02bbfb4a",
      "value": 3668
     }
    },
    "ea3255bb892c4fd3ba071646b9a9ded2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea3ac92843d44d1fb7ae7d0db3b17ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5fad3e160cb4aa8b61e1c4c215e8c50",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9cea5b99e3984744a614fa4c1e3c624d",
      "value": " 27.9k/27.9k [00:00&lt;00:00, 91.8kB/s]"
     }
    },
    "eb432719d2e6428c81619703601b2adf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb64cfa2be5e42adb40540f8667dd117": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec3346e665e549a89dc748098f79a47f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec7e8bda72634bc5bc6040217103ea9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecad496b93e242edb40cced29c6db8bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee7b27dab5f74bd99711d5795750f475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eec81435eb5346a19f598a5e6c6bcd81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef6f933eb4834b2d91397a964e8837e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efd909b842ea4ee6b3a6e2844f7f406e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0862d5095944af590bd5aa71c5b387e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1028afdc7cc4b7bbe33a0a0d1043709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a24911b97ac949489acbd63c096a15e5",
       "IPY_MODEL_0746bf21395f4abe90e1be6a661595ab",
       "IPY_MODEL_3d4131f818b74d72b70df45e123f6f76"
      ],
      "layout": "IPY_MODEL_8ec47cfb489f45aa85057c9bb81cc604"
     }
    },
    "f14d8ff493af428d931d743619c05bd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f181e720a2b548c8b1ce0f4ea2b1580d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f18eb88af966417f96fd072b2507d733": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f297e5ff171240d885126866d4dc373c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f32b937e9f404e879feeeba76c6d53cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4bf38c2479b4f64b1c97b2d4785bdf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4f5ef4b002348c48e5196a68790ad07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5436e2862a04ff3bf2485f02f3e0ef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6d3904337de461f808fb6eb563fabaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd52ab9bca9644849665112935f8cb57",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ea3255bb892c4fd3ba071646b9a9ded2",
      "value": " 124/124 [00:00&lt;00:00, 7.22kB/s]"
     }
    },
    "f72f1764917546749035c684cacd6b2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f7455262e99145c681c3a58a5337e35a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d03414a496d04b2a88f080b8d3ebf37c",
       "IPY_MODEL_c3796f02e26d4cec9c6802f4d2330900",
       "IPY_MODEL_18e3f6478edf4b77af4990f9411b5537"
      ],
      "layout": "IPY_MODEL_a2bac6fdf03542ec8ad2d005d6dddd8a"
     }
    },
    "f7f88bc4a0a741af87dc0d60bf071477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b87060d8716445d2bb1915f8c6baffd2",
      "max": 826663,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbb31eb0d1c2426ca6e30f68391298e9",
      "value": 826663
     }
    },
    "f87816bee388448eb40b4b2212293636": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ac291c00dfd4ec492f30ae43a44ff8c",
      "max": 9252,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79e309e661bf44dc93be16b5712e8491",
      "value": 9252
     }
    },
    "f97a7c1f127b4748a028fb1b4341cb2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9a16f34ff26474fa26f33163f8ff48a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8abd8aaf25e4b56868cdfd9ae4e04bc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_03c730ff4a4b4866b9193ca71c114e16",
      "value": "Map: 100%"
     }
    },
    "f9ec3e18275a4ee29abd4dab083ad0ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_635a3dc3f4e7440abb1bc8beebfbc72a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e8417066a1ae4fb8a501527a92899d52",
      "value": "100%"
     }
    },
    "fb9edfbab78e4a85a28c3dd642aacd53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbb31eb0d1c2426ca6e30f68391298e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fcbd371a0c00498f995c5b41d5c1a161": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdfdef15fba14fc8b1de6be5a4102551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe04aabeb8f344c48825f32206332b47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe38b364145442008abf0430f4061e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe7bb7657a0d4893b710bb8a56cf5d1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fee951e3317c4fe7bdc6a49c71414486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e150516900614b2ab6197bcf1cb2bf9d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_510c23a6481746e69e530c5a7a37851c",
      "value": " 806000/826663 [00:02&lt;00:00, 298375.64 examples/s]"
     }
    },
    "ff03838c865a4d2ea5ecb535421d2769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec7e8bda72634bc5bc6040217103ea9d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_bf122a0867834256ba6f9b017555ad4e",
      "value": " 8.48k/8.48k [00:00&lt;00:00, 626kB/s]"
     }
    },
    "ff1cade2f62246ebba857ad29fb1dfd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc750f8412a5492a8ea42fa1a0c1de94",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c29484cac22b42d68599566caf64e0fb",
      "value": "Map:  62%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
