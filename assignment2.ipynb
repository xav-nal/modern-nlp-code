{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0Iyg6btLW9M"
   },
   "source": [
    "#  Assignment 2 - Transfer Learning and Data Augmentation üí¨\n",
    "\n",
    "Welcome to the **second assignment** for the **CS-552: Modern NLP course**!\n",
    "\n",
    "> - üòÄ Name: **< Xavier Nal >**\n",
    "> - ‚úâÔ∏è Email: **< xavier.nal >@epfl.ch**\n",
    "> - ü™™ SCIPER: **288275**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XjnQhbFIJUu"
   },
   "source": [
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid green;background-color:#e4fae4;border-radius: 20px;\">\n",
    "\n",
    "## **Assignment Description**\n",
    "- In the first part of this assignment, you will need to implement training (fine-tuning) and evaluation of a pre-trained language model ([DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) ), on natural language inference (NLI) task for recognizing textual entailment (RTE).\n",
    "\n",
    "- Following the first finetuning task, you will need to identify the shortcut (i.e. some salient or toxic features) that the model learnt for the specific task. \n",
    "\n",
    "- For part-3, you are supposed to annotate 100 randomly assigned test datapoints as ground-truth labels. Additionally, the cross annotation should be conducted by another one or two annotators, and you will learn about how to calculate the agreement statistics as a significant characteristic reflecting the quality of a collected dataset.\n",
    "\n",
    "- For part-4, since the human annotation is quite time- and effort-consuming, there are plenty of ways to get silver-labels from automatic labeling to augment the dataset scale. We provide the reference to some simple methods (EDA and Back Translation) but you are encouraged to explore other advanced mechanisms. You will evaluate the improvement of your model performance by using your data augmentation method.\n",
    "\n",
    "For each part, you will need to complete the code in the corresponding `.py` files (`nli.py` for Part-1, `shortcut.py` for Part-2, `eda.py` for Part-4). You will be provided with the function descriptions and detailed instructions about the code snippet you need to write.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "- **[PART 1: Model Finetuning for NLI](#1)**\n",
    "    - [1.1 Data Processing](#11)\n",
    "    - [1.2 Model Training and Evaluation](#12)\n",
    "- **[PART 2: Identify Model Shortcut](#2)**\n",
    "    - [2.1 Word-Pair Pattern Extraction](#21)\n",
    "    - [2.2 Distill Potentially Useful Patterns](#22)\n",
    "    - [2.3 Case Study](#23)\n",
    "- **[PART 3: Annotate New Data](#3)**\n",
    "    - [3.1 Write an Annotation Guideline](#31)\n",
    "    - [3.2 Annotate Your 100 Datapoints with Partner(s)](#32)\n",
    "    - [3.3 Agreement Measure](#33)\n",
    "    - [3.4 Robustness Check](#34)\n",
    "- **[PART 4: Data Augmentation](#4)**\n",
    "    \n",
    "### Deliverables\n",
    "\n",
    "- ‚úÖ This jupyter notebook\n",
    "- ‚úÖ `nli.py` file\n",
    "- ‚úÖ `shortcut.py` file\n",
    "- ‚úÖ Finetuned DistilBERT models for NLI task (Part 1 and Part 4)\n",
    "- ‚úÖ Annotated and cross-annotated data files (Part 3)\n",
    "- ‚úÖ New dataset from data augmentation (Part 4)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lluaZwaS-0v9"
   },
   "source": [
    "### Google Colab Setup\n",
    "If you are using Google Colab notebook for this assignment, you will need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the popped window, sign in to your Google account. (The same account you used to store this notebook!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30185,
     "status": "ok",
     "timestamp": 1681048978980,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "VfVHqiSvK1aB",
    "outputId": "75f163f1-53db-4dbe-bcbf-760bcb9c64ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opCteyIv-_kS"
   },
   "source": [
    "Now first click the 4th left-side bar (named Files), then click the 2nd bar popped under Files column (named Refresh), under \"/drive/MyDrive/\" find the Assignment 2 folder that you uploaded to your Google Drive, copy its path and fill it in below. If everything is working correctly, then running the folowing cell should print the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['Assignment2.ipynb', 'requirements.txt', 'runs', 'predictions', 'nli_data', 'testA2.py', 'nli.py', 'shortcut.py']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1681048981102,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "agEgK0kdrUdT",
    "outputId": "b874886c-f3ad-4b4f-9317-b02fd1972e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nli_data', 'testA2.py', 'runs', '__pycache__', 'eda.py', 'nli.py', 'shortcut.py', 'requirements.txt', 'runs_augmented_model', 'Assignment2.ipynb']\n",
      "/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# TODO: Fill in the path where you download the Assignment folder into\n",
    "ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2\" # Replace with your directory to A2 folder\n",
    "print(os.listdir(ROOT_PATH))\n",
    "\"choices\"\n",
    "print(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5mABwvHy5-e"
   },
   "source": [
    "Before we start, we also need to run some boilerplate code to set up our environment, same as previous assignments. You'll need to rerun this setup code each time you start the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116603,
     "status": "ok",
     "timestamp": 1681049102556,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "ZhJT7Fo4_D1f",
    "outputId": "1dbf2938-480a-429f-9b87-45003c40a9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
      "Collecting torch==1.13.1+cu116\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp39-cp39-linux_x86_64.whl (1977.9 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m820.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.14.1+cu116\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.14.1%2Bcu116-cp39-cp39-linux_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.13.1\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchaudio-0.13.1%2Bcu116-cp39-cp39-linux_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1+cu116) (4.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1+cu116) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1+cu116) (8.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1+cu116) (1.22.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (3.4)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0+cu118\n",
      "    Uninstalling torch-2.0.0+cu118:\n",
      "      Successfully uninstalled torch-2.0.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.1+cu118\n",
      "    Uninstalling torchvision-0.15.1+cu118:\n",
      "      Successfully uninstalled torchvision-0.15.1+cu118\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.0.1+cu118\n",
      "    Uninstalling torchaudio-2.0.1+cu118:\n",
      "      Successfully uninstalled torchaudio-2.0.1+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\n",
      "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.13.1+cu116 torchaudio-0.13.1+cu116 torchvision-0.14.1+cu116\n",
      "/content/drive/MyDrive/'Colab Notebooks'/mnlp/a2-xav-nal/A2/requirements.txt\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting jsonlines==3.1.0\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Collecting transformers==4.26.1\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 3)) (3.8.1)\n",
      "Collecting apex==0.9.10.dev0\n",
      "  Downloading apex-0.9.10dev.tar.gz (36 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 5)) (1.2.2)\n",
      "Collecting huggingface-hub==0.12.1\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 7)) (1.22.4)\n",
      "Requirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 8)) (4.65.0)\n",
      "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 9)) (1.10.1)\n",
      "Requirement already satisfied: urllib3==1.26.15 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 10)) (1.26.15)\n",
      "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from jsonlines==3.1.0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 1)) (22.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (3.10.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk==3.8.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk==3.8.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 3)) (8.1.3)\n",
      "Collecting cryptacular\n",
      "  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.8/75.8 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting zope.sqlalchemy\n",
      "  Downloading zope.sqlalchemy-2.0-py3-none-any.whl (22 kB)\n",
      "Collecting velruse>=1.0.3\n",
      "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m709.8/709.8 KB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pyramid>1.1.2\n",
      "  Downloading pyramid-2.0.1-py3-none-any.whl (246 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m247.0/247.0 KB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyramid_mailer\n",
      "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting wtforms\n",
      "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m136.5/136.5 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wtforms-recaptcha\n",
      "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.2->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub==0.12.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 6)) (4.5.0)\n",
      "Collecting plaster\n",
      "  Downloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting translationstring>=0.4\n",
      "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
      "Collecting webob>=1.8.3\n",
      "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.0/115.0 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting plaster-pastedeploy\n",
      "  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting venusian>=1.0\n",
      "  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from pyramid>1.1.2->apex==0.9.10.dev0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 4)) (67.6.1)\n",
      "Collecting hupper>=1.5\n",
      "  Downloading hupper-1.12-py3-none-any.whl (22 kB)\n",
      "Collecting zope.deprecation>=3.5.0\n",
      "  Downloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\n",
      "Collecting zope.interface>=3.8.0\n",
      "  Downloading zope.interface-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m246.1/246.1 KB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.9/dist-packages (from velruse>=1.0.3->apex==0.9.10.dev0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 4)) (1.3.1)\n",
      "Collecting anykeystore\n",
      "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting python3-openid\n",
      "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pbkdf2\n",
      "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting transaction\n",
      "  Downloading transaction-3.1.0-py2.py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.3/47.3 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting repoze.sendmail>=4.1\n",
      "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.0/41.0 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.26.1->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.9/dist-packages (from wtforms->apex==0.9.10.dev0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 4)) (2.1.2)\n",
      "Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,<2,>=1.1 in /usr/local/lib/python3.9/dist-packages (from zope.sqlalchemy->apex==0.9.10.dev0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 4)) (1.4.47)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,<2,>=1.1->zope.sqlalchemy->apex==0.9.10.dev0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 4)) (2.0.2)\n",
      "Collecting PasteDeploy>=2.0\n",
      "  Downloading PasteDeploy-3.0.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from python3-openid->velruse>=1.0.3->apex==0.9.10.dev0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex==0.9.10.dev0->-r /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/requirements.txt (line 4)) (3.2.2)\n",
      "Building wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n",
      "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46463 sha256=54d4ade84250120502b76ff2fe8735e02b577125a5eedc15801a2c265d55c86a\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/4a/00/b01a1b3a5adce2b24769c16eb15382dc6044cca56cd6b06d0d\n",
      "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50930 sha256=4abd11ab884bcd627d91eb836fa10c03eae53d9bc9e2b6477ff4b3800bcce2ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/6f/ae/58b88343f17c68e0d11b5ddf60c0edecb30f5df10c82b5d0b6\n",
      "  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp39-cp39-linux_x86_64.whl size=57881 sha256=f9d0e774358cc31bfd96230cf85244ce71d35f0e4576ca20a10fceeab1e78c37\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/fb/44/920f35039c8e9ae372bb7e05f01fe01d352faf2723cea29fb1\n",
      "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16832 sha256=08b94c4b8dc66c4d58f97741c0cf9e0a6a117998b96020b250c010a0bb01c833\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/70/45/2a8f0d9c194e281bca441960ed6f30ddd01d8ed61b443f00b0\n",
      "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5101 sha256=6ac835df1b22c9bd6b24a4f20e6de8d0b09db7c83d790583aef8218194046d3b\n",
      "  Stored in directory: /root/.cache/pip/wheels/25/d2/61/653b7e13d58b8a1ea237868585640fcd626f24a1fdfe3f74d0\n",
      "Successfully built apex velruse cryptacular anykeystore pbkdf2\n",
      "Installing collected packages: translationstring, tokenizers, pbkdf2, anykeystore, zope.interface, zope.deprecation, wtforms, webob, venusian, python3-openid, plaster, PasteDeploy, jsonlines, hupper, cryptacular, wtforms-recaptcha, transaction, plaster-pastedeploy, huggingface-hub, zope.sqlalchemy, transformers, repoze.sendmail, pyramid, velruse, pyramid_mailer, apex\n",
      "Successfully installed PasteDeploy-3.0.1 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 huggingface-hub-0.12.1 hupper-1.12 jsonlines-3.1.0 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.1 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 tokenizers-0.13.3 transaction-3.1.0 transformers-4.26.1 translationstring-1.4 velruse-1.1.1 venusian-3.0.0 webob-1.8.7 wtforms-3.0.1 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-6.0 zope.sqlalchemy-2.0\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH_pip = \"/content/drive/MyDrive/'Colab Notebooks'/mnlp/a2-xav-nal/A2\"\n",
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "requirements = ROOT_PATH_pip + \"/requirements.txt\"\n",
    "print(requirements)\n",
    "!pip install -r {requirements}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUw9ycDa21dl"
   },
   "source": [
    "\n",
    "Run this cell to load the autoreload extension. This allows us to edit .py source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681049102557,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "3PVAoLPQ_I7c"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5231,
     "status": "ok",
     "timestamp": 1681049107778,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "mA1Qk-_K_LRm"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_constant_schedule_with_warmup\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csa48DhDr0td"
   },
   "source": [
    "Once you have successfully mounted your Google Drive and located the path to this assignment, run the following cell to allow us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n",
    "\n",
    "```\n",
    "Hello A2!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1681049108530,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "U10S-b9BrNxj",
    "outputId": "20d8973b-8c44-4b5e-d267-8b68b89c0821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello A2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "from testA2 import hello_A2\n",
    "hello_A2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnWpzntscWUE"
   },
   "source": [
    "Note that if CUDA is not enabled, `torch.cuda.is_available()` will return False and this notebook will fallback to CPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1681049108531,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "Rqb9cwkNIEHr",
    "outputId": "471aca82-a585-4a34-a9f9-c180512e58c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  print('Good to go!')\n",
    "else:\n",
    "  print('Please set GPU via Edit -> Notebook Settings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MSpYuMcyHfl"
   },
   "source": [
    "### Local Setup\n",
    "If you skip Google Colab setup, you still need to fill in the path where you download the Assignment folder, and install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQHs7vHhydij"
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = \"../A2\" # Replace with your directory to A2 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3444,
     "status": "ok",
     "timestamp": 1680389857820,
     "user": {
      "displayName": "xavier nal",
      "userId": "05038496635256051122"
     },
     "user_tz": -120
    },
    "id": "IKeGSDpAyigE",
    "outputId": "908002ad-4816-4f1c-a8e8-2cd71e843b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../A2/requirements.txt\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '../A2/requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "requirements = ROOT_PATH + \"/requirements.txt\"\n",
    "print(requirements)\n",
    "!pip install -r {requirements}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 1057,
     "status": "error",
     "timestamp": 1680389858867,
     "user": {
      "displayName": "xavier nal",
      "userId": "05038496635256051122"
     },
     "user_tz": -120
    },
    "id": "BDlk7XP7F4B9",
    "outputId": "e4631ee1-a78f-4e4b-97f7-c7755fb04ec8"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-622609f46675>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../A2/requirements.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../A2/requirements.txt'"
     ]
    }
   ],
   "source": [
    "with open('../A2/requirements.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1680389910194,
     "user": {
      "displayName": "xavier nal",
      "userId": "05038496635256051122"
     },
     "user_tz": -120
    },
    "id": "C6b-Enimyywz",
    "outputId": "66eaa0c9-3139-4670-e0eb-020690320ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6dgLZ9kyqpO"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import sys\n",
    "import time, os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_constant_schedule_with_warmup\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHhgkhaH-IUl"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## **PART 1: Finetuning DistilBERT for NLI**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD2YPuqeIYBN"
   },
   "source": [
    "### **What is the NLI task?üßê**\n",
    "> Given a pair of sentences, denoted as a \"premise\" sentence and a \"hypothesis\" sentence, NLI (or RTE) aims to determine their logical relationship, i.e. whether they are logically follow (entailment), unfollow (contradiction) or are undetermined (neutral) to each other.\n",
    "\n",
    "> Defined as a machine learning task, NLI can be considered as a 3-classes (entailment, contradiction, or neutral) classification task, with a sentence-pair input (\"hypothesis\" and ‚Äúpremise‚Äù).\n",
    "\n",
    "> **You can run the following cell to have the first glance at your data**. Each data sample is a python dictionary, which consists of following components:\n",
    "- premise sentence (*'premise'*), \n",
    "- hypothesis sentence (*'hypothesis'*) \n",
    "- domain (*'domain'*): describing the topic of premise and hypothesis sentences (e.g., government regulations, telephone talks, etc.)\n",
    "- label (*'label'*): indicating the logical relation between premise and hypothesis (i.e., entailment, contradiction, or neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1681049108533,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "p-ODgcNUqYtm",
    "outputId": "566b2d3a-036d-4de7-a659-fa75def94876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise The new rights are nice enough\n",
      "hypothesis Everyone really likes the newest benefits \n",
      "label neutral\n",
      "\n",
      "\n",
      "premise This site includes a list of all award winners and a searchable database of Government Executive articles.\n",
      "hypothesis The Government Executive articles housed on the website are not able to be searched.\n",
      "label contradiction\n",
      "\n",
      "\n",
      "premise uh i don't know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him\n",
      "hypothesis I like him for the most part, but would still enjoy seeing someone beat him.\n",
      "label entailment\n",
      "\n",
      "\n",
      "premise yeah i i think my favorite restaurant is always been the one closest  you know the closest as long as it's it meets the minimum criteria you know of good food\n",
      "hypothesis My favorite restaurants are always at least a hundred miles away from my house. \n",
      "label contradiction\n",
      "\n",
      "\n",
      "premise i don't know um do you do a lot of camping\n",
      "hypothesis I know exactly.\n",
      "label contradiction\n",
      "\n",
      "\n",
      "premise well that would be a help i wish they would do that here we have got so little landfill space left that we're going to run out before the end of this decade and it's really going to be\n",
      "hypothesis We have plenty of space in the landfill.\n",
      "label contradiction\n",
      "\n",
      "\n",
      "premise yeah i know and i did that all through college and it worked too\n",
      "hypothesis I did that all through college but it never worked \n",
      "label contradiction\n",
      "\n",
      "\n",
      "premise Calcutta seems to be the only other production center having any pretensions to artistic creativity at all, but ironically you're actually more likely to see the works of Satyajit Ray or Mrinal Sen shown in Europe or North America than in India itself.\n",
      "hypothesis Most of Mrinal Sen's work can be found in European collections.\n",
      "label neutral\n",
      "\n",
      "\n",
      "premise If that investor were willing to pay extra for the security of limited downside, she could buy put options with a strike price of $98, which would lock in her profit on the shares at $18, less whatever the options cost.\n",
      "hypothesis THe strike price could be $8.\n",
      "label contradiction\n",
      "\n",
      "\n",
      "premise 3)  Dare you rise to the occasion, like Raskolnikov, and reject the petty rules that govern lesser men?\n",
      "hypothesis Would you rise up and defeaat all evil lords in the town?\n",
      "label neutral\n",
      "\n",
      "\n",
      "premise The most important directions are simply up and up leads eventually to the cathedral and fortress commanding the hilltop, and down inevitably leads to one of three gates through the wall to the new town.\n",
      "hypothesis Go downwards to one of the gates, all of which will lead you into the cathedral.\n",
      "label contradiction\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you use Google Colab, then data_dir = 'GOOGLE_DRIVE_PATH/nli_data'\n",
    "data_dir = ROOT_PATH+'/nli_data'\n",
    "data_dev_path = os.path.join(data_dir, 'dev_in_domain.jsonl')\n",
    "with jsonlines.open(data_dev_path, \"r\") as reader:\n",
    "    for sid, sample in enumerate(reader.iter()):\n",
    "        print('premise', sample['premise'])\n",
    "        print('hypothesis', sample['hypothesis'])\n",
    "        print('label', sample['label'])\n",
    "        print('\\n')\n",
    "        if sid == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1681049108534,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "FF-dRWc7MZlL"
   },
   "outputs": [],
   "source": [
    "# Enter enter your Sciper number\n",
    "SCIPER = '288275'\n",
    "seed = int(SCIPER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1681049108534,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "9UPdzLSi4ZVt",
    "outputId": "f7a66745-93b7-4501-b63a-e2037ebd34b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your random seed is:  288275\n"
     ]
    }
   ],
   "source": [
    "print('Your random seed is: ', seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "b7ae14ff66d849c98e884abc434a4191",
      "437038259ba14d04aeb9e01c978fd078",
      "f389ecef7f534b3c9993144948a25dfd",
      "a5530c446fd24b34ae4b23466dea1bee",
      "f5a2b61845334ad98f8d57f193a863c6",
      "6093327e1ae74e088edaf0b26ad345dc",
      "574bc35577904e68b93d3967e252bc02",
      "b2b55eb05fc94f118d4422efeb2783ca",
      "dba432aa5c584887b716ae8f92caf2c1",
      "07591f54f67f4aa383df004151959cc2",
      "e3a83c60434548db83d57e6b59719182",
      "e7878ed83f06451c9e57a2954da2a86f",
      "7db7091ea57a4e409ae91152b7d2954f",
      "5f343dc094df4ce0adfa353f00d6d4c6",
      "06ae494556304049a67dff1c6a988cd0",
      "6f8a6bc534a1442e8df57fa5b6d1dcf5",
      "d083fa43cf3f45fab704a99bfd523d21",
      "608ee6363f7e4d9496dd7fb6db886ac4",
      "692d2d570a3641ee87a94e991fb36147",
      "ed3de58374664836a7997b703eb3d21a",
      "ce9ae65fd8b84ae3a099037271704096",
      "28350af55ee142b49689f5eddd2a4043",
      "81024a6a91d74f4a99487dbb6ad65e40",
      "f71f39d88d0246d994b2670f47e6be9c",
      "884e6e0b834a45e9882516ba9e63e09d",
      "db5f4a3ec37d4bba95a700d7b953f10d",
      "dc299c5611a7471482671a3b0e5b35ac",
      "6a8cff0c1f94402a8b0cdbca505ca2e3",
      "009cb23db59e4afab43848eaad06220a",
      "97e3364723f642a68ea54390b65a5e13",
      "04fead673bc9474280c829a2f2fb3594",
      "8c87d4d16c7c490d82c3f2ef5963f0c0",
      "622343e18cf84d1dafd40553a5ca7cd7",
      "6dad2c85abf047c5b784a254980c9e00",
      "62c321a54b4a40218f6b97e4daea7185",
      "848440db3e9c4eb7a0208dde4e398891",
      "3aa2a028b19a42f49a2653f7abba9c1a",
      "b882a7b7f6564c6bb56831807d28b947",
      "d6fe4339b15a4aeb82716e3e08e43f48",
      "c9c85a25c5f043ffbc7748aea855d06c",
      "eafd74ba82864714b6f0541683335788",
      "e08ec8fe730d49ce9a51d433027000d3",
      "f4c4444adac7444da6584fbad6446d68",
      "6723243eeb6f4a499ab9a2faf50304a9"
     ]
    },
    "executionInfo": {
     "elapsed": 4329,
     "status": "ok",
     "timestamp": 1681049112841,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "GnX8VC4C0sHW",
    "outputId": "6caf15d8-5344-4c58-b409-aac379e972d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ae14ff66d849c98e884abc434a4191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7878ed83f06451c9e57a2954da2a86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81024a6a91d74f4a99487dbb6ad65e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dad2c85abf047c5b784a254980c9e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)\"pytorch_model.bin\";:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# We use the following pretrained tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCETOFT2dB4u"
   },
   "source": [
    "### **1.1 Dataset Processing**\n",
    "Our first step is to load datasets for NLI task by constructing a Pytorch Dataset. Specifically, we will need to implement tokenization and padding with a HuggingFace pre-trained tokenizer.\n",
    "\n",
    "**Complete `NLIDataset` class following the instructions in `nli.py`, and test by running the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148,
     "referenced_widgets": [
      "224bb87361de40fa8715dd1674626707",
      "7f39ebc74ff741d8bec167093a51e1a1",
      "c405f03c8ca54009a5a5b92d11eef7b0",
      "b034bb3b386940b5a4f978ee84d9b007",
      "0b2a3294e40b43898683dd4e52279e11",
      "d95d3459d66b419db682be37f1e91f8f",
      "1f2e44badc56447cadff94811f586ee7",
      "3d543482b9a140ec8dfd331a57c1d2a6",
      "e9bf1f93880647749d6ef01ab21e0356",
      "09db8a5a023c44698129284f303aafa2",
      "612f14045cf64834b1b1b8ccdfa5f3a3",
      "48c1e22ce1cd427c9693f4727ab15666",
      "885feb5578e2406d95ad72c72f2dcb53",
      "d8c7558b6a354b9e9d98892d88a07ab9",
      "089a31b2df724582ab6209c105cfea94",
      "91917d87349e41078e548fa897df844f",
      "349577d5964a4ad9ad06f88bbbee465c",
      "b28f0d120a364c339f7dc8aaffa2f414",
      "afac91edae2843e89f7504795e2e6658",
      "d4594c00cf86453e9cba7d5b7e1fe5f1",
      "18b27074b7994418a5df559618893bd0",
      "a9009a8d2557415c8c5d67d55dcb58ef",
      "b6e568729b994312a0cd486399267ca1",
      "e18f541420224c9f92443389c9bc1e3f",
      "aa9da2da6ab24b89838aec95dcc8cd14",
      "d4c77cf5d94e4b038b22894925132576",
      "57e0c7e30a69429b8657a79ea8ba85d6",
      "52a803f63e614455be6764d621b04575",
      "84ed04123dd34e79b5c4a33e58e777d1",
      "94c25a1c235c43fc9f4b3065135251d4",
      "dae41dda4f22453ea146c046ac666ea5",
      "36adec8bb3fa456a87731d5cb5fe5340",
      "e1abd14bd2be47dcae479eaeb2541632"
     ]
    },
    "executionInfo": {
     "elapsed": 11449,
     "status": "ok",
     "timestamp": 1680467232697,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "_5Sya9W5BTDl",
    "outputId": "c5b50407-7e7d-4037-be88-15513f4a6fb3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224bb87361de40fa8715dd1674626707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c1e22ce1cd427c9693f4727ab15666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e568729b994312a0cd486399267ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9815it [00:08, 1121.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nli import NLIDataset\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "dataset = NLIDataset(ROOT_PATH+\"/nli_data/dev_in_domain.jsonl\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1680467233057,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "ynLhjRuq8vF9",
    "outputId": "3332df9e-c5ac-4b9c-b220-9deed96bbd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLIDataset test correct ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "from testA2 import test_NLIDataset\n",
    "test_NLIDataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0weQpG6_3vO"
   },
   "source": [
    "### **1.2 Model Training and Evaluation**\n",
    "Next, we will implement the training and evaluation process to finetune the model. For model training, you will need to calculate the loss and update the model weights by update the optimizer. Additionally, we add a learning rate schedular to adopt an adaptive learning rate during the whole training process. \n",
    "\n",
    "For evaluation, you will need to compute accuracy and F1 scores to assess the model performance. \n",
    "\n",
    "**Complete the `compute_metric()`, `train()` and `evaluate()` functions following the instructions in the `nli.py` file, you can test compute_metric() by running the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1681049132583,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "6w7Leraw4tIY",
    "outputId": "c8b80a5d-244e-4277-dead-7628c5660ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_metric test correct ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "from nli import evaluate, train, compute_metrics\n",
    "from testA2 import test_compute_metrics\n",
    "test_compute_metrics(compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvCUS748_3vS"
   },
   "source": [
    "#### **Start Training and Validation!**\n",
    "\n",
    "Try the following different hyperparameter settings, compare and discuss the results. (Other hyperparameters should not be changed.)\n",
    "\n",
    "> A. learning_rate 2e-5\n",
    "\n",
    "> B. learning_rate 5e-5\n",
    "\n",
    "**Note:** *Each training will take about 1 hour using a GPU, please keep your computer and notebook active during the training.*\n",
    "\n",
    "**Questions: Which learning rate is better? Explain your answers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87664,
     "status": "ok",
     "timestamp": 1680441583786,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "zn66mMOj_3vS",
    "outputId": "325c87e0-3b09-4f6c-c136-9b549c6e89f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98176it [01:12, 1347.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9815it [00:07, 1390.13it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = NLIDataset(ROOT_PATH+\"/nli_data/train.jsonl\", tokenizer)\n",
    "dev_dataset = NLIDataset(ROOT_PATH+\"/nli_data/dev_in_domain.jsonl\", tokenizer)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 4\n",
    "max_grad_norm = 1.0\n",
    "warmup_percent = 0.3\n",
    "model_save_root = ROOT_PATH+'/runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1004923,
     "status": "ok",
     "timestamp": 1680442667283,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "an7lzsAywGxE",
    "outputId": "6c98de67-31fd-466f-b492-d8ec35ad1c33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " path save repo /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/runs/lr5e-05-warmup0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:06<00:00, 24.88it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 0.949 | Validation Loss: 0.737\n",
      "Epoch 0 NLI Validation:\n",
      "Accuracy: 68.29% | F1: (73.30%, 62.55%, 68.02%) | Macro-F1: 67.95%\n",
      "Model Saved at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:01<00:00, 25.46it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.647 | Validation Loss: 0.598\n",
      "Epoch 1 NLI Validation:\n",
      "Accuracy: 75.33% | F1: (78.91%, 70.85%, 75.94%) | Macro-F1: 75.23%\n",
      "Model Saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:00<00:00, 25.46it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.486 | Validation Loss: 0.588\n",
      "Epoch 2 NLI Validation:\n",
      "Accuracy: 76.58% | F1: (80.63%, 71.63%, 76.55%) | Macro-F1: 76.27%\n",
      "Model Saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:00<00:00, 25.47it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 0.316 | Validation Loss: 0.695\n",
      "Epoch 3 NLI Validation:\n",
      "Accuracy: 75.96% | F1: (79.44%, 70.44%, 77.24%) | Macro-F1: 75.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model_lr5 = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model_lr5.to(device)\n",
    "\n",
    "learning_rate = 5e-5 # play around with this hyperparameter\n",
    "\n",
    "train(train_dataset, dev_dataset, model_lr5, device, batch_size, epochs,\n",
    "      learning_rate, warmup_percent, max_grad_norm, model_save_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1006964,
     "status": "ok",
     "timestamp": 1680443801313,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "SVnz6G5NCFeq",
    "outputId": "4b111667-8d90-4db0-e52e-2c81f8c4d1f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " path save repo /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/runs/lr2e-05-warmup0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:03<00:00, 25.20it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 0.949 | Validation Loss: 0.737\n",
      "Epoch 0 NLI Validation:\n",
      "Accuracy: 68.29% | F1: (73.30%, 62.55%, 68.02%) | Macro-F1: 67.95%\n",
      "Model Saved at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:01<00:00, 25.46it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.647 | Validation Loss: 0.598\n",
      "Epoch 1 NLI Validation:\n",
      "Accuracy: 75.33% | F1: (78.91%, 70.85%, 75.94%) | Macro-F1: 75.23%\n",
      "Model Saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:01<00:00, 25.40it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.486 | Validation Loss: 0.588\n",
      "Epoch 2 NLI Validation:\n",
      "Accuracy: 76.58% | F1: (80.63%, 71.63%, 76.55%) | Macro-F1: 76.27%\n",
      "Model Saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:01<00:00, 25.43it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 0.316 | Validation Loss: 0.695\n",
      "Epoch 3 NLI Validation:\n",
      "Accuracy: 75.96% | F1: (79.44%, 70.44%, 77.24%) | Macro-F1: 75.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "learning_rate = 2e-5 # play around with this hyperparameter\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model_lr2 = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model_lr2.to(device)\n",
    "\n",
    "train(train_dataset, dev_dataset, model_lr2, device, batch_size, epochs,\n",
    "      learning_rate, warmup_percent, max_grad_norm, model_save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGuzGJCB_3vT"
   },
   "source": [
    "### **Fine-Grained Validation**\n",
    "\n",
    "Use the model checkpoint saved under the first hyperparameter setting (learning_rate 2e-5) in 1.4, check the model performance on each domain subsets of the validation set, report the validation loss, accuracy, F1 scores and Macro-F1 on each domain, compare and discuss the results.\n",
    "\n",
    "**Questions: On which domain does the model perform the best? the worst? Give some possible explanations of why the model's best-performed domain is easier, and why the model's worst-performed domain is more challenging. Use some examples to support your explanations.**\n",
    "\n",
    "**Note:** To find examples for supporting your discussion, save the model prediction results on each domain under the './predictions/' folder, by specifying the *result_save_file* of the *evaluate* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27501,
     "status": "ok",
     "timestamp": 1680467282202,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "YCWWJjTP_3vT",
    "outputId": "6ccfbbf3-53ad-4f86-e780-e1e73aec2cde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9815it [00:25, 377.69it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "warmup_percent = 0.3\n",
    "# checkpoint = ROOT_PATH+'/runs/lr{}-warmup{}/model_epoch2.pt'.format(learning_rate, warmup_percent)\n",
    "\n",
    "# Split the validation sets into subsets with different domains\n",
    "# Save the subsets under './nli_data/'\n",
    "# Replace \"...\" with your code\n",
    "...\n",
    "\n",
    "# Define the set of domains\n",
    "domains = set([\"fiction\", \"government\", \"slate\", \"telephone\", \"travel\"])\n",
    "\n",
    "# Define the path to the output directory\n",
    "output_dir = os.path.join(ROOT_PATH, \"nli_data\")\n",
    "\n",
    "# Initialize the output files for each domain\n",
    "output_files = {domain: os.path.join(output_dir, f\"dev_{domain}.jsonl\") for domain in domains}\n",
    "for file in output_files.values():\n",
    "    with open(file, \"w\"):\n",
    "        pass\n",
    "\n",
    "# Iterate over the input samples and write them to the appropriate output file\n",
    "with jsonlines.open(ROOT_PATH+\"/nli_data/dev_in_domain.jsonl\", \"r\") as reader:\n",
    "    for sample in tqdm(reader.iter()):\n",
    "        # print(sample)\n",
    "        domain = sample['domain']\n",
    "        output_file = output_files.get(domain)\n",
    "        with jsonlines.open(output_file, \"a\") as writer:\n",
    "          writer.write(sample)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-I6GndtY2cT"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "epoch = 2\n",
    "learning_rate = 2e-5\n",
    "warmup_percent = 0.3\n",
    "repo =  ROOT_PATH+f'/runs/lr{learning_rate}-warmup{warmup_percent}'\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer_checkpoint = os.path.join(repo, 'tokenizer_epoch{}.pt'.format(epoch))\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "\n",
    "# load params model\n",
    "model_checkpoint = os.path.join(repo, 'model_epoch{}.pt'.format(epoch))\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "state_dict = torch.load(model_checkpoint)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14412,
     "status": "ok",
     "timestamp": 1680450037962,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "Q4J2pu60xHTd",
    "outputId": "f6c58ff0-90f7-4779-ed88-453de30c8ff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1973it [00:01, 1935.53it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 124/124 [00:01<00:00, 116.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: fiction\n",
      "Validation Loss: 0.596 | Accuracy: 76.43%\n",
      "F1: (79.45%, 71.58%, 77.38%) | Macro-F1: 76.14%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1945it [00:01, 1171.79it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122/122 [00:01<00:00, 97.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: government\n",
      "Validation Loss: 0.472 | Accuracy: 81.54%\n",
      "F1: (85.26%, 77.73%, 80.86%) | Macro-F1: 81.28%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1955it [00:01, 1367.75it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:01<00:00, 100.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: slate\n",
      "Validation Loss: 0.696 | Accuracy: 71.30%\n",
      "F1: (75.71%, 64.80%, 72.19%) | Macro-F1: 70.90%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1966it [00:01, 1407.34it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:01<00:00, 86.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: telephone\n",
      "Validation Loss: 0.614 | Accuracy: 75.18%\n",
      "F1: (79.50%, 68.97%, 76.05%) | Macro-F1: 74.84%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1976it [00:02, 913.36it/s] \n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 124/124 [00:01<00:00, 98.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: travel\n",
      "Validation Loss: 0.551 | Accuracy: 78.80%\n",
      "F1: (83.76%, 75.13%, 76.79%) | Macro-F1: 78.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the output files prediction for each domain\n",
    "domains = set([\"fiction\", \"government\", \"slate\", \"telephone\", \"travel\"])\n",
    "output_dir = os.path.join(ROOT_PATH, \"nli_data/predictions\")\n",
    "output_files = {domain: os.path.join(output_dir, f\"dev_pred_{domain}.jsonl\") for domain in domains}\n",
    "for file in output_files.values():\n",
    "    with open(file, \"w\"):\n",
    "        pass\n",
    "\n",
    "for domain in [\"fiction\", \"government\", \"slate\", \"telephone\", \"travel\"]:\n",
    "    \n",
    "    # Evaluate and save prediction results in each domain\n",
    "    # Replace \"...\" with your code\n",
    "    data_files= f\"/nli_data/dev_{domain}.jsonl\"\n",
    "    dev_domain_dataset = NLIDataset(ROOT_PATH + data_files, tokenizer)\n",
    "\n",
    "    result_save_file = f'/nli_data/predictions/dev_pred_{domain}.json'\n",
    "    dev_loss, acc, f1_ent, f1_neu, f1_con = evaluate(dev_domain_dataset, model, device,  batch_size, result_save_file= ROOT_PATH + result_save_file)\n",
    "    \n",
    "    macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n",
    "    \n",
    "    print(f'Domain: {domain}')\n",
    "    print(f'Validation Loss: {dev_loss:.3f} | Accuracy: {acc*100:.2f}%')\n",
    "    print(f'F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTq12l1JdQt7"
   },
   "source": [
    "The model performs better on governement domain ( 81.54% of accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NyMZ5E4-QxM"
   },
   "source": [
    "## **Task2: Identify Shortcuts**\n",
    "\n",
    "We aim to find some shortcuts that the model in 1.4 (under the first hyperparameter setting) has learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lCHLdaH_3vT"
   },
   "source": [
    "### **2.1 Word-Pair Pattern Extraction**\n",
    "\n",
    "We consider to exatrct simple word-pair patterns that the model may have learned from the NLI data. \n",
    "\n",
    "For this, we assume that a pair of words that occur in a premise-hypothesis sentence pair (one occurs in premise and the other occurs in hypothesis) may serve as a key indicator of the logical relationship between the premise and hypothesis sentences. For example:\n",
    "\n",
    ">- Premise: Consider the United States Postal Service.\n",
    ">- Hypothesis: Forget the United States Postal Service.\n",
    "\n",
    "Here the word-pair \"consider\" and \"forget\" determine that the premise and hypothesis have a *contradiction* relationship, so (consider, forget) --> *contradiction* might be a good pattern to learn.\n",
    "\n",
    "**Note:** \n",
    "- We do not consider the naive word pair patterns where the word from premise and the word from hypothesis are identical, e.g., (service, service) got from the above premise-hypothesis sentence pair.\n",
    "- We do not consider stop words neither, punctuations and words that contain special prefix '##', e.g., '##s' in the pattern extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NovYRxv_3vU"
   },
   "source": [
    "**Complete `word_pair_extraction()` function in `shortcut.py` file.**\n",
    "\n",
    "The keys of the returned dictionary *word_pairs* should be **different word-pairs** appered in premise-hypothesis sentence pairs, i.e., (a word from the premise, a word from the hypothesis).\n",
    "\n",
    "The value of a word-pair key records the counts of entailment, neutral and contradiction predictions **made by the model** when the word-pair occurs, i.e., \\[#entailment_predictions, #neutral_predictions,  #contradiction_predictions\\].\n",
    "\n",
    "**Note:** Remember to remove naive word pairs (i.e., premise word identical to hypothesis word), stop_words, puntuations and words with special prefix '##' out of consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1681036664735,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "Z_dY1by65sSd",
    "outputId": "667d4fcc-c64a-454b-8420-506779bc86a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import jsonlines\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.append('uh')\n",
    "\n",
    "import string\n",
    "puncs = string.punctuation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.append('uh')\n",
    "\n",
    "import string\n",
    "puncs = string.punctuation\n",
    "\n",
    "epoch = 2\n",
    "learning_rate = 2e-5\n",
    "warmup_percent = 0.3\n",
    "repo =  ROOT_PATH+f'/runs/lr{learning_rate}-warmup{warmup_percent}'\n",
    "# load tokenizer\n",
    "tokenizer_checkpoint = os.path.join(repo, 'tokenizer_epoch{}.pt'.format(epoch))\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTHt1frZ_3vU"
   },
   "source": [
    "### **2.2 Distill Potentially Useful Patterns**\n",
    "\n",
    "Find and print the **top-100** word-pairs that are associated with the **largest total number** of model predictions, which might contain frequently used patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFZm6tFJFmlg"
   },
   "outputs": [],
   "source": [
    "from shortcut import word_pair_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1681036671579,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "zpPmLdcOADdE",
    "outputId": "5add9a5b-aafd-4085-bdb8-843e9b65385f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_fiction.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_government.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_government.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_slate.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_fiction.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_travel.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_slate.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_travel.json']\n"
     ]
    }
   ],
   "source": [
    "# all your saved model prediction results in 1.2 Fine-Grained Validation\n",
    "folder_path = ROOT_PATH + \"/nli_data/predictions\"\n",
    "prediction_files = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    prediction_files.append(os.path.join(folder_path, filename))\n",
    "\n",
    "print(prediction_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15683,
     "status": "ok",
     "timestamp": 1681036689098,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "TUyal5mW_3vU",
    "outputId": "1a34ccca-3d19-41a0-c917-5fd26d7f4765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_fiction.json\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_government.json\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_government.jsonl\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_slate.jsonl\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_fiction.jsonl\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_travel.jsonl\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.jsonl\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_slate.json\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.json\n",
      "files /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_travel.json\n",
      "word_pairs 373356\n"
     ]
    }
   ],
   "source": [
    "word_pairs = word_pair_extraction(prediction_files, tokenizer)\n",
    "\n",
    "print('word_pairs', len(word_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 974,
     "status": "ok",
     "timestamp": 1681035265198,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "bTR-srOXZtSb",
    "outputId": "54ed7561-a70f-44b0-a545-033651dbf6d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 17]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs[('like', 'never')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1681036721345,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "s6paSQBO8h9-"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "# {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "\n",
    "sum_word_pairs = {}\n",
    "\n",
    "# Compute occurences\n",
    "for pair, freq in word_pairs.items():\n",
    "    total_freq = sum(freq)\n",
    "    sum_word_pairs[pair] = total_freq\n",
    "\n",
    "\n",
    "# find top-100 word-pairs associated with the largest total number of model predictions\n",
    "top_100_pairs = collections.Counter(sum_word_pairs).most_common(100)\n",
    "# print(top_100_pairs)\n",
    "\n",
    "# to add again the value information\n",
    "top_100_pairs_labels = {}\n",
    "for key, freq in top_100_pairs:\n",
    "  label = word_pairs[key]\n",
    "  top_100_pairs_labels[key] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681036723985,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "rpYXndVsAkec",
    "outputId": "e49029af-e94f-4ec4-aa2b-ebf6d23dda06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('services', 'legal'): [24, 18, 19], ('legal', 'services'): [21, 11, 18], ('know', 'time'): [8, 24, 14], ('postal', 'service'): [16, 13, 13], ('service', 'postal'): [14, 11, 12], ('know', 'people'): [16, 16, 4], ('know', 'money'): [13, 16, 7], ('know', 'like'): [18, 15, 3], ('know', 'lot'): [10, 21, 4], ('know', 'watch'): [11, 12, 12], ('yeah', 'like'): [9, 11, 13], ('know', 'make'): [5, 15, 11], ('know', 'get'): [6, 13, 10], ('would', 'could'): [7, 15, 6], ('like', 'think'): [16, 10, 1], ('last', 'years'): [13, 6, 8], ('know', 'never'): [1, 0, 26], ('yeah', 'one'): [7, 6, 14], ('year', 'last'): [10, 6, 10], ('yeah', 'time'): [5, 8, 13], ('like', 'lot'): [13, 10, 2], ('know', 'would'): [2, 17, 6], ('know', 'think'): [9, 2, 14], ('know', 'go'): [6, 5, 14], ('one', 'people'): [11, 9, 4], ('test', 'toxicity'): [8, 8, 8], ('yeah', 'never'): [5, 1, 18], ('yeah', 'get'): [6, 13, 5], ('first', 'mail'): [6, 6, 11], ('last', 'year'): [11, 5, 7], ('know', 'children'): [5, 11, 7], ('ca', 'da'): [8, 6, 8], ('da', 'ca'): [8, 6, 8], ('think', 'would'): [4, 12, 6], ('many', 'people'): [11, 6, 5], ('would', 'people'): [4, 12, 6], ('could', 'would'): [6, 14, 2], ('saving', 'savings'): [12, 5, 5], ('know', 'well'): [8, 5, 9], ('kids', 'children'): [10, 6, 6], ('know', 'try'): [10, 2, 10], ('know', 'year'): [10, 8, 4], ('one', 'last'): [7, 8, 6], ('mail', 'service'): [8, 6, 7], ('legal', 'state'): [8, 2, 11], ('know', 'take'): [5, 10, 6], ('like', 'never'): [3, 1, 17], ('know', 'happen'): [1, 11, 9], ('know', 'way'): [12, 4, 5], ('know', 'even'): [6, 8, 7], ('one', 'get'): [6, 10, 4], ('really', 'would'): [7, 5, 8], ('two', 'one'): [5, 5, 10], ('try', 'would'): [7, 1, 12], ('one', 'like'): [8, 5, 7], ('well', 'get'): [6, 7, 7], ('saving', 'personal'): [9, 6, 5], ('gao', 'president'): [4, 8, 8], ('york', 'new'): [9, 6, 5], ('state', 'legal'): [8, 5, 7], ('know', 'day'): [9, 4, 7], ('yeah', 'true'): [9, 3, 8], ('know', 'really'): [3, 7, 10], ('would', 'debt'): [0, 14, 6], ('really', 'like'): [6, 8, 5], ('class', 'mail'): [5, 5, 9], ('mail', 'postal'): [6, 5, 8], ('president', 'gao'): [4, 9, 6], ('costs', 'cost'): [9, 5, 5], ('may', 'might'): [13, 4, 2], ('well', 'time'): [9, 4, 6], ('even', 'people'): [5, 14, 0], ('yeah', 'really'): [8, 6, 5], ('know', 'kids'): [8, 2, 9], ('yeah', 'think'): [5, 2, 12], ('lot', 'would'): [7, 5, 7], ('going', 'get'): [7, 8, 3], ('time', 'would'): [6, 3, 9], ('life', 'whole'): [6, 6, 6], ('state', 'l'): [5, 7, 6], ('case', 'studies'): [8, 4, 6], ('year', 'one'): [7, 6, 5], ('legal', 'aid'): [8, 6, 4], ('toxicity', 'test'): [6, 6, 6], ('think', 'believe'): [14, 4, 0], ('yeah', 'lot'): [5, 12, 1], ('know', 'could'): [7, 6, 5], ('yeah', 'go'): [5, 4, 9], ('one', 'many'): [5, 8, 4], ('know', 'long'): [6, 9, 2], ('way', 'get'): [7, 7, 3], ('good', 'bad'): [4, 2, 11], ('like', 'could'): [6, 9, 2], ('national', 'saving'): [9, 3, 5], ('whole', 'life'): [6, 5, 6], ('audit', 'auditor'): [7, 3, 7], ('new', 'york'): [7, 5, 5], ('technology', 'information'): [8, 4, 5], ('one', 'year'): [7, 7, 3], ('information', 'state'): [17, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# find top-100 word-pairs associated with the largest total number of model predictions\n",
    "top_100_freq_pairs = top_100_pairs_labels\n",
    "\n",
    "print(top_100_freq_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz25EvuI_3vU"
   },
   "source": [
    "**Among the top-100 frequent word-pairs above**, find out the **top-5** word-pairs whose occurances **most likely** lead to *entailment* predictions (entailment patterns), and the **top-5** word-pairs whose occurances **most likely** lead to *contradiction* predictions (contradiction patterns).\n",
    "\n",
    "**Explain your rules for finding these word pairs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681036741214,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "Yq2cVOaWTEYw",
    "outputId": "a1fe5a54-6523-45ef-d775-6f1f5f3f8c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entailment Patterns:\n",
      "[(('services', 'legal'), [24, 18, 19]), (('legal', 'services'), [21, 11, 18]), (('know', 'like'), [18, 15, 3]), (('information', 'state'), [17, 0, 0]), (('postal', 'service'), [16, 13, 13])]\n",
      "Contradiction Patterns:\n",
      "[(('know', 'never'), [1, 0, 26]), (('services', 'legal'), [24, 18, 19]), (('legal', 'services'), [21, 11, 18]), (('yeah', 'never'), [5, 1, 18]), (('like', 'never'), [3, 1, 17])]\n"
     ]
    }
   ],
   "source": [
    "# find top-5 entailment and contradiction patterns\n",
    "top_5_entailment = sorted(top_100_pairs_labels.items(), key=lambda x: x[1][0], reverse=True)[:5]\n",
    "top_5_contradict = sorted(top_100_pairs_labels.items(), key=lambda x: x[1][2], reverse=True)[:5]\n",
    "\n",
    "print(\"Entailment Patterns:\")\n",
    "print(top_5_entailment)\n",
    "print(\"Contradiction Patterns:\")\n",
    "print(top_5_contradict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjVti-vL_3vV"
   },
   "source": [
    "### **2.3 Case Study**\n",
    "\n",
    "Find out and study **4 representative** cases where the pattern that you have found in 2.2 **fails**, e.g., the premise-hypothesis sentence pair contains ('good', 'bad'), but has an *entailment* gold label.\n",
    "\n",
    "**Based on your case study, explain the limitations of the word-pair patterns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1681032107632,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "B7xZB-GwMjB0",
    "outputId": "10f509f2-685e-46bc-97fb-9ea5bd147bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_fiction.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_government.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_government.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_slate.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_fiction.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_travel.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.jsonl', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_slate.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.json', '/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_travel.json']\n"
     ]
    }
   ],
   "source": [
    "# all your saved model prediction results in 1.2 Fine-Grained Validation\n",
    "\n",
    "# ROOT_PATH = '../A2'\n",
    "ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2\"\n",
    "folder_path = ROOT_PATH + \"/nli_data/predictions\"\n",
    "prediction_files = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    prediction_files.append(os.path.join(folder_path, filename))\n",
    "\n",
    "print(prediction_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1681036900670,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "wtko3e1PWFOq",
    "outputId": "50bea760-426f-41c3-a3a0-5d7965125820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.json\n",
      "index 546\n",
      "Premise: and uh my daughter gets irate when i when i do that because you know she's a teenager\n",
      "Hypothesis: My daughter's a teenager and so she gets mad whenever I do that.\n",
      "Label: entailment\n",
      "prediction: entailment\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking for contradiction label on the pair ('know', 'never'), [1, 0, 26])\n",
    "\"\"\"\n",
    "Example of a the patern (('know', 'never'), [1, 0, 26]) is most of the time contradiction but  have one entailment\n",
    "\"\"\"\n",
    "for file in prediction_files:\n",
    "    with jsonlines.open(file) as reader:\n",
    "        # Loop through all predictions in the file\n",
    "        for idx, sample in enumerate(reader.iter()):\n",
    "            # Check if premise contains the pair words\n",
    "            if 'know' in sample['premise'] and 'know' not in sample['hypothesis'] \\\n",
    "                and 'never' in sample['hypothesis'] and 'never' not in sample['premise'] \\\n",
    "                and sample['label'] == 'entailment':\n",
    "\n",
    "                print('file', file)\n",
    "                print('index', idx)\n",
    "                print('Premise:', sample['premise'])\n",
    "                print('Hypothesis:', sample['hypothesis'])\n",
    "                print('Label:', sample['label'])\n",
    "                print('prediction:', sample['prediction'])\n",
    "                print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1681037068386,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "Murvr0ggXu6p",
    "outputId": "2de39006-51ae-48d5-be64-61ba64c3a1b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.json\n",
      "index 766\n",
      "Premise: and the same is true of the drug hangover you know if you\n",
      "Hypothesis: It's nothing like a drug hangover.\n",
      "Label: contradiction\n",
      "prediction: contradiction\n",
      "\n",
      "\n",
      "file /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.json\n",
      "index 1101\n",
      "Premise: um-hum yeah i know what that's like uh-huh\n",
      "Hypothesis: I have no idea what that is like.\n",
      "Label: contradiction\n",
      "prediction: contradiction\n",
      "\n",
      "\n",
      "file /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/nli_data/predictions/dev_pred_telephone.json\n",
      "index 1209\n",
      "Premise: yeah right right yeah i know i uh i remember my college days  and having to do that too\n",
      "Hypothesis: I remember that when I went to college we didn't have anything like that.\n",
      "Label: contradiction\n",
      "prediction: contradiction\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking for contradiction label on the pair (('know', 'like'), [18, 15, 3])\n",
    "\"\"\"\n",
    "Example of a the patern (('know', 'like'), [18, 15, 3]) is most of the time entailment but  have one entailment\n",
    "\"\"\"\n",
    "for file in prediction_files:\n",
    "    with jsonlines.open(file) as reader:\n",
    "        # Loop through all predictions in the file\n",
    "        for idx, sample in enumerate(reader.iter()):\n",
    "            # Check if premise contains \"may\" and hypothesis contains \"might\"\n",
    "            if 'know' in sample['premise'] and 'like' in sample['hypothesis'] and sample['label'] == 'contradiction' :\n",
    "                print('file', file)\n",
    "                print('index', idx)\n",
    "                print('Premise:', sample['premise'])\n",
    "                print('Hypothesis:', sample['hypothesis'])\n",
    "                print('Label:', sample['label'])\n",
    "                print('prediction:', sample['prediction'])\n",
    "                print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzGGwXlQn7Db"
   },
   "source": [
    "The word-pair pattern approach can be effective in detecting entailment and contradiction relationships in certain cases. However, there are limitations to this approach. For example, in the case of the word-pair pattern ('services', 'legal'), it may suggest a strong entailment relationship (top5 frequency for entailment), but it is also pattern word pair in the top5 for contradiction.\n",
    "\n",
    "Similarly, the word-pair pattern ('know', 'like') may suggest a entailment relationship, but in some cases, it may not hold true. In our case there is 3 case with contradiction relationship. \n",
    "\n",
    "These examples demonstrate the limitations of  word-pair patterns for detecting entailment and contradiction relationships. To improve the accuracy of these predictions, it is important to take into account the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yND0DEfT-eXn"
   },
   "source": [
    "## **Task3: Annotate New Data**\n",
    "\n",
    "To check the robustness of developed model, **some additional sets of test data** are collected, which contain NLI samples that are out of the domains of the training and validation data.\n",
    "\n",
    "However, the test data does not have gold labels of the relationships between premise and hypothesis sentences, i.e., all the labels are marked as *hidden*. **We consider to annotate the data by ourselves.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQNXrRHr_3vV"
   },
   "source": [
    "### **3.1 Write an Annotation Guideline**\n",
    "\n",
    "Imagine that you are going to assign this annotation task to a crowdsourcing worker, who is completely not familiar with computer science and NLP. Think about how you are going to explain this annotation task to him in order to guide him do a decent job. Write an annotation guideline for such a worker who are going to do this task for you.\n",
    "\n",
    "**Note:** You should come up with your own guideline without the help of your partner(s) in later Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfkqNbUA_3vV"
   },
   "source": [
    "(Write your annotation guideline here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdWjryWzCINL"
   },
   "source": [
    "#### Guideline\n",
    "\n",
    "You will have the data to annotate under the form on one premise sentence follow by an hypothesis.\n",
    "Your role is to labelised to say the link between the premise and the hypothesis. In detail is to determine whether the hypothesis is supported, contradicted or can't be inderred from the premise. \n",
    "\n",
    "\n",
    "1. Read and understand the premise and the hypothesis carefully\n",
    "\n",
    "2. Now determine the link between the hypothesis and the premise:\n",
    "- does the hypothesis contradicted the premise?\n",
    "- does they say incompatible information?\n",
    "- Note: seek for the presence of negation in one sentence, seek for the presence of words that have contradictoire meaning (start/finish, at time/late, old/young, ...\n",
    "-> then the label is \"contradiction\"\n",
    "2.1 if the sentence is not contradictoire, does the hypothesis support the premise?\n",
    "- if the premise is the only knowledge you have, can you determine the hypothesis? \n",
    "- does all the information provide by the hypothesis come from the premise?\n",
    "- does the hypothesis repeat what say the premise without adding information?\n",
    "- does the hypothesis clearly implied by the premise?\n",
    "write label \"entailment\"\n",
    "2.2 if the sentence is not contradictoire and not support by the premise,it may be an example of 'neutral' \n",
    "- does the hypothesis speak about another thing than the premise?\n",
    "- is the hypothesis not directly support by the premise?\n",
    "write 'neutral' \n",
    "\n",
    "\n",
    "\n",
    "**studen note:** the choice has been made in the guideline to pay attention at contradiction before entailment is because he found easier to repart contradiction than clear support between the premise and the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBWK4Bw__3vV"
   },
   "source": [
    "### **3.2 Annotate Your 100 Datapoints with Partner(s)**\n",
    "\n",
    "Annotate your 100 test datapoints with your partner(s), by editing the value of the key \"label_student1\", \"label_student2\" and \"label_student3\" (if you are in a group of three students) in each datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cczFQm0eHknv"
   },
   "source": [
    "**Note:** \n",
    "- You can download the assigned annotation file (`<your-testset-id>.jsonl`) by [this link](https://drive.google.com/drive/folders/146ExExmpnSUayu6ArGiN5gQzCPJp0myB?usp=share_link)\n",
    "- Please find your annotation partner according to the \"Student Pairing List for A2 Task3\" shared on Ed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWhjTn2fQ5YE"
   },
   "source": [
    "**Name your annotated file as `<index>-<sciper_number>.jsonl`.** \n",
    "\n",
    "For example, if you get `01.jsonl` to annotate, you should name your deliverable as `01-<your_sciper_number>.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1680789742842,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "Xiivy8c40_PH",
    "outputId": "a9c30295-d3f1-413d-b343-4c939df1e7b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  91\n",
      "premise:     As Indianapolis Center continued searching for the aircraft, two managers and the controller responsible for American 77 looked to the west and southwest along the flight's projected path, not east-where the aircraft was now heading.\n",
      "hypothesis:  They did not locate the plane until it crashed.\n",
      "label:       neutral\n",
      "\n",
      "\n",
      "index:  92\n",
      "premise:     But most important, it must have a managerial system capable of coordinating these elements on an ongoing basis.\n",
      "hypothesis:  A competent managerial system that is capable of consistently coordinating these elements is a necessity.\n",
      "label:       entailment\n",
      "\n",
      "\n",
      "index:  93\n",
      "premise:     Some within the Pentagon argued in the 1990s that the alert sites should be eliminated entirely.\n",
      "hypothesis:  Alert sites are costing the government a lot of money.\n",
      "label:       neutral\n",
      "\n",
      "\n",
      "index:  94\n",
      "premise:     Our approach to the problem was to use operations research techniques and computer simulations of demand to explore the appropriate inventory levels, taking into account the statistical nature of the weekly demand for each of the SKUs for a style.\n",
      "hypothesis:  Setting up the computer simulations was the easiest part.\n",
      "label:       neutral\n",
      "\n",
      "\n",
      "index:  95\n",
      "premise:     Then all the pieces of the patterns must be laid out for the various units so that they can be cut at the same time.\n",
      "hypothesis:  You can cut the patterns at the same time without laying all the pieces out.\n",
      "label:       contradiction\n",
      "\n",
      "\n",
      "index:  96\n",
      "premise:     All proceeds of this project will be used to pay for the benches and additional upgrades for the student lounge.\n",
      "hypothesis:  The student lounge will receive upgrades through the funds received from the project. \n",
      "label:       neutral\n",
      "\n",
      "\n",
      "index:  97\n",
      "premise:     Urban did excellent with his cane, but with Cameron, Urban gets from point A to point B in a snap- quicker than I can take him.\n",
      "hypothesis:  Urban would take longer to get from point A to point B if he did not have Cameron.\n",
      "label:       entailment\n",
      "\n",
      "\n",
      "index:  98\n",
      "premise:     As Scholastic Aptitude Test (SAT) scores of American high school graduates plummeted and concern over the academic preparation of American children and youths became widespread, a  back to basics  movement arose that, by 1980, was in full swing.\n",
      "hypothesis:  The schools began to try to teach kids more after finding low SAT scores.\n",
      "label:       neutral\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code to see the data\n",
    "number = 90\n",
    "data_dir = ROOT_PATH+'/nli_data'\n",
    "data_dev_path = os.path.join(data_dir, '28-288275.jsonl')\n",
    "with jsonlines.open(data_dev_path, \"r\") as reader:\n",
    "    for sid, sample in enumerate(reader.iter()):\n",
    "        if sid > number:\n",
    "            print('index: ',sid)\n",
    "            print('premise:    ', sample['premise'])\n",
    "            print('hypothesis: ',sample['hypothesis'])\n",
    "            print('label:      ', sample['label_student2'])\n",
    "            print('\\n')\n",
    "        if sid > number + 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7AhPeNeAy0S"
   },
   "outputs": [],
   "source": [
    "# code to label the data\n",
    "#ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2\" \n",
    "data_dir = ROOT_PATH+'/nli_data'\n",
    "data_dev_path = os.path.join(data_dir, '28-288275.jsonl')\n",
    "\n",
    "my_dict = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "\n",
    "with jsonlines.open(data_dev_path) as reader:\n",
    "    data = list(reader)\n",
    "new_label = '0'\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    if new_label == 'q':\n",
    "        break\n",
    "        \n",
    "    if d['label_student2'] == 'unknown':\n",
    "        while True:\n",
    "            print(' i: ', i)\n",
    "            print('premise:', d['premise'])\n",
    "            print('hypothesis:',d['hypothesis'])\n",
    "            print('label:',d['label_student2'])\n",
    "            \n",
    "            new_label = input('Enter label')\n",
    "\n",
    "            if new_label == 'q':\n",
    "                break            \n",
    "            elif new_label.isdigit() and 0 <= int(new_label) < 3:\n",
    "                new_label = int(new_label)\n",
    "                data_1[i]['label_student3'] = my_dict[new_label]\n",
    "                break\n",
    "         \n",
    "\n",
    "with jsonlines.open(data_dev_path, mode='w') as writer:\n",
    "    writer.write_all(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyP0GtHe_3vW"
   },
   "source": [
    "### **3.3 Agreement Measure**\n",
    "\n",
    "Based on your and your partner's annotations on the 100 test datapoints in 3.2, calculate the [Cohen's Kappa](https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-kappa) or [Krippendorff's Alpha](https://github.com/pln-fing-udelar/fast-krippendorff) (if you are in a group of three students) between the annotators. Discuss the agreement measure results.\n",
    "\n",
    "**Note:** Cohen's Kappa or Krippendorff's Alpha interpretation\n",
    "\n",
    "0: No Agreement\n",
    "\n",
    "0 ~ 0.2: Slight Agreement\n",
    "\n",
    "0.2 ~ 0.4: Fair Agreement\n",
    "\n",
    "0.4 ~ 0.6: Moderate Agreement\n",
    "\n",
    "0.6 ~ 0.8: Substantial Agreement\n",
    "\n",
    "0.8 ~ 1.0: Near Perfect Agreement\n",
    "\n",
    "1.0: Perfect Agreement\n",
    "\n",
    "> **Questions**: What is your interpretation of Cohen's Kappa or Krippendorff's Alpha value according to the above mapping? Which kind of disagreements are most frequently happen between you and your partner(s), i.e., *entailment* vs. *neutral*, *entailment* vs. *contradiction*, or *neutral* vs. *contradiction*? For the second question, give some examples to explain why that is the case. Are there possible ways to address the disagrrements between two annotators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpS6VOiX_3vW"
   },
   "outputs": [],
   "source": [
    "# fill your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFRR5lHbA4VY"
   },
   "outputs": [],
   "source": [
    "def check_disagreement(label_studen_1, label_studen_2):\n",
    "    \"\"\"\n",
    "    input: label_student_1, label_student_2: string\n",
    "    output: number\n",
    "    0: error\n",
    "    1: for entailment vs. neutral\n",
    "    2: for entailment vs. contradiction\n",
    "    3: for neutral vs. contradiction\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    \n",
    "    if label_studen_1 == \"entailment\":\n",
    "        \n",
    "        if label_studen_2 == \"neutral\":\n",
    "            result = 1\n",
    "        elif label_studen_2 == \"contradiction\":\n",
    "            result = 2\n",
    "        else:\n",
    "            print('error the label are the same',label_studen_1, label_studen_2)\n",
    "        \n",
    "    elif label_studen_1 == \"neutral\":\n",
    "        \n",
    "        if label_studen_2 == \"entailment\":\n",
    "            result = 1\n",
    "        elif label_studen_2 == \"contradiction\":\n",
    "            result = 3\n",
    "        else:\n",
    "            print('error the label are the same',label_studen_1, label_studen_2)\n",
    "        \n",
    "    elif label_studen_1 == \"contradiction\":\n",
    "        \n",
    "        if label_studen_2 == \"entailment\":\n",
    "            result = 2\n",
    "        elif label_studen_2 == \"neutral\":\n",
    "            result = 3\n",
    "        else:\n",
    "            print('error the label are the same',label_studen_1, label_studen_2)\n",
    "\n",
    "            \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJxIURgkA5Yf"
   },
   "outputs": [],
   "source": [
    "# code to check the number of commun labl\n",
    "# ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2\" \n",
    "ROOT_PATH = \"../A2\" # Replace with your directory to A2 folder\n",
    "data_dir = ROOT_PATH+'/nli_data'\n",
    "data_dev_path = os.path.join(data_dir, '28-351555.jsonl')\n",
    "data_dev_path_2 = os.path.join(data_dir, '28-288275.jsonl')\n",
    "\n",
    "my_dict = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "my_dict_inv = {\"entailment\": 0, \"neutral\":1 , \"contradiction\":2}\n",
    "\n",
    "# 1: for entailment vs. neutral\n",
    "# 2: for entailment vs. contradiction\n",
    "# 3: for neutral vs. contradiction\n",
    "\n",
    "entvsneu = 0\n",
    "entvscon = 0\n",
    "neuvscon = 0\n",
    "\n",
    "\n",
    "with jsonlines.open(data_dev_path) as reader:\n",
    "    data_1 = list(reader)\n",
    "\n",
    "with jsonlines.open(data_dev_path_2) as reader:\n",
    "    data_2 = list(reader)\n",
    "\n",
    "input = '0'\n",
    "same = 0\n",
    "not_same= 0\n",
    "diff = []\n",
    "ind_diff = []\n",
    "for i, d in enumerate(data_1):\n",
    "    if d['label_student1'] == data_2[i]['label_student2']:\n",
    "        #print(i)\n",
    "        same += 1\n",
    "    else:\n",
    "        not_same += 1\n",
    "        disagreement = check_disagreement(d['label_student1'], data_2[i]['label_student2'])\n",
    "        \n",
    "        if disagreement == 0:\n",
    "            print('error disagrement')\n",
    "        # entailment vs. neutral\n",
    "        elif disagreement == 1:\n",
    "            entvsneu += 1\n",
    "        # entailment vs. contradiction\n",
    "        elif disagreement == 2:\n",
    "            entvscon += 1\n",
    "        # 3: for neutral vs. contradiction\n",
    "        elif disagreement == 3:\n",
    "            neuvscon += 1\n",
    "        diff.append(d)\n",
    "        ind_diff.append(i)\n",
    "\n",
    "\n",
    "print('same:', same, 'not_same', not_same)\n",
    "print('entailment vs. neutral', entvsneu)\n",
    "print('entailment vs. contradiction', entvscon)\n",
    "print('neutral vs. contradiction', neuvscon)\n",
    "print('indices of label differents:', ind_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urVt95nGCuta"
   },
   "source": [
    "There are 35 disagreements between my partner and me. The most frequent disagreement is about entailment versus neutrality. One possible reason for this is the multiple meanings of certain words, as well as the fact that neither my partner nor I have English as our native language. Therefore, sometimes we do not completely understand the meaning of a sentence. The disagreement between entailment and contradiction occurs the least, and when it does happen, it is usually due to an unintentional mistake or lack of attention. We are able to reach an agreement quickly in such cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WUeSASOC1JM"
   },
   "source": [
    "Disagrement entailment vs neutral:\n",
    "- index:  48\n",
    "- premise:     That was the favorite part of the story!\n",
    "- hypothesis:  That was the best part of the story!\n",
    "- label student 1:  neutral   \n",
    "- label student 2:  entailment\n",
    "\n",
    "In the given example, there is a disagreement between two students on whether the hypothesis entails the premise. Although the two sentences convey similar meanings, there is a subtle difference in the words \"favorite\" and \"best\". \"Favorite\" refers to something that is preferred or liked the most, while \"best\" refers to something that is of the highest quality or excellence, which conduct to put the label neutral for the first student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GcDTQpbC4H7"
   },
   "source": [
    "Disagrement contradiction vs neutral:\n",
    "- premise:     Into adulthood, what books do you like now?\n",
    "- hypothesis:  Why don't you read books, now that you're an adult?\n",
    "- label:       contradiction\n",
    "- label2:      neutral\n",
    "\n",
    "In the example above, at first, I labeled it as neutral, reasoning that the premise and the hypothesis were asking about different things: the type of books or if the person reads books at all. However, my partner pointed out that the premise implies that the person has already started reading books, and thus the hypothesis contradicts this by implying that the person doesn't read books as an adult. This example shows the importance of carefully reading and analyzing the context of the given sentences to accurately identify the correct label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB0537y9C6PZ"
   },
   "source": [
    "How to do better?\n",
    "\n",
    "In summary, most of our labeling disagreements were due to a lack of deep understanding of the sentences. Employing the services of two English-speaking workers to label the data could improve the Cohen's Kappa or Krippendorff's Alpha values, as they have a better understanding of the meaning of the sentences and common expressions. The remaining the disagreements were caused by inattention errors. In such cases, having multiple workers label the same data and taking results with the highest frequency can remove such errors. However, this would increase the cost of human labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxAnfp6_C_Vq"
   },
   "outputs": [],
   "source": [
    "# code see in detail the disagrement\n",
    "# ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2\" \n",
    "ROOT_PATH = \"../A2\" # Replace with your directory to A2 folder\n",
    "data_dir = ROOT_PATH+'/nli_data'\n",
    "#data_dev_path_fin = os.path.join(data_dir, 'commun_agrre.jsonl')\n",
    "\n",
    "new_label = 0\n",
    "\n",
    "for i in ind_diff:\n",
    "        \n",
    "    print(i)\n",
    "    print('index: ',i)\n",
    "    print('premise:    ', data_1[i]['premise'])\n",
    "    print('hypothesis: ', data_1[i]['hypothesis'])\n",
    "    print('label:      ', data_1[i]['label_student1'])\n",
    "    print('label2:     ', data_2[i]['label_student2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 3062,
     "status": "ok",
     "timestamp": 1681052376601,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "413HU82yDE4X"
   },
   "outputs": [],
   "source": [
    "# agreement on disagreement values \n",
    "ground_truth = {\n",
    "    0:'entailment',\n",
    "    1:'neutral', 4:'entailment', \n",
    "    13:'entailment', 17:'entailment', \n",
    "    19:'entailment', 22:'neutral', \n",
    "    32:'entailment', 36:'entailment', \n",
    "    41:'entailment', 42:'neutral', \n",
    "    43:'neutral', 48:'entailment', \n",
    "    51:'contradiction', 53:'contradiction', \n",
    "    54:'contradiction', 61:'entailment', \n",
    "    62:'neutral', 63:'contradiction', \n",
    "    66:'entailment', 71:'entailment', \n",
    "    72:'neutral', 74:'contradiction',\n",
    "    75:'neutral', 78:'neutral',\n",
    "    80:'neutral', 81:'contradiction',\n",
    "    83:'neutral', 86:'neutral',\n",
    "    87:'contradiction', 90:'entailment',\n",
    "    91:'neutral', 93:'neutral',\n",
    "    94:'neutral', 96:'neutral'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3052,
     "status": "ok",
     "timestamp": 1681052410692,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "M2SDHmvDDHJm",
    "outputId": "6c2d994b-f9ab-471e-8b94-6435cf8be7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 entailment\n",
      "1 neutral\n",
      "2 entailment\n",
      "3 contradiction\n",
      "4 entailment\n",
      "5 entailment\n",
      "6 contradiction\n",
      "7 entailment\n",
      "8 contradiction\n",
      "9 neutral\n",
      "10 contradiction\n",
      "11 contradiction\n",
      "12 contradiction\n",
      "13 entailment\n",
      "14 contradiction\n",
      "15 entailment\n",
      "16 entailment\n",
      "17 entailment\n",
      "18 neutral\n",
      "19 entailment\n",
      "20 entailment\n",
      "21 entailment\n",
      "22 neutral\n",
      "23 neutral\n",
      "24 neutral\n",
      "25 contradiction\n",
      "26 entailment\n",
      "27 contradiction\n",
      "28 neutral\n",
      "29 neutral\n",
      "30 contradiction\n",
      "31 neutral\n",
      "32 entailment\n",
      "33 contradiction\n",
      "34 neutral\n",
      "35 contradiction\n",
      "36 entailment\n",
      "37 contradiction\n",
      "38 contradiction\n",
      "39 entailment\n",
      "40 contradiction\n",
      "41 entailment\n",
      "42 neutral\n",
      "43 neutral\n",
      "44 entailment\n",
      "45 contradiction\n",
      "46 entailment\n",
      "47 entailment\n",
      "48 entailment\n",
      "49 contradiction\n",
      "50 entailment\n",
      "51 contradiction\n",
      "52 entailment\n",
      "53 contradiction\n",
      "54 contradiction\n",
      "55 entailment\n",
      "56 neutral\n",
      "57 contradiction\n",
      "58 neutral\n",
      "59 entailment\n",
      "60 entailment\n",
      "61 entailment\n",
      "62 neutral\n",
      "63 contradiction\n",
      "64 entailment\n",
      "65 entailment\n",
      "66 entailment\n",
      "67 entailment\n",
      "68 entailment\n",
      "69 contradiction\n",
      "70 entailment\n",
      "71 entailment\n",
      "72 neutral\n",
      "73 neutral\n",
      "74 contradiction\n",
      "75 neutral\n",
      "76 entailment\n",
      "77 entailment\n",
      "78 neutral\n",
      "79 contradiction\n",
      "80 neutral\n",
      "81 contradiction\n",
      "82 contradiction\n",
      "83 neutral\n",
      "84 neutral\n",
      "85 contradiction\n",
      "86 neutral\n",
      "87 contradiction\n",
      "88 entailment\n",
      "89 contradiction\n",
      "90 entailment\n",
      "91 neutral\n",
      "92 entailment\n",
      "93 neutral\n",
      "94 neutral\n",
      "95 contradiction\n",
      "96 neutral\n",
      "97 entailment\n",
      "98 neutral\n",
      "99 neutral\n"
     ]
    }
   ],
   "source": [
    "# code to put all the information in the file 28-288275.jsonl\n",
    "ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2\" \n",
    "# ROOT_PATH = \"../A2\" # Replace with your directory to A2 folder\n",
    "data_dir = ROOT_PATH+'/nli_data'\n",
    "data_dev_path = os.path.join(data_dir, '28-351555.jsonl')\n",
    "data_dev_path_2 = os.path.join(data_dir, '28-288275.jsonl')\n",
    "\n",
    "my_dict = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "my_dict_inv = {\"entailment\": 0, \"neutral\":1 , \"contradiction\":2}\n",
    "\n",
    "\n",
    "with jsonlines.open(data_dev_path) as reader_1:\n",
    "    data_1 = list(reader_1)\n",
    "\n",
    "with jsonlines.open(data_dev_path_2) as reader_2:\n",
    "    data_2 = list(reader_2)\n",
    "\n",
    "\n",
    "for i, d in enumerate(data_2):\n",
    "    # print('index', i)\n",
    "    d['label_student1'] = data_1[i]['label_student1']\n",
    "    \n",
    "    if d['label_student2'] == data_1[i]['label_student1']:\n",
    "        d['label'] = d['label_student2']\n",
    " \n",
    "    else:\n",
    "        # print('disagrement index',i)\n",
    "        d['label'] = ground_truth[i]\n",
    "        \n",
    "    # print(i,d['label'])\n",
    "# write the label student 1 and label values in the document 28-288275.jsonl\n",
    "with jsonlines.open(data_dev_path_2, mode='w') as writer:\n",
    "    writer.write_all(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff12-RLf_3vW"
   },
   "source": [
    "### **3.4 Robustness Check**\n",
    "\n",
    "Take into account both your and your partner's annotations, determine the final labels of the 100 test datapoints, by editing the value of the key \"label\" in each of your datapoint.\n",
    "\n",
    "Evaluate the performance of your developed model in 1.4 (still under the first hyperparameter setting) on your annotated 100 test datapoints, and compare with the model performance on the validation set.\n",
    "\n",
    "> **Question**: Do you think that your developed model has a good robuestness of handling out-of-domain NLI predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LowJ05h6ypaA"
   },
   "outputs": [],
   "source": [
    "# fill your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1681052287196,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "xdEcBkOCWbec",
    "outputId": "f5a0647f-62fb-41e4-c67a-973852c6e761"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "epoch = 2\n",
    "learning_rate = 2e-5\n",
    "warmup_percent = 0.3\n",
    "repo =  ROOT_PATH+f'/runs/lr{learning_rate}-warmup{warmup_percent}'\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer_checkpoint = os.path.join(repo, 'tokenizer_epoch{}.pt'.format(epoch))\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "\n",
    "# load params model\n",
    "model_checkpoint = os.path.join(repo, 'model_epoch{}.pt'.format(epoch))\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "state_dict = torch.load(model_checkpoint)\n",
    "model.load_state_dict(state_dict)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1681052482097,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "0LsjmKhuWr7d",
    "outputId": "183faa59-d328-49d7-993d-7f7ab6d2d31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 1317.66it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 27.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own annotation data\n",
      "Validation Loss: 0.770 | Accuracy: 76.00%\n",
      "F1: (81.01%, 59.26%, 83.58%) | Macro-F1: 74.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################### Results on own data annotation #########################333\n",
    "# Initialize the output files prediction for each domain\n",
    "output_dir = os.path.join(ROOT_PATH, \"nli_data/predictions\")\n",
    "output_file = os.path.join(output_dir, f\"pred_own_annotation.jsonl\")\n",
    "batch_size = 50\n",
    "\n",
    "# Evaluate and save prediction results\n",
    "data_annotation = f\"/nli_data/28-288275.jsonl\"\n",
    "data_annotation_dataset = NLIDataset(ROOT_PATH + data_annotation, tokenizer)\n",
    "\n",
    "result_save_file = f'/nli_data/predictions/dev_pred_data_annotation.json'\n",
    "dev_loss, acc, f1_ent, f1_neu, f1_con = evaluate(data_annotation_dataset, model, device,  batch_size, result_save_file= ROOT_PATH + result_save_file)\n",
    "\n",
    "macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n",
    "\n",
    "print(f'Own annotation data')\n",
    "print(f'Validation Loss: {dev_loss:.3f} | Accuracy: {acc*100:.2f}%')\n",
    "print(f'F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anEDJlnaieHW"
   },
   "source": [
    "The model achieve hight F1 and accuracy score, so the model seems to be good to predict data outside its dataset.However the test need to be done with more than 100 new data to have a good conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4wuRpHt-rQF"
   },
   "source": [
    "## **Task4: Data Augmentation**\n",
    "\n",
    "Finally, we consider to use a data augmentation method to create more training data, and use the augmented data to improve the model performance. The data augmentation method we are going to use is [EDA](https://aclanthology.org/D19-1670/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEtgwKJt0kfO"
   },
   "source": [
    "### **4.1 EDA: Easy Data Augmentation algorithm for Text**\n",
    "\n",
    "For this section, we will need to implement the most simple data augmentation techniques on textual sentences, including **SR** (Synonym Replacement), **RD** (Random Deletion), **RS** (Random Swap), **RI** (Random Insertion). \n",
    "\n",
    "You should complete all the functions in `eda.py` script, and you can test them with a simple testcase by running the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djFbjk31AR0M"
   },
   "source": [
    "- **Synonym Replacement (SR)**\n",
    "> In Synonym Replacement, we randomly replace some words in the sentence with their synonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyJi-zYyIqsq"
   },
   "source": [
    "You can test whether you get the synonyms right and see an example with synonym replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2161,
     "status": "ok",
     "timestamp": 1681047556076,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "ZMRmcZtx81R4",
    "outputId": "948da8d5-a29e-4d30-f04e-fa576ea63ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The synonyms for the word \"task\" are:  ['chore', 'tax', 'undertaking', 'job', 'project', 'labor']\n"
     ]
    }
   ],
   "source": [
    "from eda import get_synonyms\n",
    "from testA2 import test_get_synonyms\n",
    "\n",
    "test_get_synonyms(get_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1681047556385,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "AjFGy4DLFziY",
    "outputId": "3355c239-c8de-4d97-d485-5bce4d16dcb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Synonym Replacement: hey humankind how are you doing\n"
     ]
    }
   ],
   "source": [
    "from eda import synonym_replacement\n",
    "\n",
    "print(f\" Example of Synonym Replacement: {synonym_replacement('hey man how are you doing',3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfdHwyxaJXUn"
   },
   "source": [
    "- **Random Deletion (RD)**\n",
    "\n",
    "> In Random Deletion, we randomly delete a word if a uniformly generated number between 0 and 1 is smaller than a pre-defined threshold. This allows for a random deletion of some words of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681047556385,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "76bVm640Msa7",
    "outputId": "4f51c9b0-2c4c-4b85-ec6d-ad2a95b8bbbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Random Deletion: hey how are you doing\n"
     ]
    }
   ],
   "source": [
    "from eda import random_deletion\n",
    "\n",
    "print(f\" Example of Random Deletion: {random_deletion('hey man how are you doing', p=0.3, max_deletion_n=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ajqx9cABNk5a"
   },
   "source": [
    "- **Random Swap (RS)**\n",
    "> In Random Swap, we randomly swap the order of two words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681047556386,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "6Vuott-vQn6W",
    "outputId": "ddf5b80f-0b3a-4d0a-80e8-de373251d975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Random Swap: hey man how are doing you\n"
     ]
    }
   ],
   "source": [
    "from eda import swap_word\n",
    "\n",
    "print(f\" Example of Random Swap: {swap_word('hey man how are you doing')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSpcGqdfQ78_"
   },
   "source": [
    "- **Random Insertion (RI)**\n",
    "> Finally, in Random Insertion, we randomly insert synonyms of a word at a random position.\n",
    "> Data augmentation operations should not change the true label of a sentence, as that would introduce unnecessary noise into the data. Inserting a synonym of a word in a sentence, opposed to a random word, is more likely to be relevant to the context and retain the original label of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681047559284,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "G5itS2lJRmvV",
    "outputId": "a19106d1-5df5-49c7-b7a9-fdd415ec399c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Random Insertion: hey man how are you doing perform\n"
     ]
    }
   ],
   "source": [
    "from eda import random_insertion\n",
    "\n",
    "print(f\" Example of Random Insertion: {random_insertion('hey man how are you doing', n=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGOlMl3n1SyJ"
   },
   "source": [
    "### **4.2 Augment Your Model**\n",
    "\n",
    "Combine all the functions you have implemented in 4.1, you can come up with your own data augmentation pipeline with various p and n ;)\n",
    "\n",
    "Next step is to expand the training data you used in Task1, re-train your model in 1.4 on your augmented data, and re-evaluate its performance on both the given validation set as well as on your manually annotated 100 test datapoints. \n",
    "\n",
    "Discuss the improvements that your data augmentation brings to your model. ***Include some examples of old vs. new model predictions to demonstrate the improvements.***\n",
    "\n",
    "**Warning: In terms of data size and training time control, we stipulate that your augmented training data should not be larger than 100M.** (Currently the training data train.jsonl is about 25M.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1681047562213,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "d0pTcUsYzsGZ",
    "outputId": "f239b5e3-b075-4746-e55e-5fe5c5ce3e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original Sentence : hey man how are you doing\n",
      " SR Augmented Sentence : hey gentlemans gentleman how are you doing\n",
      " RD Augmented Sentence : hey man how are you doing\n",
      " RS Augmented Sentence : hey doing how are you man\n",
      " RI Augmented Sentence : hey man how are be you doing\n"
     ]
    }
   ],
   "source": [
    "def aug(sent,n,p):\n",
    "    print(f\" Original Sentence : {sent}\")\n",
    "    print(f\" SR Augmented Sentence : {synonym_replacement(sent, n)}\")\n",
    "    print(f\" RD Augmented Sentence : {random_deletion(sent, p, n)}\")\n",
    "    print(f\" RS Augmented Sentence : {swap_word(sent)}\")\n",
    "    print(f\" RI Augmented Sentence : {random_insertion(sent,n)}\")\n",
    "    \n",
    "aug('hey man how are you doing', p=0.2, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-0U-CD323iY"
   },
   "source": [
    "- Augment training dataset and Re-train your model\n",
    "> Notes: you can decide on your own how much data you want to augment. But there are two pitfalls: i) by EDA, more augmentation means more noises, which not necessarily increases the performance; ii) more data means longer training time. Please balance your data scale and GPU time ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283712,
     "status": "ok",
     "timestamp": 1681047869116,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "bwz2V2F9Mrdg",
    "outputId": "d43f95d2-82ff-45a6-84c1-3ab21d0c5c0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98176it [04:43, 346.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the input samples and write them to the appropriate output file\n",
    "with jsonlines.open(ROOT_PATH+\"/nli_data/train.jsonl\", \"r\") as reader:\n",
    "    for sample in tqdm(reader.iter()):\n",
    "        augment_sample_data(sample, 'train_augmented.jsonl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1681047581330,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "ccdYP7V4Msfl"
   },
   "outputs": [],
   "source": [
    "# function to get 4 augmented sentence from a same premise, we augmented just 50% of the training dataset\n",
    "def augment_sample_data(example, output_file):\n",
    "    augmented_data = []\n",
    "    augmentation = random.choice([0, 1])\n",
    "        \n",
    "    premise = example['premise']\n",
    "    hypothesis = example['hypothesis']\n",
    "    domain = example['domain']\n",
    "    label = example['label']\n",
    "    \n",
    "    # init the augmented data\n",
    "    original_data = {'premise': premise, 'hypothesis':hypothesis, 'domain':domain ,'label': label}\n",
    "    augmented_data.append(original_data)\n",
    "\n",
    "    # just augment the half of the data\n",
    "    if (augmentation % 2) == 0:\n",
    "      augmented_example_sr = {'premise': premise, 'hypothesis':hypothesis, 'domain':domain ,'label': label}\n",
    "      augmented_example_rd = {'premise': premise, 'hypothesis':hypothesis, 'domain':domain ,'label': label}\n",
    "      augmented_example_rs = {'premise': premise, 'hypothesis':hypothesis, 'domain':domain ,'label': label}\n",
    "      augmented_example_ri = {'premise': premise, 'hypothesis':hypothesis, 'domain':domain ,'label': label}\n",
    "      \n",
    "\n",
    "      # get the augmented data\n",
    "      augmented_example_sr['premise'] = synonym_replacement(premise, 2)\n",
    "      augmented_example_rd['premise'] = random_deletion(premise, 0.2, 2)\n",
    "      augmented_example_rs['premise'] = swap_word(premise)\n",
    "      augmented_example_ri['premise'] = random_insertion(premise, 2)\n",
    "\n",
    "      \n",
    "      augmented_data.append(augmented_example_sr)\n",
    "      augmented_data.append(augmented_example_rd)\n",
    "      augmented_data.append(augmented_example_rs)\n",
    "      augmented_data.append(augmented_example_ri)\n",
    "\n",
    "\n",
    "    with jsonlines.open(ROOT_PATH+\"/nli_data/\"+ output_file, \"a\") as writer:\n",
    "      writer.write(sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1681052819322,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "IVxEX5rIEeLw"
   },
   "outputs": [],
   "source": [
    "SCIPER = '288275'\n",
    "seed = int(SCIPER)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79358,
     "status": "ok",
     "timestamp": 1681049236992,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "OBA1EciSFGhc",
    "outputId": "16942c48-63ff-41d0-a4f9-35fc694a3c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98176it [01:13, 1340.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9815it [00:07, 1387.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NLIDataset(ROOT_PATH+\"/nli_data/train_augmented.jsonl\", tokenizer)\n",
    "dev_dataset = NLIDataset(ROOT_PATH+\"/nli_data/dev_in_domain.jsonl\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176765,
     "status": "ok",
     "timestamp": 1681050737081,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "sgvxeArUwvCk",
    "outputId": "2ac2dfec-0e33-46ce-f0f7-fb71650647e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " path save repo /content/drive/MyDrive/Colab Notebooks/mnlp/a2-xav-nal/A2/runs_augmented_model/lr2e-05-warmup0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:03<00:00, 25.25it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 0.949 | Validation Loss: 0.737\n",
      "Epoch 0 NLI Validation:\n",
      "Accuracy: 68.29% | F1: (73.30%, 62.55%, 68.02%) | Macro-F1: 67.95%\n",
      "Model Saved at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:01<00:00, 25.37it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.647 | Validation Loss: 0.598\n",
      "Epoch 1 NLI Validation:\n",
      "Accuracy: 75.33% | F1: (78.91%, 70.85%, 75.94%) | Macro-F1: 75.23%\n",
      "Model Saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:03<00:00, 25.25it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.486 | Validation Loss: 0.588\n",
      "Epoch 2 NLI Validation:\n",
      "Accuracy: 76.58% | F1: (80.63%, 71.63%, 76.55%) | Macro-F1: 76.27%\n",
      "Model Saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6136/6136 [04:01<00:00, 25.38it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:06<00:00, 98.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 0.316 | Validation Loss: 0.695\n",
      "Epoch 3 NLI Validation:\n",
      "Accuracy: 75.96% | F1: (79.44%, 70.44%, 77.24%) | Macro-F1: 75.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 4\n",
    "max_grad_norm = 1.0\n",
    "warmup_percent = 0.3\n",
    "model_save_root = ROOT_PATH+'/runs_augmented_model/'\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model_lr2 = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model_lr2.to(device)\n",
    "\n",
    "learning_rate = 2e-5\n",
    "\n",
    "train(train_dataset, dev_dataset, model_lr2, device, batch_size, epochs,\n",
    "      learning_rate, warmup_percent, max_grad_norm, model_save_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1681052719254,
     "user": {
      "displayName": "patrick colab",
      "userId": "08848837170904977801"
     },
     "user_tz": -120
    },
    "id": "W4mcaQsdcANB",
    "outputId": "cbbc266b-47ea-4081-9755-378527b9b138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 1294.85it/s]\n",
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 27.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own annotation data\n",
      "Validation Loss: 0.803 | Accuracy: 76.00%\n",
      "F1: (80.49%, 57.69%, 84.85%) | Macro-F1: 74.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################### Results on own data annotation #########################333\n",
    "# Initialize the output files prediction for each domain\n",
    "output_dir = os.path.join(ROOT_PATH, \"nli_data/predictions\")\n",
    "output_file = os.path.join(output_dir, f\"pred_own_annotation.jsonl\")\n",
    "batch_size = 50\n",
    "\n",
    "# Evaluate and save prediction results\n",
    "data_annotation = f\"/nli_data/28-288275.jsonl\"\n",
    "data_annotation_dataset = NLIDataset(ROOT_PATH + data_annotation, tokenizer)\n",
    "\n",
    "result_save_file = f'/nli_data/predictions/dev_pred_data_annotation.json'\n",
    "dev_loss, acc, f1_ent, f1_neu, f1_con = evaluate(data_annotation_dataset, model_lr2, device,  batch_size, result_save_file= ROOT_PATH + result_save_file)\n",
    "\n",
    "macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n",
    "\n",
    "print(f'Own annotation data')\n",
    "print(f'Validation Loss: {dev_loss:.3f} | Accuracy: {acc*100:.2f}%')\n",
    "print(f'F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, all three models trained here are producing the same errors and metrics without any improvement despite changing learning rate and data augmentation. It may be an error in the training function. However, most of the time cases, data augmentation can significantly enhance the learning of the data, and the model is still able to produce consistent and accurate predictions.\n",
    "\n",
    "\n",
    "Student Note: Due to problem with git lfs I put all the three model in the folder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7vgXkeJjOhL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3CIeN_kaOQl"
   },
   "source": [
    "### **5 Upload Your Notebook, Data and Models**\n",
    "\n",
    "Please **rename** your filled jupyter notebook as **your Sciper number** and upload it to your GitHub Classroom repository, **with all cells run and output results shown**.\n",
    "\n",
    "**Note:** We are **not** responsible for re-running the cells in your notebook.\n",
    "\n",
    "Please also submit all your processed (e.g., anotated and augmented) datasets, as well as all your trained models in Task 1 and Task 4, in your GitHub Classroom repository.\n",
    "\n",
    "The datasets and models that you need to submit include:\n",
    "\n",
    "**1. The best model checkpoint you trained in the Section 1.2 \"Start Training and Validation!\"**\n",
    "\n",
    "**2. The best model prediction results in the Section 1.2 \"Fine-Grained Validation\"**\n",
    "\n",
    "**3. Your annotated test dataset in the Section 3.2 \"Annotate Your 100 Datapoints with Partner(s)\"**\n",
    "\n",
    "**4. Your augmented training data and best model checkpoint in the Section 4.2 \"Augment Your Model\"**\n",
    "\n",
    "**Note:** You may need to use [GitHub LFS](https://edstem.org/eu/courses/379/discussion/27240) for submitting large files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "009cb23db59e4afab43848eaad06220a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04fead673bc9474280c829a2f2fb3594": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "06ae494556304049a67dff1c6a988cd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce9ae65fd8b84ae3a099037271704096",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_28350af55ee142b49689f5eddd2a4043",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.59kB/s]"
     }
    },
    "07591f54f67f4aa383df004151959cc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "089a31b2df724582ab6209c105cfea94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18b27074b7994418a5df559618893bd0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a9009a8d2557415c8c5d67d55dcb58ef",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.00kB/s]"
     }
    },
    "09db8a5a023c44698129284f303aafa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b2a3294e40b43898683dd4e52279e11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18b27074b7994418a5df559618893bd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f2e44badc56447cadff94811f586ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "224bb87361de40fa8715dd1674626707": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f39ebc74ff741d8bec167093a51e1a1",
       "IPY_MODEL_c405f03c8ca54009a5a5b92d11eef7b0",
       "IPY_MODEL_b034bb3b386940b5a4f978ee84d9b007"
      ],
      "layout": "IPY_MODEL_0b2a3294e40b43898683dd4e52279e11"
     }
    },
    "28350af55ee142b49689f5eddd2a4043": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "349577d5964a4ad9ad06f88bbbee465c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36adec8bb3fa456a87731d5cb5fe5340": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa2a028b19a42f49a2653f7abba9c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4c4444adac7444da6584fbad6446d68",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6723243eeb6f4a499ab9a2faf50304a9",
      "value": " 268M/268M [00:01&lt;00:00, 209MB/s]"
     }
    },
    "3d543482b9a140ec8dfd331a57c1d2a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "437038259ba14d04aeb9e01c978fd078": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6093327e1ae74e088edaf0b26ad345dc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_574bc35577904e68b93d3967e252bc02",
      "value": "Downloading (‚Ä¶)solve/main/vocab.txt: 100%"
     }
    },
    "48c1e22ce1cd427c9693f4727ab15666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_885feb5578e2406d95ad72c72f2dcb53",
       "IPY_MODEL_d8c7558b6a354b9e9d98892d88a07ab9",
       "IPY_MODEL_089a31b2df724582ab6209c105cfea94"
      ],
      "layout": "IPY_MODEL_91917d87349e41078e548fa897df844f"
     }
    },
    "52a803f63e614455be6764d621b04575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "574bc35577904e68b93d3967e252bc02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57e0c7e30a69429b8657a79ea8ba85d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f343dc094df4ce0adfa353f00d6d4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_692d2d570a3641ee87a94e991fb36147",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed3de58374664836a7997b703eb3d21a",
      "value": 28
     }
    },
    "608ee6363f7e4d9496dd7fb6db886ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6093327e1ae74e088edaf0b26ad345dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "612f14045cf64834b1b1b8ccdfa5f3a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "622343e18cf84d1dafd40553a5ca7cd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62c321a54b4a40218f6b97e4daea7185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6fe4339b15a4aeb82716e3e08e43f48",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c9c85a25c5f043ffbc7748aea855d06c",
      "value": "Downloading (‚Ä¶)&quot;pytorch_model.bin&quot;;: 100%"
     }
    },
    "6723243eeb6f4a499ab9a2faf50304a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "692d2d570a3641ee87a94e991fb36147": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a8cff0c1f94402a8b0cdbca505ca2e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dad2c85abf047c5b784a254980c9e00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62c321a54b4a40218f6b97e4daea7185",
       "IPY_MODEL_848440db3e9c4eb7a0208dde4e398891",
       "IPY_MODEL_3aa2a028b19a42f49a2653f7abba9c1a"
      ],
      "layout": "IPY_MODEL_b882a7b7f6564c6bb56831807d28b947"
     }
    },
    "6f8a6bc534a1442e8df57fa5b6d1dcf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7db7091ea57a4e409ae91152b7d2954f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d083fa43cf3f45fab704a99bfd523d21",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_608ee6363f7e4d9496dd7fb6db886ac4",
      "value": "Downloading (‚Ä¶)okenizer_config.json: 100%"
     }
    },
    "7f39ebc74ff741d8bec167093a51e1a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d95d3459d66b419db682be37f1e91f8f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1f2e44badc56447cadff94811f586ee7",
      "value": "Downloading (‚Ä¶)solve/main/vocab.txt: 100%"
     }
    },
    "81024a6a91d74f4a99487dbb6ad65e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f71f39d88d0246d994b2670f47e6be9c",
       "IPY_MODEL_884e6e0b834a45e9882516ba9e63e09d",
       "IPY_MODEL_db5f4a3ec37d4bba95a700d7b953f10d"
      ],
      "layout": "IPY_MODEL_dc299c5611a7471482671a3b0e5b35ac"
     }
    },
    "848440db3e9c4eb7a0208dde4e398891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eafd74ba82864714b6f0541683335788",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e08ec8fe730d49ce9a51d433027000d3",
      "value": 267967963
     }
    },
    "84ed04123dd34e79b5c4a33e58e777d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "884e6e0b834a45e9882516ba9e63e09d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97e3364723f642a68ea54390b65a5e13",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04fead673bc9474280c829a2f2fb3594",
      "value": 483
     }
    },
    "885feb5578e2406d95ad72c72f2dcb53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_349577d5964a4ad9ad06f88bbbee465c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b28f0d120a364c339f7dc8aaffa2f414",
      "value": "Downloading (‚Ä¶)okenizer_config.json: 100%"
     }
    },
    "8c87d4d16c7c490d82c3f2ef5963f0c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91917d87349e41078e548fa897df844f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94c25a1c235c43fc9f4b3065135251d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97e3364723f642a68ea54390b65a5e13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5530c446fd24b34ae4b23466dea1bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07591f54f67f4aa383df004151959cc2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e3a83c60434548db83d57e6b59719182",
      "value": " 232k/232k [00:00&lt;00:00, 4.69MB/s]"
     }
    },
    "a9009a8d2557415c8c5d67d55dcb58ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa9da2da6ab24b89838aec95dcc8cd14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94c25a1c235c43fc9f4b3065135251d4",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dae41dda4f22453ea146c046ac666ea5",
      "value": 483
     }
    },
    "afac91edae2843e89f7504795e2e6658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b034bb3b386940b5a4f978ee84d9b007": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09db8a5a023c44698129284f303aafa2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_612f14045cf64834b1b1b8ccdfa5f3a3",
      "value": " 232k/232k [00:00&lt;00:00, 1.12MB/s]"
     }
    },
    "b28f0d120a364c339f7dc8aaffa2f414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2b55eb05fc94f118d4422efeb2783ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6e568729b994312a0cd486399267ca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e18f541420224c9f92443389c9bc1e3f",
       "IPY_MODEL_aa9da2da6ab24b89838aec95dcc8cd14",
       "IPY_MODEL_d4c77cf5d94e4b038b22894925132576"
      ],
      "layout": "IPY_MODEL_57e0c7e30a69429b8657a79ea8ba85d6"
     }
    },
    "b7ae14ff66d849c98e884abc434a4191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_437038259ba14d04aeb9e01c978fd078",
       "IPY_MODEL_f389ecef7f534b3c9993144948a25dfd",
       "IPY_MODEL_a5530c446fd24b34ae4b23466dea1bee"
      ],
      "layout": "IPY_MODEL_f5a2b61845334ad98f8d57f193a863c6"
     }
    },
    "b882a7b7f6564c6bb56831807d28b947": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c405f03c8ca54009a5a5b92d11eef7b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d543482b9a140ec8dfd331a57c1d2a6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9bf1f93880647749d6ef01ab21e0356",
      "value": 231508
     }
    },
    "c9c85a25c5f043ffbc7748aea855d06c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce9ae65fd8b84ae3a099037271704096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d083fa43cf3f45fab704a99bfd523d21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4594c00cf86453e9cba7d5b7e1fe5f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4c77cf5d94e4b038b22894925132576": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36adec8bb3fa456a87731d5cb5fe5340",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e1abd14bd2be47dcae479eaeb2541632",
      "value": " 483/483 [00:00&lt;00:00, 16.4kB/s]"
     }
    },
    "d6fe4339b15a4aeb82716e3e08e43f48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8c7558b6a354b9e9d98892d88a07ab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afac91edae2843e89f7504795e2e6658",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4594c00cf86453e9cba7d5b7e1fe5f1",
      "value": 28
     }
    },
    "d95d3459d66b419db682be37f1e91f8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dae41dda4f22453ea146c046ac666ea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "db5f4a3ec37d4bba95a700d7b953f10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c87d4d16c7c490d82c3f2ef5963f0c0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_622343e18cf84d1dafd40553a5ca7cd7",
      "value": " 483/483 [00:00&lt;00:00, 35.1kB/s]"
     }
    },
    "dba432aa5c584887b716ae8f92caf2c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dc299c5611a7471482671a3b0e5b35ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e08ec8fe730d49ce9a51d433027000d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e18f541420224c9f92443389c9bc1e3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52a803f63e614455be6764d621b04575",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_84ed04123dd34e79b5c4a33e58e777d1",
      "value": "Downloading (‚Ä¶)lve/main/config.json: 100%"
     }
    },
    "e1abd14bd2be47dcae479eaeb2541632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3a83c60434548db83d57e6b59719182": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7878ed83f06451c9e57a2954da2a86f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7db7091ea57a4e409ae91152b7d2954f",
       "IPY_MODEL_5f343dc094df4ce0adfa353f00d6d4c6",
       "IPY_MODEL_06ae494556304049a67dff1c6a988cd0"
      ],
      "layout": "IPY_MODEL_6f8a6bc534a1442e8df57fa5b6d1dcf5"
     }
    },
    "e9bf1f93880647749d6ef01ab21e0356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eafd74ba82864714b6f0541683335788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed3de58374664836a7997b703eb3d21a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f389ecef7f534b3c9993144948a25dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2b55eb05fc94f118d4422efeb2783ca",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dba432aa5c584887b716ae8f92caf2c1",
      "value": 231508
     }
    },
    "f4c4444adac7444da6584fbad6446d68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a2b61845334ad98f8d57f193a863c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f71f39d88d0246d994b2670f47e6be9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a8cff0c1f94402a8b0cdbca505ca2e3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_009cb23db59e4afab43848eaad06220a",
      "value": "Downloading (‚Ä¶)lve/main/config.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
